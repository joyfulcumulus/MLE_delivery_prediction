{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b50484d2-bfa4-40b6-82cd-e8bf86187cfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pyspark\n",
    "import pprint\n",
    "from datetime import datetime, timedelta\n",
    "from dateutil.relativedelta import relativedelta\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "import xgboost as xgb\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from pyspark.sql.functions import col\n",
    "from pyspark.sql import SparkSession\n",
    "from sklearn.metrics import make_scorer, f1_score, roc_auc_score, accuracy_score\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import roc_auc_score, fbeta_score, confusion_matrix, ConfusionMatrixDisplay\n",
    "import numpy as np\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fcac9436-de95-4ebf-9655-56df8e1eafd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build a .py script that takes a snapshot date, trains a model and outputs artefact into storage."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37c91bb1-bcf0-4195-90f3-dc88806ebf8c",
   "metadata": {},
   "source": [
    "## set up pyspark session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "32fb3bc6-4166-4893-88e1-0d3140df5a92",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/06/20 10:03:51 WARN Utils: Your hostname, Baohongs-MacBook-Air.local resolves to a loopback address: 127.0.0.1; using 10.232.169.110 instead (on interface en0)\n",
      "25/06/20 10:03:51 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "25/06/20 10:03:51 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "25/06/20 10:03:52 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.\n"
     ]
    }
   ],
   "source": [
    "# Initialize SparkSession\n",
    "spark = pyspark.sql.SparkSession.builder \\\n",
    "    .appName(\"dev\") \\\n",
    "    .master(\"local[*]\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "# Set log level to ERROR to hide warnings\n",
    "spark.sparkContext.setLogLevel(\"ERROR\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30206071-5f00-4c3b-be13-55c54db8e336",
   "metadata": {},
   "source": [
    "## set up config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f0f3a464-fe45-477b-8815-cebe102228f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'model_train_date': datetime.datetime(2017, 12, 4, 0, 0),\n",
      " 'model_train_date_str': '2017-12-04',\n",
      " 'oot_end_date': datetime.datetime(2017, 12, 3, 0, 0),\n",
      " 'oot_period_months': 3,\n",
      " 'oot_start_date': datetime.datetime(2017, 9, 4, 0, 0),\n",
      " 'train_test_end_date': datetime.datetime(2017, 9, 3, 0, 0),\n",
      " 'train_test_period_months': 12,\n",
      " 'train_test_ratio': 0.8,\n",
      " 'train_test_start_date': datetime.datetime(2016, 9, 4, 0, 0)}\n"
     ]
    }
   ],
   "source": [
    "# set up config\n",
    "model_train_date_str = \"2017-12-04\" # \"2024-09-01\"\n",
    "train_test_period_months = 12\n",
    "oot_period_months = 3\n",
    "train_test_ratio = 0.8\n",
    "\n",
    "config = {}\n",
    "config[\"model_train_date_str\"] = model_train_date_str\n",
    "config[\"train_test_period_months\"] = train_test_period_months\n",
    "config[\"oot_period_months\"] =  oot_period_months\n",
    "config[\"model_train_date\"] =  datetime.strptime(model_train_date_str, \"%Y-%m-%d\")\n",
    "config[\"oot_end_date\"] =  config['model_train_date'] - timedelta(days = 1)\n",
    "config[\"oot_start_date\"] =  config['model_train_date'] - relativedelta(months = oot_period_months)\n",
    "config[\"train_test_end_date\"] =  config[\"oot_start_date\"] - timedelta(days = 1)\n",
    "config[\"train_test_start_date\"] =  config[\"oot_start_date\"] - relativedelta(months = train_test_period_months)\n",
    "config[\"train_test_ratio\"] = train_test_ratio \n",
    "\n",
    "\n",
    "pprint.pprint(config)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d723c08",
   "metadata": {},
   "source": [
    "## get data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "46387f1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_gold_table(table, gold_db, spark):\n",
    "    \"\"\"\n",
    "    Helper function to read all partitions of a gold table\n",
    "    \"\"\"\n",
    "    folder_path = os.path.join(gold_db, table)\n",
    "    files_list = [os.path.join(folder_path, os.path.basename(f)) for f in glob.glob(os.path.join(folder_path, '*'))]\n",
    "    df = spark.read.option(\"header\", \"true\").parquet(*files_list)\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6f7c2f68",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "features_store_sdf = read_gold_table('feature_store', 'datamart/gold', spark)\n",
    "label_store_sdf = read_gold_table('label_store', 'datamart/gold', spark)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "66dbfece",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(39767, 8)\n",
      "(39751, 8)\n"
     ]
    }
   ],
   "source": [
    "test = features_store_sdf.toPandas().shape\n",
    "test2 = features_store_sdf.dropna().toPandas().shape\n",
    "\n",
    "print(test)\n",
    "print(test2)\n",
    "\n",
    "from pyspark.sql.functions import col\n",
    "from functools import reduce\n",
    "\n",
    "rows_with_nulls = features_store_sdf.filter(\n",
    "    reduce(lambda a, b: a | b, (col(c).isNull() for c in features_store_sdf.columns))\n",
    ")\n",
    "\n",
    "order_ids_to_drop = [row[\"order_id\"] for row in rows_with_nulls.select(\"order_id\").distinct().collect()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7706861b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['delivered', 'invoiced', 'shipped', 'processing', 'canceled',\n",
       "       'approved', 'unavailable'], dtype=object)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test2 = features_store_sdf.toPandas()\n",
    "test2['order_status'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c5f841d",
   "metadata": {},
   "source": [
    "## Data split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "73fa662a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extract data for training and testing...\n",
      "extracted labels_sdf 22631\n",
      "extracted features_sdf 22631\n",
      "\n",
      " Extract data for oot...\n",
      "extracted labels_sdf 16026\n",
      "extracted features_sdf 16026\n"
     ]
    }
   ],
   "source": [
    "#Filter for delivered data for training \n",
    "features_store_sdf = features_store_sdf.filter(~col(\"order_id\").isin(order_ids_to_drop))\n",
    "features_store_sdf = features_store_sdf.filter(col(\"order_status\") == \"delivered\")\n",
    "#features_store_sdf = features_store_sdf.filter(col(\"order_status\") == \"delivered\")\n",
    "\n",
    "#Filter for test and train data\n",
    "label_store_sdf = label_store_sdf.filter(~col(\"order_id\").isin(order_ids_to_drop))\n",
    "y_model = label_store_sdf.filter((col(\"snapshot_date\") >= config[\"train_test_start_date\"]) & (col(\"snapshot_date\") <= config[\"train_test_end_date\"]))\n",
    "y_model_oot = label_store_sdf.filter((col(\"snapshot_date\") >= config[\"oot_start_date\"]) & (col(\"snapshot_date\") <= config[\"oot_end_date\"]))\n",
    "\n",
    "# Change to pandas for training \n",
    "features_store_sdf = features_store_sdf.toPandas().sort_values(by=[\"order_id\"])\n",
    "y_model = y_model.toPandas().sort_values(by=[\"order_id\"])\n",
    "X_model = features_store_sdf[np.isin(features_store_sdf['order_id'], y_model['order_id'].unique())]\n",
    "\n",
    "# Change to pandas for OOT \n",
    "y_model_oot = y_model_oot.toPandas().sort_values(by=[\"order_id\"])\n",
    "X_model_oot = features_store_sdf[np.isin(features_store_sdf['order_id'], y_model_oot['order_id'].unique())]\n",
    "\n",
    "print(\"Extract data for training and testing...\")\n",
    "print(\"extracted labels_sdf\", y_model.shape[0])\n",
    "print(\"extracted features_sdf\", X_model.shape[0])\n",
    "\n",
    "print(\"\\n Extract data for oot...\")\n",
    "print(\"extracted labels_sdf\", y_model_oot.shape[0])\n",
    "print(\"extracted features_sdf\", X_model_oot.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4107adfd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>order_id</th>\n",
       "      <th>total_qty</th>\n",
       "      <th>total_price</th>\n",
       "      <th>total_freight_value</th>\n",
       "      <th>total_weight_g</th>\n",
       "      <th>total_volume_cm3</th>\n",
       "      <th>order_status</th>\n",
       "      <th>total_density</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5577</th>\n",
       "      <td>00010242fe8c5a6d1ba2dd792cb16214</td>\n",
       "      <td>1</td>\n",
       "      <td>58.90</td>\n",
       "      <td>13.29</td>\n",
       "      <td>650.0</td>\n",
       "      <td>3528.0</td>\n",
       "      <td>delivered</td>\n",
       "      <td>0.184240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23525</th>\n",
       "      <td>00018f77f2f0320c557190d7a144bdd3</td>\n",
       "      <td>1</td>\n",
       "      <td>239.90</td>\n",
       "      <td>19.93</td>\n",
       "      <td>30000.0</td>\n",
       "      <td>60000.0</td>\n",
       "      <td>delivered</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36088</th>\n",
       "      <td>00042b26cf59d7ce69dfabb4e55b4fd9</td>\n",
       "      <td>1</td>\n",
       "      <td>199.90</td>\n",
       "      <td>18.14</td>\n",
       "      <td>3750.0</td>\n",
       "      <td>42000.0</td>\n",
       "      <td>delivered</td>\n",
       "      <td>0.089286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12306</th>\n",
       "      <td>00048cc3ae777c65dbb7d2a0634bc1ea</td>\n",
       "      <td>1</td>\n",
       "      <td>21.90</td>\n",
       "      <td>12.69</td>\n",
       "      <td>450.0</td>\n",
       "      <td>2880.0</td>\n",
       "      <td>delivered</td>\n",
       "      <td>0.156250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30500</th>\n",
       "      <td>000c3e6612759851cc3cbb4b83257986</td>\n",
       "      <td>1</td>\n",
       "      <td>99.00</td>\n",
       "      <td>13.71</td>\n",
       "      <td>1800.0</td>\n",
       "      <td>4096.0</td>\n",
       "      <td>delivered</td>\n",
       "      <td>0.439453</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1096</th>\n",
       "      <td>fff90cdcb3b2e6cfb397d05d562fd3fe</td>\n",
       "      <td>1</td>\n",
       "      <td>89.90</td>\n",
       "      <td>11.83</td>\n",
       "      <td>750.0</td>\n",
       "      <td>9900.0</td>\n",
       "      <td>delivered</td>\n",
       "      <td>0.075758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36087</th>\n",
       "      <td>fffb0b1a50e65c449020434fa835e078</td>\n",
       "      <td>1</td>\n",
       "      <td>4.90</td>\n",
       "      <td>10.96</td>\n",
       "      <td>100.0</td>\n",
       "      <td>10560.0</td>\n",
       "      <td>delivered</td>\n",
       "      <td>0.009470</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23035</th>\n",
       "      <td>fffb9224b6fc7c43ebb0904318b10b5f</td>\n",
       "      <td>4</td>\n",
       "      <td>220.00</td>\n",
       "      <td>34.19</td>\n",
       "      <td>1400.0</td>\n",
       "      <td>9856.0</td>\n",
       "      <td>delivered</td>\n",
       "      <td>0.142045</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12153</th>\n",
       "      <td>fffce4705a9662cd70adb13d4a31832d</td>\n",
       "      <td>1</td>\n",
       "      <td>99.90</td>\n",
       "      <td>16.95</td>\n",
       "      <td>967.0</td>\n",
       "      <td>9576.0</td>\n",
       "      <td>delivered</td>\n",
       "      <td>0.100982</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9826</th>\n",
       "      <td>fffe18544ffabc95dfada21779c9644f</td>\n",
       "      <td>1</td>\n",
       "      <td>55.99</td>\n",
       "      <td>8.72</td>\n",
       "      <td>100.0</td>\n",
       "      <td>8000.0</td>\n",
       "      <td>delivered</td>\n",
       "      <td>0.012500</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>38657 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                               order_id  total_qty  total_price  \\\n",
       "5577   00010242fe8c5a6d1ba2dd792cb16214          1        58.90   \n",
       "23525  00018f77f2f0320c557190d7a144bdd3          1       239.90   \n",
       "36088  00042b26cf59d7ce69dfabb4e55b4fd9          1       199.90   \n",
       "12306  00048cc3ae777c65dbb7d2a0634bc1ea          1        21.90   \n",
       "30500  000c3e6612759851cc3cbb4b83257986          1        99.00   \n",
       "...                                 ...        ...          ...   \n",
       "1096   fff90cdcb3b2e6cfb397d05d562fd3fe          1        89.90   \n",
       "36087  fffb0b1a50e65c449020434fa835e078          1         4.90   \n",
       "23035  fffb9224b6fc7c43ebb0904318b10b5f          4       220.00   \n",
       "12153  fffce4705a9662cd70adb13d4a31832d          1        99.90   \n",
       "9826   fffe18544ffabc95dfada21779c9644f          1        55.99   \n",
       "\n",
       "       total_freight_value  total_weight_g  total_volume_cm3 order_status  \\\n",
       "5577                 13.29           650.0            3528.0    delivered   \n",
       "23525                19.93         30000.0           60000.0    delivered   \n",
       "36088                18.14          3750.0           42000.0    delivered   \n",
       "12306                12.69           450.0            2880.0    delivered   \n",
       "30500                13.71          1800.0            4096.0    delivered   \n",
       "...                    ...             ...               ...          ...   \n",
       "1096                 11.83           750.0            9900.0    delivered   \n",
       "36087                10.96           100.0           10560.0    delivered   \n",
       "23035                34.19          1400.0            9856.0    delivered   \n",
       "12153                16.95           967.0            9576.0    delivered   \n",
       "9826                  8.72           100.0            8000.0    delivered   \n",
       "\n",
       "       total_density  \n",
       "5577        0.184240  \n",
       "23525       0.500000  \n",
       "36088       0.089286  \n",
       "12306       0.156250  \n",
       "30500       0.439453  \n",
       "...              ...  \n",
       "1096        0.075758  \n",
       "36087       0.009470  \n",
       "23035       0.142045  \n",
       "12153       0.100982  \n",
       "9826        0.012500  \n",
       "\n",
       "[38657 rows x 8 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features_store_sdf[~features_store_sdf.isnull().any(axis=1)]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2784f559",
   "metadata": {},
   "source": [
    "## Prepare data for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a688960c",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_model, y_model, \n",
    "                                                    test_size=config['train_test_ratio'], \n",
    "                                                    random_state=42, \n",
    "                                                    shuffle=True, \n",
    "                                                    stratify=y_model['miss_delivery_sla'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "df4157d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train_processed 4526\n",
      "X_test_processed 18105\n",
      "X_oot_processed 16026\n",
      "X_train shape: (4526, 6)\n"
     ]
    }
   ],
   "source": [
    "# Transform data into numpy arrays\n",
    "X_train_arr = X_train.drop(columns=['order_id','order_status']).values\n",
    "X_test_arr = X_test.drop(columns=['order_id','order_status']).values\n",
    "X_oot_arr = X_model_oot.drop(columns=['order_id','order_status']).values\n",
    "\n",
    "y_train = y_train['miss_delivery_sla'].values\n",
    "y_test = y_test['miss_delivery_sla'].values\n",
    "y_oot = y_model_oot['miss_delivery_sla'].values\n",
    "\n",
    "# Normalize the data using sklearn\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "transformer_stdscaler = scaler.fit(X_train_arr)\n",
    "\n",
    "X_train_processed = transformer_stdscaler.transform(X_train_arr)\n",
    "X_test_processed = transformer_stdscaler.transform(X_test_arr)\n",
    "X_oot_processed = transformer_stdscaler.transform(X_oot_arr)\n",
    "\n",
    "# Print diagnostics\n",
    "print('X_train_processed', X_train_processed.shape[0])\n",
    "print('X_test_processed', X_test_processed.shape[0])\n",
    "print('X_oot_processed', X_oot_processed.shape[0])\n",
    "print(\"X_train shape:\", X_train_arr.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e6a7ca4",
   "metadata": {},
   "source": [
    "## Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "47901b5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== MODEL EVALUATION ===\n",
      "Train AUC: 0.7589 | GINI: 0.5178\n",
      "Test AUC : 0.7145 | GINI: 0.429\n",
      "OOT AUC  : 0.7085 | GINI: 0.417\n"
     ]
    }
   ],
   "source": [
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "# Define fixed hyperparameters\n",
    "params = {\n",
    "    'n_estimators': 300,\n",
    "    'max_depth': 3,\n",
    "    'learning_rate': 0.01,\n",
    "    'subsample': 0.8,\n",
    "    'colsample_bytree': 0.8,\n",
    "    'gamma': 0,\n",
    "    'min_child_weight': 3,\n",
    "    'reg_alpha': 3,\n",
    "    'reg_lambda': 1\n",
    "}\n",
    "\n",
    "# Train model\n",
    "model = XGBClassifier(\n",
    "    eval_metric='logloss',\n",
    "    use_label_encoder=False,\n",
    "    random_state=42,\n",
    "    **params\n",
    ")\n",
    "\n",
    "model.fit(X_train_processed, y_train)\n",
    "\n",
    "# Predict and evaluate\n",
    "y_pred_train = model.predict_proba(X_train_processed)[:, 1]\n",
    "y_pred_test = model.predict_proba(X_test_processed)[:, 1]\n",
    "y_pred_oot = model.predict_proba(X_oot_processed)[:, 1]\n",
    "\n",
    "train_auc = roc_auc_score(y_train, y_pred_train)\n",
    "test_auc = roc_auc_score(y_test, y_pred_test)\n",
    "oot_auc = roc_auc_score(y_oot, y_pred_oot)\n",
    "\n",
    "print(\"\\n=== MODEL EVALUATION ===\")\n",
    "print(\"Train AUC:\", round(train_auc, 4), \"| GINI:\", round(2*train_auc - 1, 4))\n",
    "print(\"Test AUC :\", round(test_auc, 4), \"| GINI:\", round(2*test_auc - 1, 4))\n",
    "print(\"OOT AUC  :\", round(oot_auc, 4), \"| GINI:\", round(2*oot_auc - 1, 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "968f48d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# F1.5 score across thresholds - recall is more important\n",
    "thresholds = np.arange(0.0, 1.0, 0.01)\n",
    "beta = 1.5\n",
    "f1_scores_train = [fbeta_score(y_train, y_pred_train > t, beta=beta) for t in thresholds]\n",
    "f1_scores_test = [fbeta_score(y_test, y_pred_test > t, beta=beta) for t in thresholds]\n",
    "f1_scores_oot = [fbeta_score(y_oot, y_pred_oot > t, beta=beta) for t in thresholds]\n",
    "best_threshold = thresholds[np.argmax(f1_scores_train)]\n",
    "\n",
    "# Plot F1 Score vs. Threshold\n",
    "plt.figure(figsize=(10, 4))\n",
    "plt.plot(thresholds, f1_scores_train, label=\"Train F-%.1f Score\" % beta)\n",
    "plt.plot(thresholds, f1_scores_test, label=\"Test F-%.1f Score\" % beta)\n",
    "plt.plot(thresholds, f1_scores_oot, label=\"OOT F-%.1f Score\" % beta)\n",
    "plt.axvline(x=best_threshold, color=\"red\", linestyle=\"--\", label=\"Best Threshold: %.2f\" % round(best_threshold, 2))\n",
    "plt.title(\"F-%.1f Score vs. Probability Threshold\" % beta)\n",
    "plt.xlabel(\"Threshold\")\n",
    "plt.ylabel(\"F-%.1f Score\" % beta)\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e6645cd4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAABm4AAAHqCAYAAAANuLHCAAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjAsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvlHJYcgAAAAlwSFlzAAAPYQAAD2EBqD+naQAAcEdJREFUeJzt3Xd4FGXbxuFr0xsJJCGhh957L9JEOkhTURBBmhRBBASRlyZNUJEixQqIqGBBRQGlKtI7SG+B0AKEEkgIIcl8f+TLypIENpCQSfidx5HjfffZZ2bvWQl7M9fOMxbDMAwBAAAAAAAAAAAg3TmkdwEAAAAAAAAAAACIR3ADAAAAAAAAAABgEgQ3AAAAAAAAAAAAJkFwAwAAAAAAAAAAYBIENwAAAAAAAAAAACZBcAMAAAAAAAAAAGASBDcAAAAAAAAAAAAmQXADAAAAAAAAAABgEgQ3AAAAAAAAAAAAJkFwAwAAAAAAAAAAYBIEN3isLBaLXT/r1q17pNcZPXq0LBZL6hR9l+PHj8vV1VWbNm3SunXr7D6eu2u6fPlyqtf1MNKinnr16qlevXoPnBccHCyLxaJ58+alyuueOHFCbdu2VdasWeXl5aWGDRtq586dD9wuNjZWU6ZMUZMmTZQnTx55eHioRIkSevvtt3Xt2rVE88+fP68uXbooICBAbm5uKlu2rL744otE80aMGKGKFSsqLi4uNQ4PAABJj6+PkqTIyEiNHj06xftav369XF1dderUKc2bN8+uevPnzy9J6tKli7y8vB659tSSFvXkz59fXbp0eeC8hD4zNf5bStLOnTv1zDPPyMvLS1mzZlXbtm114sSJB24XHh6u8ePHq169esqRI4e8vLxUpkwZTZo0SVFRUYnmHzlyRO3atVO2bNnk4eGhatWq6ddff000r1OnTmrdunVqHBoAAPe1efNmPf/888qZM6dcXFyUI0cOPffcc9q0adMjb5Navdm1a9fk7++v7777znq+xJ6f4OBga7+1ffv21Hi7Hlla1NOlSxdrv/ggFotFo0ePTpXXvXjxorp06SJ/f395eHioRo0aWr16tV3bfv7552rdurXy588vd3d3FS5cWL1799b58+cTzb1x44b69++v3Llzy9XVVUWLFtXkyZMVGxtrM++LL75Q7ty5FRERkSrHB/NzSu8C8GS590Nu7NixWrt2rdasWWMzXrJkyUd6ne7du6tJkyaPtI+kDB48WA0bNlSNGjUUHh6e6HjatGmjQoUK6YMPPkj110bSLl26pNq1aytbtmz68ssv5ebmpokTJ6pevXratm2bihUrluy2t27d0ujRo/XSSy+pe/fu8vf3186dOzVu3DgtXbpU27dvl7u7uyTp+vXreuqppxQdHa3JkycrZ86c+vbbb9W9e3ddv35dAwcOtO538ODB+vjjjzV//ny9+uqraf4eAACeDI+rj5Lig5sxY8ZIkl1fypAkwzA0YMAA9ejRQ0FBQWrevHmimmvUqKHnnntOgwYNso65uro+cr1I3qFDh1SvXj2VL19eixcvVlRUlEaOHKnatWtr9+7dyp49e7Lbnj59WlOnTlWnTp00cOBAeXl5af369Ro9erRWrlyplStXWr+kFBwcrBo1aihnzpyaM2eOvLy8NHv2bLVu3Vrff/+92rVrZ93v6NGjVbx4ca1Zs0ZPP/10mr8HAIAn04wZMzRgwABVrVpVkydPVlBQkE6fPq2ZM2fqqaee0rRp0/T6668/9Dap1ZuNGTNGuXLlUvv27RUdHZ1ov3369NH169e1cOFCm/GcOXOm6P2A/W7fvq0GDRro2rVrmjZtmgICAjRz5kw1adJEq1atUt26de+7/ahRo1S/fn1NmDBBuXPn1uHDhzV27Fj98ssv2rVrlwIDAyVJMTExatiwoY4cOaKxY8eqaNGiWrFihd5++22dOXNG06dPt+6zc+fOmjRpkiZPnmzt05HJGUA66ty5s+Hp6fnAeREREY+hmvs7cOCAIclYsWJFsnOCgoKM5s2bJ/ncqFGjDEnGpUuXUvzacXFxRmRkZIq3u59HqSc5devWNerWrfvAeSdPnjQkGXPnzn3k13zrrbcMZ2dnIzg42Dp2/fp1w9/f33jhhRfuu21MTIxx+fLlROPff/+9IclYsGCBdWzixImGJGP79u02cxs1amR4enoaV69etRl//fXXjaJFixpxcXEPcVQAADyYvX3Uw7h06ZIhyRg1apTd2yxbtsyQZBw6dCjZOZKMvn37JvncoxxPTEyMERUV9VDbJict3t+goCCjc+fOD5y3du1aQ5Kxdu3aR37N559/3vD39zeuX79uHQsODjacnZ2NIUOG3HfbmzdvGjdv3kw0/v777xuSjPXr11vHXnvtNcPNzc04c+aMdSwmJsYoUaKEkTdvXiM2NtZmHy1atDAaNmz4sIcFAMB9/fPPP4aDg4PRokUL486dOzbP3blzx2jRooXh4OBg/PPPP4+0zd0epncICwsz3N3djTlz5iQ7p27dukapUqWSfG7u3LmGJGPbtm0pet0EqX2u6VHrSUrnzp2NoKAgu+amtH9NzsyZMw1JxsaNG61jd+7cMUqWLGlUrVr1gduHhoYmGtu2bZshyRg7dqx17NtvvzUkGT/++KPN3J49exoODg6J+uoPPvjA8PHxMcV5UqQ9lkqD6dSrV0+lS5fW33//rZo1a8rDw0Ndu3aVJC1atEiNGjVSzpw55e7ubl3W6t7LBJNaKi1//vxq0aKFVqxYoYoVK8rd3V3FixfXl19+aVdds2fPVo4cOdSwYcNHOr7Q0FC99NJL8vHxUWBgoLp27arr16/bzLFYLHr99dc1Z84clShRQq6urpo/f74k6ejRo+rQoYMCAgLk6uqqEiVKaObMmTbbx8XFady4cSpWrJjc3d2VNWtWlS1bVtOmTXuoeqKiojRs2DAVKFBALi4uyp07t/r27ZvkcmL3OnfunF544QVlyZJFPj4+at++vS5cuJDCdy15S5Ys0dNPP62goCDrmLe3t9q2baulS5cqJiYm2W0dHR3l5+eXaLxq1aqSpJCQEOvYhg0bFBgYqEqVKtnMbdGihSIiIrRixQqb8U6dOunIkSNau3btQx0XAAAPIzo6WuPGjVPx4sXl6uqq7Nmz69VXX9WlS5ds5q1Zs0b16tWTn5+f3N3dlS9fPrVr106RkZEKDg62XoUxZswY63IcD1ria/bs2apSpcp9r3a1x7Fjx9SsWTN5eXkpb968GjRokG7fvm19PmEJkcmTJ2vcuHEqUKCAXF1drZ+527dv17PPPitfX1+5ubmpQoUKWrx4sc1rREZGavDgwSpQoIDc3Nzk6+urypUr69tvv01xPZJ05coV9enTR7lz55aLi4sKFiyo4cOHJ5qXlEOHDqlJkyby8PCQv7+/evXqpRs3bjzMW5dITEyMfvvtN7Vr107e3t7W8aCgINWvX19Lliy57/aenp7y9PRMNJ5cr1SuXDnlzp3bOubo6KimTZsqJCREW7dutdlHp06dtGrVKh0/fvyhjg0AgPuZOHGiLBaLZs+eLScn2wWHnJycNGvWLFksFr333nuPtM2jmjdvnmJiYtS+fftH2s+NGzfUu3dv+fv7y8/PT23bttW5c+ds5iScF/vpp59UoUIFubm5Wa/cuHDhgl577TXlyZNHLi4uKlCggMaMGZPonMrs2bNVrlw5eXl5KUuWLCpevLjeeeedh6onLi5OkydPtvatAQEBeuWVV3TmzJkHHm94eLh69OghPz8/eXl5qUmTJjpy5EhK37ZkLVmyRMWKFVONGjWsY05OTnr55Ze1detWnT179r7bBwQEJBqrVKmSHB0dE/VPFotFTZs2tZnbokULxcXFJerVOnbsqPDwcH333XcPc1jIYFgqDaZ0/vx5vfzyyxoyZIgmTJggB4f4jPHo0aNq1qyZBgwYIE9PTx06dEiTJk3S1q1bE12KmpQ9e/Zo0KBBevvttxUYGKjPP/9c3bp1U+HChVWnTp37bvv777+rTp061loeVrt27dS+fXt169ZN+/bt07BhwyQpUYD0888/a/369Ro5cqRy5MihgIAAHThwQDVr1lS+fPn04YcfKkeOHPrjjz/Uv39/Xb58WaNGjZIkTZ48WaNHj9b//vc/1alTR3fu3NGhQ4eSDFoeVI9hGGrdurVWr16tYcOGqXbt2tq7d69GjRqlTZs2adOmTckucXLr1i0988wzOnfunCZOnKiiRYvq999/T7IhMQwj0fqdyUlooG7duqXjx4+rTZs2ieaULVtWt27d0okTJ1S0aFG79psg4c9SqVKlrGPR0dFJHmfC2N69e/Xiiy9axytVqiQvLy/9/vvvLAECAHgs4uLi1KpVK61fv15DhgxRzZo1derUKY0aNUr16tWzLgEaHBys5s2bq3bt2vryyy+VNWtWnT17VitWrFB0dLRy5sypFStWqEmTJurWrZu6d+8uSfddUis6OlqrVq1Sv379HukY7ty5o2effVbdunXToEGD9Pfff2vs2LHy8fHRyJEjbeZOnz5dRYsW1QcffCBvb28VKVJEa9euVZMmTVStWjXNmTNHPj4++u6779S+fXtFRkZaw6eBAwdqwYIFGjdunCpUqKCIiAj9+++/CgsLS3E9UVFRql+/vo4fP64xY8aobNmyWr9+vSZOnKjdu3fr999/T/Z4Q0NDVbduXTk7O2vWrFkKDAzUwoULEy3bIsX/97Xn/nkWi0WOjo6S4u/PeOvWLZUtWzbRvLJly2rlypWKioqSm5vbA/d7t+R6JV9f30Rz7+6Vqlevbh2vV6+eDMPQsmXLHvnPDQAAd4uNjdXatWtVuXJl5cmTJ8k5efPmVaVKlbRmzRrruYiUbpPwefsofv/9d1WoUEFZs2Z9pP10795dzZs31zfffKOQkBC99dZbevnllxOdK9u5c6cOHjyo//3vfypQoIA8PT114cIFVa1aVQ4ODho5cqQKFSqkTZs2ady4cQoODtbcuXMlSd9995369Omjfv366YMPPpCDg4OOHTumAwcOPFQ9vXv31qeffqrXX39dLVq0UHBwsEaMGKF169Zp586d8vf3T/JYE85Tbdy4USNHjlSVKlW0YcOGROFHwtyUnmuSpH///Ve1a9dONCehp9q/f7/Nl1Xs8ddffyk2NjZR/+Tg4CBnZ2ebuXf3T3fLkSOHihcvrt9//936JXdkYul6vQ+eeEldRlq3bl1DkrF69er7bhsXF2fcuXPH+OuvvwxJxp49e6zPJSwDdregoCDDzc3NOHXqlHXs1q1bhq+vr/Haa6/d97VCQ0MNScZ7771333n2LJU2efJkm/E+ffoYbm5uNktqSTJ8fHyMK1eu2Mxt3LixkSdPHpulLgwjflkuNzc36/wWLVoY5cuXv2+t9tazYsWKJOctWrTIkGR8+umn1rF7l0qbPXu2Icn45ZdfbLbt0aNHoqXSEi6ntecnwdmzZw1JxsSJExMd3zfffJPoslZ7nDlzxggMDDQqV65ss6THgAEDDAcHB5s/P4ZhGJ06dTIkGT179ky0r1q1ahnVqlVL0esDAGCve/uo5JZaSFiWYdasWYZhGMYPP/xgSDJ2796d7L5TulTali1bDEnGd999d995esBSaZKMxYsX24w3a9bMKFasmPVxwpKrhQoVMqKjo23mFi9e3KhQoUKi5U1atGhh5MyZ0/rZXrp0aaN169b3rdXeeubMmZPkvEmTJhmSjD///NM6du9SaUOHDjUsFkui/xYNGzZMtFRaQu/2oJ+7lxLZsGGDIcn49ttvEx3fhAkTDEnGuXPn7vs+3GvPnj2Gu7u70aZNG5vx1q1bG1mzZjVu3LhhM167dm1DkjFhwoRE+8qdO7fRvn37FL0+AAAPcuHCBUOS8eKLL953Xvv27Q1JRmho6ENtc6+HWSrNw8PD6NWr133n2LNUWp8+fWzGJ0+ebEgyzp8/bx0LCgoyHB0djcOHD9vMfe211wwvL69E5zs++OADQ5Kxf/9+wzDizz1lzZr1vrXaW8/BgweTnJfQU77zzjvWsXuXSlu+fLkhyZg2bZrNtuPHj0/UvyYsP2vPz8mTJ63bOTs7J3mucOPGjYYk45tvvrnv+3Cv8PBw6/Kxd/dKU6dOTbT8rGEYxogRIwxJRqNGjRLtq2PHjkZgYGCKXh8ZE0ulwZSyZcuW5FUKJ06cUIcOHZQjRw45OjrK2dnZekOwgwcPPnC/5cuXV758+ayP3dzcVLRoUZ06deq+2yVczpnUpY4p9eyzz9o8Llu2rKKionTx4kWb8aefflrZsmWzPo6KitLq1avVpk0beXh4KCYmxvrTrFkzRUVFafPmzZLil6/Ys2eP+vTpoz/++EPh4eEPXU/CtyHuXR7l+eefl6enp1avXp3svteuXassWbIkeo0OHTokmtuyZUtt27bNrp973bssnr3P3evKlStq1qyZDMPQokWLbK6u6tmzp5ydndWxY0ft379fYWFhmjlzphYtWiRJSV6JFRAQ8MDLZwEASC2//fabsmbNqpYtW9r0CeXLl1eOHDm0bt06SfH9kIuLi3r27Kn58+frxIkTj/zaqdUrWSwWtWzZ0masbNmySfZqzz77rM23E48dO6ZDhw6pY8eOkpSoVzp//rwOHz4sKb5XWr58ud5++22tW7dOt27deuh61qxZI09PTz333HM28xJ6pwf1SqVKlVK5cuVsxpPqlXr27GlXn7R06dIkjyM5KemVgoOD1aJFC+XNm1eff/65zXOvv/66rl+/rldeeUUnTpxQaGioRowYoY0bN0qiVwIAmI9hGJJS9ln4MNsk59q1a4qMjEyzc02SEvVQZcuWTbQqyW+//ab69esrV65cNv1TwhUsf/31l6T4/unatWt66aWX9Msvv+jy5csPXU/CErf3nmuqWrWqSpQo8cD+SZK150uQVP9UqVIlu8815cqVy2bb1OqfoqKi1LZtW506dUrff/+9vLy8rM917NhRvr6+6tmzp7Zs2aJr167p22+/1fTp0yUl3z9dvHjxvrcGQObAUmkwpZw5cyYau3nzpmrXri03NzeNGzdORYsWlYeHh0JCQtS2bdtk/8F9t6TuZ+Lq6vrAbROeT+kyEvbUkHD547013PsehIWFKSYmRjNmzNCMGTOS3HfCh+awYcPk6empr7/+WnPmzJGjo6Pq1KmjSZMmqXLlyimqJywsTE5OTomWR7FYLMqRI0eiJUXurTkwMDDReI4cORKN+fr6ysfHJ9l9JSVbtmyyWCxJ1nDlyhXrfu1x9epVNWzYUGfPntWaNWtUsGBBm+dLlCihJUuW6LXXXlPp0qUlxV8m/eGHH6pfv35JXiLr5uZm159LAABSQ2hoqK5duyYXF5ckn0/oEwoVKqRVq1Zp8uTJ6tu3ryIiIlSwYEH1799fb7zxxkO9dmr1Sh4eHon24erqqqioqERz7+2VQkNDJUmDBw/W4MGDk9x/wnswffp05cmTR4sWLdKkSZPk5uamxo0b6/3331eRIkVSVE9YWJhy5MiR6B/wAQEBcnJyemCvVKBAgUTjSfVKCUvnPsjddST0ecn1ShaLxe6lWU6dOqX69evLyclJq1evTtRjNWjQQHPnztWgQYNUqFAhSVLJkiU1duxYvfPOO/RKAIDHxt/fXx4eHjp58uR95wUHB8vDw8P6mfYw2zwKM5xrkuJ7qKVLlyZaritBQv/UqVMnxcTE6LPPPlO7du0UFxenKlWqaNy4cYnuB23Puabk6smVK9d9v2CdcJ7q3tdIqn/y8vJS+fLlk93X3e5eKs3Pzy9VzjXdvn1bbdq00T///KPffvtN1apVs3ne399fK1asUOfOna1Lyvr5+WnKlCnq1q1bsv2TYRiKioqyCYGQ+RDcwJSSSq7XrFmjc+fOad26ddarbCQled+W1JawrmbCX9CPw73vQbZs2eTo6KhOnTqpb9++SW6T8A9/JycnDRw4UAMHDtS1a9e0atUqvfPOO2rcuLFCQkLk4eFhdx1+fn6KiYnRpUuXbMIbwzB04cIFValS5b7b3nsjWin+pnf3mj9/vl599VW7akr4hou7u7sKFy6sffv2JZqzb98+ubu7JwpgknL16lU988wzOnnypFavXp3kOvCS1LRpU506dUrHjh1TTEyMihYtar3ZcVL3SLpy5Uqya7ICAJDaEm7+umLFiiSfz5Ili/X/165dW7Vr11ZsbKy2b9+uGTNmaMCAAQoMDLS5Z1tKXltK314poYZhw4apbdu2SW5TrFgxSZKnp6fGjBmjMWPGKDQ01Hr1TcuWLXXo0KEU1eHn56ctW7bIMAybmhK+CXm/XsDPzy/JviipsXfffdd6A+H7CQoKUnBwsKT4kM7d3T3ZXqlw4cJ2nSw6deqU9Z4069atS3bt/86dO6tjx446evSonJ2dVbhwYeuNnpNaJ/7KlSvKnz//A18fAICUcHR0VP369bVixQqdOXMmyc+tM2fOaMeOHWratKn1XjUPs82jSAge0rN/kuJ7qLJly2r8+PFJbnP3lSivvvqqXn31VUVEROjvv//WqFGj1KJFCx05ckRBQUF215Fw7OfPn0/0Xp87d+6B/VNMTIzCwsJswpuk+qe//vpL9evXt6umkydPWvuSMmXKJNs/SbJ+ofd+bt++rdatW2vt2rX65Zdf1KBBgyTnValSRQcOHFBwcLAiIiJUpEgR7dixQ1Ly55pcXV0JbZ4ABDfIMBI+XO69Qfwnn3yS5q8dFBQkd3d3HT9+PM1fKzkeHh6qX7++du3apbJlyyb7bdp7Zc2aVc8995zOnj2rAQMGKDg4WCVLlrT7dRs0aKDJkyfr66+/1ptvvmkd//HHHxUREZHsB48U3/QsXrxYv/76q81lst98802iuQlLpaVUmzZtNHXqVIWEhChv3rySpBs3buinn37Ss88+a/ONiaQkhDYnTpzQypUrVaFChfvOt1gs1m/iRkdHa9q0aSpfvnySH6YnTpyw68McAIDU0KJFC3333XeKjY1N9G2+5Dg6OqpatWoqXry4Fi5cqJ07d+rFF19M9luaySlRooQkpWuvVKxYMRUpUkR79uzRhAkT7N4uMDBQXbp00Z49ezR16lRFRkam6EsuDRo00OLFi/Xzzz+rTZs21vGvvvrK+nxy6tevr8mTJ2vPnj02y6Ul1Sv17NlTLVq0eGA9d/fKTk5OatmypX766SdNnjzZGt6dPn1aa9eutentknP69GnVq1dPsbGxWrdu3QNPyjg5OVn/PFy/fl2ffvqpWrVqlWi7mJgYhYSEqFmzZg+sAQCAlBo2bJiWL1+uPn36aMmSJTZBS2xsrHr37i3DMDRs2LBH2uZRuLi4qGDBgunaP0nxPeSyZctUqFAhmyX778fT01NNmzZVdHS0Wrdurf3796couEm4PcLXX39t84Xgbdu26eDBgxo+fHiy2yb0TwsXLlT//v2t40n1TwlLpdnj7oCqTZs26tOnj7Zs2WLtq2NiYvT111+rWrVqiZZVu1fClTZr1qzRTz/9pMaNGz/w9RNCI8Mw9OGHHypXrlx6/vnnE807ceJEis7rIeMiuEGGUbNmTWXLlk29evXSqFGj5OzsrIULF2rPnj1p/touLi6qUaOG9R4y6WXatGl66qmnVLt2bfXu3Vv58+fXjRs3dOzYMS1dutR6P5qWLVuqdOnSqly5srJnz65Tp05p6tSpCgoKsln+wx4NGzZU48aNNXToUIWHh6tWrVrau3evRo0apQoVKqhTp07JbvvKK6/oo48+0iuvvKLx48erSJEiWrZsmf74449Ec/38/JJcyu5BBg8erAULFqh58+Z699135erqqvfee09RUVEaPXq0zdzChQtLil8DX4o/GdW4cWPt2rVLU6dOVUxMjM1/4+zZs1uX+pCkfv36qV69evLz89OJEyc0ffp0nTlzxrre693CwsJ09OhR9evXL8XHBADAw3jxxRe1cOFCNWvWTG+88YaqVq0qZ2dnnTlzRmvXrlWrVq3Upk0bzZkzR2vWrFHz5s2VL18+RUVF6csvv5QkPfPMM5Lir84JCgqyfjvQ19dX/v7+yV4dkSdPHhUsWFCbN2+2+Qf04/bJJ5+oadOmaty4sbp06aLcuXPrypUrOnjwoHbu3Knvv/9eklStWjW1aNFCZcuWVbZs2XTw4EEtWLBANWrUSFFoI8X3OzNnzlTnzp0VHBysMmXK6J9//tGECRPUrFkz63ualAEDBujLL79U8+bNNW7cOAUGBmrhwoVJXvWTK1euB54kSMqYMWNUpUoVtWjRQm+//baioqI0cuRI+fv7a9CgQTZznZycVLduXeu68hcvXlT9+vV1/vx5ffHFF7p48aLNfRnz5Mlj/ZbsxYsX9eGHH6pWrVrKkiWLDh06pMmTJ8vBwUEzZ85MVNfevXsVGRlp97dgAQBIiVq1amnq1KkaMGCAnnrqKb3++uvKly+fTp8+rZkzZ2rLli2aOnWqatas+UjbPKp69epp+fLlqba/h/Huu+9q5cqVqlmzpvr3769ixYopKipKwcHBWrZsmebMmaM8efKoR48ecnd3V61atZQzZ05duHBBEydOlI+Pz31XY0lKsWLF1LNnT82YMUMODg5q2rSpgoODNWLECOXNm/e+Xy5p1KiR6tSpoyFDhigiIkKVK1fWhg0btGDBgkRzs2TJkuiWAfbo2rWrZs6cqeeff17vvfeeAgICNGvWLB0+fFirVq2ymdugQQP99ddfNvecee6557R8+XINHz5cfn5+NueavL29bYKX4cOHq0yZMsqZM6dOnz6tL7/8Ulu2bNHvv/8ud3d3m9eKi4vT1q1b1a1btxQfEzIgA0hHnTt3Njw9PW3G6tata5QqVSrJ+Rs3bjRq1KhheHh4GNmzZze6d+9u7Ny505BkzJ071zpv1KhRxr1/vIOCgozmzZsn2mfdunWNunXrPrDWL774wnB0dDTOnTuX7JzkXuPumi5dumQzPnfuXEOScfLkSeuYJKNv375J7ufkyZNG165djdy5cxvOzs5G9uzZjZo1axrjxo2zzvnwww+NmjVrGv7+/oaLi4uRL18+o1u3bkZwcPBD1XPr1i1j6NChRlBQkOHs7GzkzJnT6N27t3H16lWbbZN6L8+cOWO0a9fO8PLyMrJkyWK0a9fO2LhxY6L/Zo/i2LFjRuvWrQ1vb2/Dw8PDaNCggbFjx45E84KCgoygoCDr45MnTxqSkv3p3LmzzfatWrUycubMaTg7Oxs5cuQwunTpYvOe3u2LL74wnJ2djQsXLqTKMQIAcK+k+qg7d+4YH3zwgVGuXDnDzc3N8PLyMooXL2689tprxtGjRw3DMIxNmzYZbdq0MYKCggxXV1fDz8/PqFu3rvHrr7/a7GvVqlVGhQoVDFdX1yQ/F+81YsQII1u2bEZUVFSyc+7X4yR1PIaRuK9L+Px+//33k9zPnj17jBdeeMEICAiwfmY//fTTxpw5c6xz3n77baNy5cpGtmzZDFdXV6NgwYLGm2++aVy+fDnF9RiGYYSFhRm9evUycubMaTg5ORlBQUHGsGHDEr0XQUFBid7HAwcOGA0bNjTc3NwMX19fo1u3bsYvv/xiSDLWrl2b5DGm1Pbt240GDRoYHh4ehre3t9G6dWvj2LFjieZJsunl1q5de99eadSoUTbvQaNGjYzs2bMbzs7ORr58+Yx+/fol6jUTjBgxwvD397/vnxcAAB7Vpk2bjOeee84IDAw0nJycjICAAKNt27bGxo0bU3Ubw0i+d7if1atXG5KMrVu3JjvnfufJEs7hbNu2zWY84TP87l7ifuesLl26ZPTv398oUKCA4ezsbPj6+hqVKlUyhg8fbty8edMwDMOYP3++Ub9+fSMwMNBwcXExcuXKZbzwwgvG3r17H6qe2NhYY9KkSUbRokUNZ2dnw9/f33j55ZeNkJAQm207d+5scy7HMAzj2rVrRteuXY2sWbMaHh4eRsOGDY1Dhw4l6k8exYULF4xXXnnF8PX1Ndzc3Izq1asbK1euTDSvbt26iXrD+/VP95436927t5EvXz7DxcXF8Pf3N9q1a2fznt4t4c9LUue8kPlYDOP/bxYB4L6ioqKUL18+DRo0SEOHDk3vcmBytWvXVr58+bRw4cL0LgUAgMfi3LlzKlCggL766iu1b98+vcuBicXGxqpw4cLq0KFDsuvpAwDwpChbtqxq1aql2bNnp3cpMLlOnTrpxIkT2rBhQ3qXgseA4AZIgdmzZ2v06NE6ceKEPD0907scmNTff/+tRo0a6cCBAypYsGB6lwMAwGMzdOhQLV++XLt375aDg0N6lwOTmj9/vgYPHqyjR48qa9as6V0OAADpasWKFWrTpo2OHj1qXYIUuNfx48dVokQJrVmzRk899VR6l4PHgHvcACnQs2dPXbt2TSdOnFCZMmXSuxyYVFhYmL766itCGwDAE+d///ufPDw8dPbsWeXNmze9y4FJxcXFaeHChYQ2AABIatKkid5//32dPHmS4AbJOn36tD7++GNCmycIV9wAAAAAAAAAAACYBOsXAAAAAAAAAAAAmATBDQAAAAAAAAAAgElk6HvcxMXF6dy5c8qSJYssFkt6lwMAyAQMw9CNGzeUK1cubqyNTIfeCQCQmuibkNnROwEAUlNKeqcMHdycO3eOm54CANJESEgIN4ZEpkPvBABIC/RNyKzonQAAacGe3ilDBzdZsmSRJLmU7CyLo0s6VwMAyAyM2GhFH5hv/YwBMhNr71R3pCxObulcDWByF0+mdwWA6dE3IbPjvBOQAk7O6V0BYHpGbLSi935uV++UoYObhMtULY4ufIACAFIVSyEgM7L2Tk5uBDfAg/DvC8Bu9E3IrDjvBKQAvyOA3ezpnViEFgAAAAAAAAAAwCQIbgAAAAAAAAAAAEyC4AYAAAAAAAAAAMAkCG4AAAAAAAAAAABMguAGAAAAAAAAAADAJAhuAAAAAAAAAAAATILgBgAAAAAAAAAAwCQIbgAAAAAAAAAAAEyC4AYAAAAAAAAAAMAkCG4AAAAAAAAAAABMguAGAAAAAAAAAADAJAhuAAAAAAAAAAAATILgBgAAAAAAAAAAwCQIbgAAAAAAAAAAAEyC4AYAAAAAAAAAAMAkCG4AAAAAAAAAAABMguAGAAAAAAAAAADAJAhuAAAAAAAAAAAATILgBgAAAAAAAAAAwCQIbgAAAAAAAAAAAEyC4AYAAAAAAAAAAMAkCG4AAAAAAAAAAABMguAGAAAAAAAAAADAJAhuAAAAAAAAAAAATILgBgAAAAAAAAAAwCQIbgAAAAAAAAAAAEyC4AYAAAAAAAAAAMAkCG4AAAAAAAAAAABMguAGAAAAAAAAAADAJAhuAAAAAAAAAAAATILgBgAAAAAAAAAAwCQIbgAAAAAAAAAAAEyC4AYAAAAAAAAAAMAkCG4AAAAAAAAAAABMguAGAAAAAAAAAADAJAhuAAAAAAAAAAAATILgBgAAAAAAAAAAwCQIbgAAAAAAAAAAAEyC4AYAAAAAAAAAAMAkCG4AAAAAAAAAAABMguAGAAAAAAAAAADAJAhuAAAAAAAAAAAATILgBgAAAAAAAAAAwCQIbgAAAAAAAAAAAEyC4AYAAAAAAAAAAMAkCG4AAAAAAAAAAABMguAGAAAAAAAAAADAJAhuAAAAAAAAAAAATILgBgAAAAAAAAAAwCQIbgAAAAAAAAAAAEyC4AYAAAAAAAAAAMAkCG4AAAAAAAAAAABMguAGAAAAAAAAAADAJAhuAAAAAAAAAAAATILgBgAAAAAAAAAAwCQIbgAAAAAAAAAAAEyC4AYAAAAAAAAAAMAkCG4AAAAAAAAAAABMguAGAAAAAAAAAADAJAhuAAAAAAAAAAAATILgBgAAAAAAAAAAwCQIbgAAAAAAAAAAAEyC4AYAAAAAAAAAAMAkCG4AAAAAAAAAAABMguAGAAAAAAAAAADAJAhuAAAAAAAAAAAATILgBgAAAAAAAAAAwCQIbgAAAAAAAAAAAEyC4AYAAAAAAAAAAMAkCG4AAAAAAAAAAABMguAGAAAAAAAAAADAJAhuAAAAAAAAAAAATILgBgAAAAAAAAAAwCQIbgAAAAAAAAAAAEyC4AYAAAAAAAAAAMAkCG4AAAAAAAAAAABMguAGAAAAAAAAAADAJAhuAAAAAAAAAAAATILgBgAAAAAAAAAAwCQIbgAAAAAAAAAAAEyC4AYAAAAAAAAAAMAkCG4AAAAAAAAAAABMguAGAAAAAAAAAADAJAhuAAAAAAAAAAAATILgBgAAAAAAAAAAwCQIbgAAAAAAAAAAAEyC4AYAAAAAAAAAAMAkCG4AAAAAAAAAAABMguAGAAAAAAAAAADAJAhuAAAAAAAAAAAATILgBgAAAAAAAAAAwCQIbgAAAAAAAAAAAEyC4AYAAAAAAAAAAMAknNK7AJhTzQqF1K/TMypXPJ9yZvdRx8Gfatlfe63Pzxz1sjq0qG6zzbZ9J9Wo64dJ7u/7ab31TM1SifZTtlgeje7XWhVL5lNsrKFf1+7W/z76URG3otPmwIBU9rh+VwrlC9C7/VurWrmCcnZy1MHj5zRu9m/6Z8fRtDkwAIDdhnaorrc71LAZC70aoeKdPpUkZc/qodFdnlL9CkHy8XTVxv1nNfSTtTpx7lqS+/t+dGs9U7mAOo77Vcs2H7eOly0UoNFdnlLFIoGKjTP068Zj+t/nfyki6k6aHRuQ2nJm99Hofq30TI1ScnNz1vHTF9Vv7ELtORSSaO5Hw15Ul7ZPadiUHzTn23VJ7i+53skni7smDX5eTeuUkSQt/3ufhrz/vcJv3kqT4wIA2G9oj2Z6u2czm7HQsHAVb/KOzZzObWopaxZ37dh/Sm9NXqRDJy5Yn1865w09VamIzT5++nOHug2fazPWqFYpvdW9qUoVzqXIqGht3HVMrwz5PA2OCkhbb77SQCN7N9fsRX/rnak/S5KyZ/PS6L4tVL9qMflkcdfG3Sc09MOfdOLMZet2Ab5Z9O7rLVWvalF5ebjq2OlLmjJ/lX5d+1/f9M3kripTJLf8s3np2o1b+mvbEY2e9ZsuXA5/3IeJu6R7cDNr1iy9//77On/+vEqVKqWpU6eqdu3a6V3WE8/D3VX/HjmrhUs3a8HkHknOWbVxv/q++7X1cfSd2CTn9X6pvgwj8XgOfx/9PLOflqzcqSHvL1YWTzdNHNhOM0d1Upe3v0iV4wDS2uP4XZGkRR/10vHTF9Wq93Tdun1HvV+qr+8+6qWKbUbrYtiNRz4OABkHvZM5HTx1Wa2H/2h9HBv331/oX/+vpWJi4tRx3K+6ERmtvq0r6udx7VS993xF3o6x2U/vVhWU1EdBDl9P/TyunZasP6whc9Yqi4eLJvaop5lvNlaXib+l1WEBqconi7tWfD5Q63cc1fNvzNKlqzdUII+/rt9IHKY0q1tWlUrn17mL15Ld3/16p8/HdVGugGx6rv8sSdLUd17SJ+++opcGfpIahwIgA6F3MqeDx8+pdd8Z1sexsf/9hf7GK8+oT4f66vvu1zp++qIGd22inz7up6rPvaubkbet8+Yt2aCJn/zXB0Xd82WWlvXLa9rwlzR21lL9vf2ILBapZKFcaXhUQNqoUCKvOreqrn+PnrMZ/3pSV8XExKrj0C91IyJKfV+qp5+n91L1DpMVGRX/pfg5ozrI28tdHYZ8qbBrN/Vco4r6cuwrqt/1I+07claStH7nMU2Zv1qhYeHKmd1HY/u11PwJndW454xEteDxSdel0hYtWqQBAwZo+PDh2rVrl2rXrq2mTZvq9OnT6VkWJK3aeEDj5/ym39buSXbO7egYXQy7Yf25Fh6ZaE7pIrnVt+PTen3s14mea1y7tO7ExGrw5MU6duqidh04rcGTF6tVgwoqkMc/VY8HSCuP43fF18dThfIFaOr8ldp/7JxOhFzSmI9/kae7q4oXzJmqxwPA3OidzCsmNk4Xr0Vaf8LC409EF8qVVVWL59KgWWu062iojp29qkGz18jTzVnt6ha32UfpAv7q27qSXp/6Z6L9N65SML5vmr1Gx85e1a6joRo8e41a1SqiAjl9HssxAo9qQOeGOht6Va+/+7V2HjilkPNX9Pe2Iwo+e9lmXs7sPpr81vPqOWKeYmKS/sLL/XqnovkD9UzNUuo/bqG27TupbftO6o3x36hJ7TIqHBSQJscGwJzoncwrJjbO5t/JYdduWp/r9VJ9TZn7h35bu0cHj59X79EL5OHmrOcaV7bZx62oaJt9hEdEWZ9zdHTQxEHtNHL6z5r70z86fvqijp26qF/X7H5chwikCk93F306uqPeeG+xrt3473xSobzZVbVMfg16/wftOhiiY6cvadD7P8jTw1XtGlawzqtSOr8++369dh44rVPnrujDeat0/eYtlSuWxzpn9nd/a/v+Uwq5cFVb9wVr6ldrVLlUkJwcuctKekrXd3/KlCnq1q2bunfvrhIlSmjq1KnKmzevZs+enZ5lwU5PVSqiI39M1LYfRmrq8Jfkn83L5nl3V2d9Nq6L3pq8OMkrAlycnXQnJlbGXV+Ti7od/+2I6uULpW3xwGP0qL8rV65H6NCJ82rfvKo83Fzk6OigLm2fUmhYuHYfTLysCIDMi97JvArmyqYD83to9+dd9cWQZgoKjA9TXJ0dJUlR0f9dWRMXZyg6Jk7VS/73jU93Vyd99lYzvTVnjS5eSxzwuzg76k5MnM3VBQn7rF4yd1ocEpDqmtQuo10HT2vuxK468sdE/fX1UL3SuqbNHIvFojljXtGMr1fbLIlztwf1TlXKFND1G5Hasf+UdWz7v8G6fiNSVcsWTN2DAmBq9E7mVTBvdh1YNl67fx6tL8a/qqDcfpKkoNx+yuHvozWbD1nnRt+J0YadxxL9Hf58k8o6tvI9bVw0XO++0UZeHq7W58oVy6vcgdkUZxj66+uhOrh8vL6f1lvFC+Z4PAcIpJL3B7fTnxsP6q9ttkvlu7rEL6SV6N8Zd2JVvVwB69jmvSfV5pnyyurtIYvForbPlJeLs5P+2XksydfL6u2h5xpX1NZ9wYqJjUuDI4K90i24iY6O1o4dO9SoUSOb8UaNGmnjxo3pVBXstWrjAfUcMV+t+kzXiGk/qWLJIP06u79cnP9bfW/CwHbauveklv+9L8l9rN9+WAF+3ur3cgM5OznKJ4u7RvR5VlL8MmpAZpAavyuS1Pb1j1W2aF6F/PWBLvzzkXq/VF/P9Z/JOu3AE4Teybx2HL6g3lNW6LmRP+mNGasUkM1Df3zQXtmyuOnImas6HXpdIzs/JR9PVzk7OWjAc1WUw9dTgb6e1n1M6F5XWw+e0/ItJ5J8jfV7QxSQzUP92laSs5ODfDxdNeKVWpLil1EDMoL8uf3VtV1tnQi5pHb9Zmruj//ovUHPqX2zqtY5Azo3VExsnD75bl2y+3lQ7xTo561LV24mGr905aYC/bwf+TgAZAz0Tua1Y3+weo9aoOf6zdQbE75VgJ+3/vhikLL5eFr/nr50xTaYv3jlhgLu+jv8+xXb1P1/89Sy1zR98PkKPVu/nL66a/ny/LnjV3J5u0czffDFH3rxzTm6Fn5Lv30yQFm9PR7DUQKPru0z5VWuWB69O/v3RM8dCQ7V6fNXNLJ3c/lkcZezk6MGdHpaOfy9bfqdbv/7So6Ojjr5xziF/j1ZHw19Xp3enqvgs2E2+xvdp4XOrJmok3+MU57AbOow5Ms0Pz7cX7rd4+by5cuKjY1VYGCgzXhgYKAuXEj6m1W3b9/W7dv/rWUZHs4NktLLkpU7rf//4PHz2nXgtPYufVeNniql39buUdM6ZVS7clHVffm9ZPdx6MQF9Rm9QOPebKuRfZ9VbFycPl30l0LDwhVLootMIjV+VyTpg6HtdfnqDTXrMVW3bkfrldY19d2UXmrQ+X2FhvF3IfAkoHcyr1U7gv97cCpM2w6d087Pu+qlBiU16+edemXCb5rxRkMFL+qjmNg4rdt9Wiu3n7Ru0rRqQdUul1d1+y9M9jUOnQ5Tn4/+0LjudTWy81PxfdOvuxV6NcLmfjqAmTk4WLT74GmNnbVUkrTvyBkVL5hTXdvV1qJlW1WueF699mI91Xt5UrL7sLd3MpK4W5TFIpur/QFkbvRO5rVq44H/HhyXtu09qZ0/j9ZLzatp+7/xPdK9f19bLLZ/t3/183/h28Hj53U85KLWLRiqssXyaO/hM3JwsEiSPpz7h5au3S1J6vvu19r/+1i1blBB85ZsSKOjA1JH7oCsmvhmG7V74xPdjo5J9HxMbJxeGTZPM95pr+A/xysmJlbrth/Vyo0HbeYNf62psmZxV6t+s3XlWoSa1SmteeM7q1nvj3Xg+HnrvOkL12rB0i3KmyObhnZrpDkjO6j94M/T/DiRvHQLbhJYLBabx4ZhJBpLMHHiRI0ZM+ZxlIUUCg0LV8j5KyqUN7skqXbloiqQx1/Ba963mffVpO7atPu4WvaaJkn64Y/t+uGP7crum0WRt27LMKQ+HZ7WqXNhiV4DyAwe5nelTpWiavxUaRVoMEQ3/n/N3sGTFqte1eJ6qUU1TZ2/8rEfB4D0Q+9kfpG3Y3Qg+LIK5coqSdpz/KLq9F8obw8XOTs5Kiz8llZ++KJ2Hw2VJNUul1cFcmRV8KI+Nvv5algLbTpwVi2H/SBJ+uGvw/rhr8PKntVDkVF3ZBiG+rSuqFMXrj/W4wMeVujl8ETLnx0JvqCWT5eXJNWoUEjZs3lp39J3rc87OTlq3Btt1fvF+irXapRdvVNoWLgCfLMken3/bF66eCXx0moAMjd6J/OLjIrWgWPnVChvdv3+V/z9YwP8vG2+pJg9WxZdSmJ5zAR7DoUo+k6MCuUL0N7DZ3Thcnx/dPjEfyemo+/EKPhsmPLk8E2jIwFST7nieRTgm0Vr575pHXNyclTN8gXVo10tBdYdoj2Hz6hO5w/l7ekmZ2dHhV2L0MrP39DuQ/HL6ufP7aeez9dWjQ6TdOhk/L89/j12TjXKF1T3drU0cPIP1n1fuR6hK9cjdDzkko4Eh2r/r6NUpXSQtv17Skgf6Rbc+Pv7y9HRMdG3HC5evJjo2xAJhg0bpoEDB1ofh4eHK2/evGlaJ+yTzcdTuQOz6cLl+A/VqfP/1IJfbC893vjdcL3z0Y9asf7fRNsnXALbsWV1RUXf0dothxLNATKDh/ld8XBzkSTFxdleiRZnGHJI5h8cADIfeqeMw8XJUUXz+mrT/rM24+GR0ZKkgrmyqkLhQE34Ov7v/6nfb9OCP237o40zX9E7n/+lFVsTL5126f/vgdOxYSlF3YnV2t3cYBkZw5Y9J1QkKMBmrFC+AJ25cEWStGjZNv219bDN8z9M76vFy7dq4dLNkuzrnbbtOymfLB6qWDJIOw/En2yoVCpIPlk8tHVv0ssRAsh86J0yDhdnJxXNH6hNu4/p1NkwXbh8XfWrFde+I2ckSc5OjqpVsbBGz/gl2X2UKJRTLs5OCv3/wGbPoRBF3b6jwkGB2rwn/u9+J0cH5cvpq5D//9wBzOzv7UdVs+Nkm7GPh7+oo6cuatrXaxR311X34f//Jd+CefxVoXheTfh0uaS7zyfZXsEWGxuXbIAt/Rd4373MPx6/dHv3XVxcVKlSJa1cuVJt2rSxjq9cuVKtWrVKchtXV1e5urom+RxSl6e7iwr8/xUBkhSUy0+li+bWteuRuhoeoaE9m2vpmt26cPm68uX008i+LRV27aZ+Xxf/zYiLYTeSvFHomQtXdfquq2l6PF9HW/aeUMStaNWvVlxj+rfWmI9/4b4dyDAex+/K1r0nde1GpGaNfkXvf75ct27fUefWNRWUy09/btj/eA4UQLqjdzKvd7vW1oqtJ3Tm0g1l9/HQ4BerKYuHi75bHb8MSKtaRXQ5/JbOXLyhkvn99F7Pevp983Gt3RUfuFy8FqmL/x/G3O3MpRs6HfrfN017tCinLQfPx/dNFYI05tXaGjP/H4VH3E60LWBGs75doz++GKSBXRppyaqdqlQqvzq3qaU3J3wrSbp6PUJXr0fYbBMTE6vQsHAdO3VRkn2905HgUK3auF/Thr+kNyd+J0ma+s5LWrF+n3U/ADI/eifzeveNNlqxfp/OXLiq7Nm8NLhbE2XxdNN3v22RJM35dq0GvtpIx0Mu6kTIJQ3s0liRUXf0wx/bJcXfv+b5ppW1csMBhV27qeIFcmjsgLbacyjEGtLciIjS3J/+0ds9m+ls6FWFXLiifi8/I0n6edXOpAsDTORm5G0dvOdK5cioaF0Jj7SOt3q6nC5fvakzoVdVslBOvfdmG/3+979au/WIpPie6HjIJX009HmN+HiprlyPUPM6pVW/alG9OPgLSVLFkvlUqWQ+bdpzQtdv3FJQLj+906OJTpy5rG3/Bj/WY4atdI3NBg4cqE6dOqly5cqqUaOGPv30U50+fVq9evVKz7IgqXyJIP32yRvWxxMGtpMkffPbZg16b5FKFsqlF5tVlU8Wd4VeDtf6HUfU9Z0vdTMyZScOKpYK0ts9m8vTw0VHg0M1cMK3WrR8W6oeC5CWHsfvypXrEXqu/yz9r3dL/TKrv5ycHHToxAV1HPyp/j169sE7AJBp0DuZU27/LPr8rWby83bX5fBb2n7ovBoN+k4hl+JPLgf6emp897rKntVDoVcj9N2aA3r/uy0pfp2KRXPo7Q415OnurKNnrmrgzNVatPbggzcETGLXgdPq9NZnGtn3Wb3VvalOnQvTO1N+1Pcrtqf6a/UYMV+TBj+nH2f0lSStWL9Pb03+PtVfB4C50TuZU+6ArPp83Kvyy+qpy1dvavu/wWrU9UOFXLgqSZr21Sq5ubrog6HtlTWLh3bsD1a7fh9b/x19JyZGdasUU6/29eXp4aKzodf054Z/Nemz5TZXFoyctkQxsXGaM+YVubk6a8f+U2rVZ7qu3+DLwsgcAv28Nb7/s8rum0Whl8P13Yrtev/L/5bTj4mN0wsDP9OoPi307fvd5OnuopNnwtRn7LdauSn+3xFRt++oRd0yert7Y3m4uSg0LFyrNx9St5ELFH0nNr0ODZIsRjrfnXHWrFmaPHmyzp8/r9KlS+ujjz5SnTp17No2PDxcPj4+ci3TQxZHlzSuFADwJDBio3V732e6fv26vL2907scIJFU6Z0aTJDFyS2NKwUyuNDj6V0BYHr0TcgIOO8EPCZO/I4AD2LE3tbtXbPs6p3SPbh5FHyAAgBSGycgkJkR3AApQHADPBB9EzI7zjsBKUBwAzxQSoIbh8dUEwAAAAAAAAAAAB6A4AYAAAAAAAAAAMAkCG4AAAAAAAAAAABMguAGAAAAAAAAAADAJAhuAAAAAAAAAAAATILgBgAAAAAAAAAAwCQIbgAAAAAAAAAAAEyC4AYAAAAAAAAAAMAkCG4AAAAAAAAAAABMguAGAAAAAAAAAADAJAhuAAAAAAAAAAAATILgBgAAAAAAAAAAwCQIbgAAAAAAAAAAAEyC4AYAAAAAAAAAAMAkCG4AAAAAAAAAAABMguAGAAAAAAAAAADAJAhuAAAAAAAAAAAATILgBgAAAAAAAAAAwCQIbgAAAAAAAAAAAEyC4AYAAAAAAAAAAMAkCG4AAAAAAAAAAABMguAGAAAAAAAAAADAJAhuAAAAAAAAAAAATILgBgAAAAAAAAAAwCQIbgAAAAAAAAAAAEyC4AYAAAAAAAAAAMAkCG4AAAAAAAAAAABMguAGAAAAAAAAAADAJAhuAAAAAAAAAAAATILgBgAAAAAAAAAAwCQIbgAAAAAAAAAAAEyC4AYAAAAAAAAAAMAkCG4AAAAAAAAAAABMguAGAAAAAAAAAADAJAhuAAAAAAAAAAAATILgBgAAAAAAAAAAwCQIbgAAAAAAAAAAAEyC4AYAAAAAAAAAAMAkCG4AAAAAAAAAAABMguAGAAAAAAAAAADAJAhuAAAAAAAAAAAATILgBgAAAAAAAAAAwCQIbgAAAAAAAAAAAEyC4AYAAAAAAAAAAMAkCG4AAAAAAAAAAABMguAGAAAAAAAAAADAJAhuAAAAAAAAAAAATILgBgAAAAAAAAAAwCQIbgAAAAAAAAAAAEyC4AYAAAAAAAAAAMAkCG4AAAAAAAAAAABMguAGAAAAAAAAAADAJAhuAAAAAAAAAAAATILgBgAAAAAAAAAAwCQIbgAAAAAAAAAAAEyC4AYAAAAAAAAAAMAkCG4AAAAAAAAAAABMguAGAAAAAAAAAADAJAhuAAAAAAAAAAAATILgBgAAAAAAAAAAwCQIbgAAAAAAAAAAAEyC4AYAAAAAAAAAAMAkCG4AAAAAAAAAAABMwsmeSdOnT7d7h/3793/oYgAAADIDeicAAAD70TsBAGDLruDmo48+smtnFouFD1AAAPDEo3cCAACwH70TAAC27ApuTp48mdZ1AAAAZBr0TgAAAPajdwIAwNZD3+MmOjpahw8fVkxMTGrWAwAAkCnROwEAANiP3gkA8CRLcXATGRmpbt26ycPDQ6VKldLp06clxa8x+t5776V6gQAAABkZvRMAAID96J0AAHiI4GbYsGHas2eP1q1bJzc3N+v4M888o0WLFqVqcQAAABkdvRMAAID96J0AALDzHjd3+/nnn7Vo0SJVr15dFovFOl6yZEkdP348VYsDAADI6OidAAAA7EfvBADAQ1xxc+nSJQUEBCQaj4iIsPlABQAAAL0TAABAStA7AQDwEMFNlSpV9Pvvv1sfJ3xofvbZZ6pRo0bqVQYAAJAJ0DsBAADYj94JAICHWCpt4sSJatKkiQ4cOKCYmBhNmzZN+/fv16ZNm/TXX3+lRY0AAAAZFr0TAACA/eidAAB4iCtuatasqQ0bNigyMlKFChXSn3/+qcDAQG3atEmVKlVKixoBAAAyLHonAAAA+9E7AQDwEFfcSFKZMmU0f/781K4FAAAgU6J3AgAAsB+9EwDgSfdQwU1sbKyWLFmigwcPymKxqESJEmrVqpWcnB5qdwAAAJkavRMAAID96J0AAE+6FH/i/fvvv2rVqpUuXLigYsWKSZKOHDmi7Nmz69dff1WZMmVSvUgAAICMit4JAADAfvROAAA8xD1uunfvrlKlSunMmTPauXOndu7cqZCQEJUtW1Y9e/ZMixoBAAAyLHonAAAA+9E7AQDwEFfc7NmzR9u3b1e2bNmsY9myZdP48eNVpUqVVC0OAAAgo6N3AgAAsB+9EwAAD3HFTbFixRQaGppo/OLFiypcuHCqFAUAAJBZ0DsBAADYj94JAAA7g5vw8HDrz4QJE9S/f3/98MMPOnPmjM6cOaMffvhBAwYM0KRJk9K6XgAAANOjdwIAALAfvRMAALbsWiota9asslgs1seGYeiFF16wjhmGIUlq2bKlYmNj06BMAACAjIPeCQAAwH70TgAA2LIruFm7dm1a1wEAAJBp0DsBAADYj94JAABbdgU3devWTes6AAAAMg16JwAAAPvROwEAYMuu4CYpkZGROn36tKKjo23Gy5Yt+8hFAQAAZDb0TgAAAPajdwIAPMlSHNxcunRJr776qpYvX57k86w1CgAA8B96JwAAAPvROwEAIDmkdIMBAwbo6tWr2rx5s9zd3bVixQrNnz9fRYoU0a+//poWNQIAAGRY9E4AAAD2o3cCAOAhrrhZs2aNfvnlF1WpUkUODg4KCgpSw4YN5e3trYkTJ6p58+ZpUScAAECGRO8EAABgP3onAAAe4oqbiIgIBQQESJJ8fX116dIlSVKZMmW0c+fO1K0OAAAgg6N3AgAAsB+9EwAADxHcFCtWTIcPH5YklS9fXp988onOnj2rOXPmKGfOnKleIAAAQEZG7wQAAGA/eicAAB5iqbQBAwbo/PnzkqRRo0apcePGWrhwoVxcXDRv3rzUrg8AACBDo3cCAACwH70TAAAPEdx07NjR+v8rVKig4OBgHTp0SPny5ZO/v3+qFgcAAJDR0TsBAADYj94JAICHCG7u5eHhoYoVK6ZGLQAAAJkevRMAAID96J0AAE8iu4KbgQMH2r3DKVOmPHQxAAAAmQG9EwAAgP3onQAAsGVXcLNr1y67dmaxWB6pGAAAgMyA3gkAAMB+9E4AANiyGIZhpHcRDys8PFw+Pj4KDbsub2/v9C4HMLWSQ5aldwlAhhB3O1KnZj2v69f5bEHmQ+8E2O/pKX+ndwmA6cVERWjbqGb0Tci06J0A+2VrNCG9SwBMz4iJ0u31Y+3qnRweU00AAAAAAAAAAAB4AIIbAAAAAAAAAAAAkyC4AQAAAAAAAAAAMAmCGwAAAAAAAAAAAJMguAEAAAAAAAAAADCJhwpuFixYoFq1ailXrlw6deqUJGnq1Kn65ZdfUrU4AACAzIDeCQAAwH70TgCAJ12Kg5vZs2dr4MCBatasma5du6bY2FhJUtasWTV16tTUrg8AACBDo3cCAACwH70TAAAPEdzMmDFDn332mYYPHy5HR0freOXKlbVv375ULQ4AACCjo3cCAACwH70TAAAPEdycPHlSFSpUSDTu6uqqiIiIVCkKAAAgs6B3AgAAsB+9EwAADxHcFChQQLt37040vnz5cpUsWTI1agIAAMg06J0AAADsR+8EAIDklNIN3nrrLfXt21dRUVEyDENbt27Vt99+q4kTJ+rzzz9PixoBAAAyLHonAAAA+9E7AQDwEMHNq6++qpiYGA0ZMkSRkZHq0KGDcufOrWnTpunFF19MixoBAAAyLHonAAAA+9E7AQDwEMGNJPXo0UM9evTQ5cuXFRcXp4CAgNSuCwAAINOgdwIAALAfvRMA4En3UMFNAn9//9SqAwAAINOjdwIAALAfvRMA4EmV4uCmQIECslgsyT5/4sSJRyoIAAAgM6F3AgAAsB+9EwAADxHcDBgwwObxnTt3tGvXLq1YsUJvvfVWatUFAACQKdA7AQAA2I/eCQCAhwhu3njjjSTHZ86cqe3btz9yQQAAAJkJvRMAAID96J0AAJAcUmtHTZs21Y8//phauwMAAMjU6J0AAADsR+8EAHiSpFpw88MPP8jX1ze1dgcAAJCp0TsBAADYj94JAPAkSfFSaRUqVLC5SZxhGLpw4YIuXbqkWbNmpWpxAAAAGR29EwAAgP3onQAAeIjgpnXr1jaPHRwclD17dtWrV0/FixdPrboAAAAyBXonAAAA+9E7AQCQwuAmJiZG+fPnV+PGjZUjR460qgkAACBToHcCAACwH70TAADxUnSPGycnJ/Xu3Vu3b99Oq3oAAAAyDXonAAAA+9E7AQAQL0XBjSRVq1ZNu3btSotaAAAAMh16JwAAAPvROwEA8BD3uOnTp48GDRqkM2fOqFKlSvL09LR5vmzZsqlWHAAAQEZH7wQAAGA/eicAAFIQ3HTt2lVTp05V+/btJUn9+/e3PmexWGQYhiwWi2JjY1O/SgAAgAyG3gkAAMB+9E4AAPzH7uBm/vz5eu+993Ty5Mm0rAcAACBToHcCAACwH70TAAD/sTu4MQxDkhQUFJRmxQAAAGQW9E4AAAD2o3cCAOA/DimZbLFY0qoOAACATIfeCQAAwH70TgAAxLP7ihtJKlq06AM/RK9cufJIBQEAAGQW9E4AAAD2o3cCACBeioKbMWPGyMfHJ61qAQAAyFTonQAAAOxH7wQAQLwUBTcvvviiAgIC0qoWAACATIXeCQAAwH70TgAAxLP7HjesMwoAAGA/eicAAAD70TsBAPAfu4MbwzDSsg4AAIBMhd4JAADAfvROAAD8x+6l0uLi4tKyDgAAgEyF3gkAAMB+9E4AAPzH7ituAAAAAAAAAAAAkLYIbgAAAAAAAAAAAEyC4AYAAAAAAAAAAMAkCG4AAAAAAAAAAABMguAGAAAAAAAAAADAJAhuAAAAAAAAAAAATILgBgAAAAAAAAAAwCQIbgAAAAAAAAAAAEyC4AYAAAAAAAAAAMAkCG4AAAAAAAAAAABMguAGAAAAAAAAAADAJAhuAAAAAAAAAAAATILgBgAAAAAAAAAAwCQIbgAAAAAAAAAAAEyC4AYAAAAAAAAAAMAkCG4AAAAAAAAAAABMguAGAAAAAAAAAADAJAhuAAAAAAAAAAAATILgBgAAAAAAAAAAwCQIbgAAAAAAAAAAAEyC4AYAAAAAAAAAAMAkCG4AAAAAAAAAAABMguAGAAAAAAAAAADAJAhuAAAAAAAAAAAATILgBgAAAAAAAAAAwCQIbgAAAAAAAAAAAEyC4AYAAAAAAAAAAMAkCG4AAAAAAAAAAABMguAGAAAAAAAAAADAJAhuAAAAAAAAAAAATILgBgAAAAAAAAAAwCQIbgAAAAAAAAAAAEyC4AYAAAAAAAAAAMAkCG4AAAAAAAAAAABMguAGAAAAAAAAAADAJAhuAAAAAAAAAAAATILgBgAAAAAAAAAAwCQIbgAAAAAAAAAAAEyC4AYAAAAAAAAAAMAkCG4AAAAAAAAAAABMguAGAAAAAAAAAADAJAhuAAAAAAAAAAAATILgBgAAAAAAAAAAwCQIbgAAAAAAAAAAAEyC4AYAAAAAAAAAAMAkCG4AAAAAAAAAAABMguAGAAAAAAAAAADAJAhuAAAAAAAAAAAATILgBgAAAAAAAAAAwCQIbgAAAAAAAAAAAEyC4AYAAAAAAAAAAMAkCG4AAAAAAAAAAABMguAGAAAAAAAAAADAJAhuAAAAAAAAAAAATILgBgAAAAAAAAAAwCQIbgAAAAAAAAAAAEyC4AYAAAAAAAAAAMAkCG4AAAAAAAAAAABMguAGAAAAAAAAAADAJAhuAAAAAAAAAAAATMIpvQuA+U2Z+4d+W7tHR0+Fys3VWVXLFtTo11upSP5A65yla3Zr3pJ/tPtgiK5cj9DfX7+tMsXy2OynxWtTtWHnMZuxNg0r6ssJXR/LcQBpoVKBbOpat6BK5fFRgLeb+s3fodX7QyVJTg4W9W9cVHWKByiPn7tuRsVo09HLmrL8sC6F37bu4/lqedW8fC6VzO0tLzdnVRv5p25ExST5es6ODlrUr6aK5/JW24/W69D5G4/lOAEAyduw85hmLFilPYdO68LlcH39fg81r1fO+rxhGJr02TLNX7JB127cUqVSQXp/SHuVKJTTOufkmUsaMW2JNu8+oeg7MWpQo4QmDX5eAX7eNq/1xz//6v3Pl2v/sXPycHNRzQqFteD9Ho/tWIHU9FKVvOpRu4B+3HlGM9edsI7n83VXz9oFVTaPjxwsUnBYpN797aAu3ritLG5O6lIjSJWDsil7Flddv3VHG46Hae6GYEVEx1r34eXqpH71C6lGIT9J0qbjYZq+9pgibscmqgMA8Hg9qHey5xyTPb3TtfBIDf3gey3/e58kqWmdMpr81vPyyeLxeA4USEVvvlhDI7vW1+yftuqdOaskSVf/fCfJuSM/W60Z32+RJOXPmVVjezZQ9VJ55eLsqNXbT2jozD916VqEJKlW2Xz67YOXk9zP06/P1a4j59PgaGAPrrjBA23ceUzdn6+jP78crJ8+fl0xsbFq2+9jRdz678RzRFS0qpUtpFGvt7rvvjq3rqlDyydYfz5656W0Lh9IUx4uTjp8/obG/bw/0XNuLo4qmdtHc1Yf1XPTNqj/VzuV399TM7tUtp3n7Kh/Dl/Sp2uOP/D1BjcvpovhUalWPwDg0UXeuq3SRXNr8lsvJPn8tK9WadY3azX5rRe0et5bCvDzVtvXZ+hGRPzf5xG3bqvt6zNlkUW/zO6n5Z+/qeg7sXpp4CeKi4uz7ufXNbvUa9RX6tCyutYvfFsrPh+o55pUTvI1AbMrFuilFmVz6vilmzbjuXzcNK19eZ2+EqmBi/eox4KdWrD5tKJj4n8X/Dxd5Oflojl/n1D3r3Zo8h9HVCV/Ng1uVNRmP8ObFVehAC+9/dM+vf3TPhUK8NI7TYo/tuMDACTvQb3Tg84x2ds7df/fPO07ckY/TO+jH6b30b4jZ/TayK/S5JiAtFShaE51blZB/x4PtRkv1n6azU/fD35TXJyhX9cfliR5uDnrp4kvyTCkVkMWqumbX8nF2UHfvvu8LJb4fWw9cCbRfuYv26VTF64R2qSzdL3i5u+//9b777+vHTt26Pz581qyZIlat26dniUhCT/M6GvzeObIl1Wk0TDtPhiiWhULS5JebFZVknT6XNh99+Xu5qJAf+/7zgEykvWHL2n94UtJPnczKkbdP99qMzb+lwNa3L+WcmZ10/lr8SfsFvwTLEmqUtD3vq9Vu1h21SySXQMW7FSd4gGPXjyADIfeyZwa1iqlhrVKJfmcYRia8+1aDXy1sVo+XV6SNHt0JxVt/I5++GO7Xm37lLbsOaHT58P019dD5e3lLim+3yrQYIj+3nZE9aoVV0xMrIZ9+KPe7d9anVrVtO7/7iuggYzCzdlB7zQrrg9XHtHL1fLZPNe1Vn5tPXlFn64/aR07f/2/L60Eh0Vq9NKD1sfnrkfpy3+CNaxpcTlYpDgj/oqdagV81eebXTp0If7q5A9XHtHMlyoobzZ3hVy9lcZHCMAs6J3M6X69k/Tgc0z29E6HT17Q6k0HtHLuYFUunV+SNG14BzXq+qGOBofSQyHD8HRz1qdvP6s3PlqmwR1q2Tx38WqEzeNmNYto/Z5TOnXhmiSpWqk8yhfoo7p9vtCNyGhJUt8PflfwTwNVp3x+/bUrWHdi4mz24+TooKY1iuqzX7en7YHhgdL1ipuIiAiVK1dOH3/8cXqWgRQKvxn/D6ds3im/tPT7FdtV6JmhqvHCOI2Y+pP1m6bAkyKLm5Pi4gyF30p6KbTk+Hm5aEy70np70R7dusMSH8CTit4p4zl1NkyhYeF6uvp/3/R3dXFWrYqFtXVv/NJQt6NjZLFY5OridNccJzk4WLR5T/zVmHsOh+jcxWtysFhUp+N7Kt7kHT3Xf5YOHudbcMh43ni6iLacuKKdp6/ZjFskVS/oq5CrtzSpbWn92Ku6Zr5UXrX+f7mz5Hi6OikyOkZxRvzjkjm9dTMqxhraSNLB8zd0MypGpXLxJTLgSULvlDnZ0ztt23dS3l7u1tBGkqqUKSBvL3drDwZkBO/3a6w/tx7XX7uC7zsve1ZPNapaWF+v2G0dc3V2lCHp9l3nkW5Hxyg2Nk7VS+dNcj9NaxSRn7e7vv1zbypUj0eRrlfcNG3aVE2bNk3PEpBChmFo+Ec/qnr5QipZOFeKtn2+SRUF5fJTgJ+3Dp44p3dnLtW/R89qycx+aVQtYC4uTg56s1lx/b77nCJupyy4mfBCWS3afFr7z1xXrmzuaVQhALOjd8p4QsPCJUnZfbPYjAf4ZlHIhSuSpCpl8svDzUWjZ/yiEX2flWEYGj3jF8XFGbpwOX774LOXJUnvfbZM499sq3w5/fTxwtVq8dpUbf9xpLL5eD7GowIeXv1i2VUk0Eu9F+5M9FxWD2d5uDjppap5NXdDsD5df1JV8/tqzLMlNfD7vdp75nqibbzdnNSpej79tveCdczX00VXb0Unmnv1VrSyebik7gEBMDV6p8zJnt4pNCxc2X29Em2b3dfL2p8BZte2XkmVK5xDT78+94FzX2pYRjcjo7X0n8PWsW0HzykyKlqju9XX2LnrZLFYNLpbfTk6OihHEr8fktSpSTmt2XFCZy9xT+X0lqHucXP79m2Fh4fb/ODxemvyYu0/dk6fj+uS4m07t6mletWKq2ThXGrXqLLmv9dN67Ye1p5DIalfKGAyTg4WfdihvBws0rtLEt8P535erhUkTzcnfbb2wffAAYC70TuZhyVhEen/ZxiSRfFj/tmyaN573bRi/b/KU2eQguq/pfCbt1SueF45OsS363H/fynBoFcb69mnK6h8iXyaOfJlWSwW/bx61+M9GOAhZfdyVd96hTRh2SHdiTUSPe/w/78nG4+H6YedZ3X8UoS+3RaizSeu6NmyORPN93Bx1IQ2pRUcFqn5m0/ZPpl499bfOQBIDr1TxmBP7yQl/fe+YSTuywAzyp09iyb2bqjXJv1qc8VMcjo2Kafv1+y3mRt2PVJdxi1Rk+pFdOaXt3RqySB5e7pq99Hzir3rflAJcvln0dOVCmrBij2peix4OOl6xU1KTZw4UWPGjEnvMp5YQ95frOV/79OyTwcod2C2R95fueJ55ezkqOOnL6pc8aQvzwMyAycHi6a8XEG5fT306qdbUny1TbVCfiqXL5t2T2hiM764fy39tuuc3lnM5asAkkbvlP4C/eKXZboYFq4c/j7W8UtXbyi7339X4TxdvYR2/TxaYdduysnRQT5ZPFSs8TAFNYpfIiph22IF/zt57erirPy5/XTm/6/cAcyuaKCXfD1d9MnLFa1jjg4Wlc3jo9blc6vZjH8UExunU2GRNtuduhKpMvcscebu7KhJbUvrVnSsRv66X7Fx/yU1VyKSvrImq7uzrkYmvhIHABLQO2UcD+qdAv28dfFK4isGLl+9qYB7roQGzKhckZwKyOaptTO7WsecHB1Us0w+9WhVWYHNJ1m/3FWjdF4VzeunbuOXJNrP2h0nVbHLbPl6uysmNk7hEbd16Lv+1vvg3K1D47K6cuOWlm86mmbHBftlqOBm2LBhGjhwoPVxeHi48ublhH9aMwxDQ97/Xr+v26Olc95QUG7/VNnvwePndScmVoF3ncQAMpuE0CbI31NdPtmi65F3UryPCb8e0LQ/jlgfB3i76fMeVTVo4W7tDbmWitUCyGzondJfUG4/Bfp5a+2WQypbLP69j74Tow07j2l0v1aJ5vtljV+y4O9th3Xp6k01rV1GUvwXXlxdnHTsVKhqlC8kSboTE6vT568obw7fx3Q0wKPZefqaus63vdHtkMbFFHIlUt9uC9GdWEOHQ28o7z3LwubN5q7QG7etjz1cHDWpbRndiY3T/37Zn+jqnQPnw+Xl5qTiObJY73NTPEcWebk5af85vj0PIHn0ThlPcr1TlTIFFH7zlnbsD1alUvklSdv/DVb4zVuqWrZgepUL2O3vXcGq2fMzm7GPBzXX0ZAwTVu82RraSNLLTcpp15Hz+vfExWT3dyX8liSpdvkgZc/qmWQ407FRWX23cp9iYhNfjYPHL0MFN66urnJ1dU3vMp44gyct1g9/bNc3H/SUl4ebQv9/vVBvLze5u8V/k+3q9QiduXBV5y/Hrzt99FSoJCnAz1uB/t46eeaSvl++XQ1rlZRfVi8dOnlBI6b+pLLF8qh6OT4wkXF5uDgqn5+H9XFuX3cVz5lF12/d0cXw25raqaJK5PZWn7nb5WiR/L3if2eu37pjPcng7+Ui/yyuyucfv5+iObIo4naMzl+L0vVbd3T+WpTNa0ZGx1/2GhIWodDrts8BwN3onR6Pm5G3dTLkkvXxqXNh2nf4jLL6eChvDl/1eqm+psz9U4XyBqhg3uyaMu8Pebg567nGla3bLPx1k4oWyCH/bF7auvekhk35QX1eqq8i+QMlSd5e7nq17VN679Nlyh2YTXlz+GrG16skSa2fqSggI7h1J1bB91xNE3UnVuFRd6zji7af0YjmJbT37HXtCrmmqvl9VaOgn95cHL9kh7uzoya3KyNXJwdNXH5IHi6O8nBxlBTfX8UZ0ukrt7Tl5BUNalhEU1bFn5QY+EwRbToeppCrtx7jEQPIaOidHo8H9U4POsckPbh3KlYghxrUKKk3xn+rj4a9KEkaMOFbNX6qtHUOYGY3b0XrYPAlm7HIqDu6En7LZjyLh4ta1SmuEZ+sTnI/HRqV1ZHTl3X5eqSqlsytib0batZPW3XsjO1V+3XK51f+nNn0NcukmUaGCm6QPr78cb0kqUWvaTbjM0e+rA4tq0uSlv+9T33f/dr6XLfh8TfNGtqjqd7u2VzOTk76a9thzVm0VhGR0codmFWNapXW0B5N5eiYoW61BNgolcdH83tVtz5+u2VJSdKS7Wc0c+VRPV0qviFc8mZtm+06z9msbSfiPyTb1whS34ZFrM8t6FNDkvTOoj36ecfZNK0fAPDodh88pZa9plsfD//oJ0nSS82radboTnrjlWcUdTtagyct0rUbkapUKr9+nPG6sni6Wbc5euqi3p35q66GRypfLl8NerWx+nR42uZ13n2jjZwcHdRr1FeKun1HlUoF6ZdZ/ZXV20NAZvHPsTB9tOqoOlTNp9frF1LIlVsatfSA/v3/K2WKBnqpZM74k3Zfd6tqs+1Ln29RaHj8lTkTlh/S6/ULaXLb+G9ebzwRpulrjj3GIwEAJOdBvdODzjFJ9vVOn43trKEf/KB2/WZKkprULqP3hzyfpscGPG5t65WURRb9uPZAks8XyeOrkV3rKVsWd50OvaYPv92oWT9uTTSvU5Ny2rI/REdCwtK6ZNjJYhhGErdtfDxu3rypY8fim+cKFSpoypQpql+/vnx9fZUvX74Hbh8eHi4fHx+Fhl2Xt7f3A+cDT7KSQ5aldwlAhhB3O1KnZj2v69f5bIH50DsBj8/TU/5O7xIA04uJitC2Uc3om2Ba9E7A45Ot0YT0LgEwPSMmSrfXj7Wrd0rXK262b9+u+vXrWx8nrCPauXNnzZs3L52qAgAAMCd6JwAAAPvROwEAMqp0DW7q1aundLzgBwAAIEOhdwIAALAfvRMAIKPi5iIAAAAAAAAAAAAmQXADAAAAAAAAAABgEgQ3AAAAAAAAAAAAJkFwAwAAAAAAAAAAYBIENwAAAAAAAAAAACZBcAMAAAAAAAAAAGASBDcAAAAAAAAAAAAmQXADAAAAAAAAAABgEgQ3AAAAAAAAAAAAJkFwAwAAAAAAAAAAYBIENwAAAAAAAAAAACZBcAMAAAAAAAAAAGASBDcAAAAAAAAAAAAmQXADAAAAAAAAAABgEgQ3AAAAAAAAAAAAJkFwAwAAAAAAAAAAYBIENwAAAAAAAAAAACZBcAMAAAAAAAAAAGASBDcAAAAAAAAAAAAmQXADAAAAAAAAAABgEgQ3AAAAAAAAAAAAJkFwAwAAAAAAAAAAYBIENwAAAAAAAAAAACZBcAMAAAAAAAAAAGASBDcAAAAAAAAAAAAmQXADAAAAAAAAAABgEgQ3AAAAAAAAAAAAJkFwAwAAAAAAAAAAYBIENwAAAAAAAAAAACZBcAMAAAAAAAAAAGASBDcAAAAAAAAAAAAmQXADAAAAAAAAAABgEgQ3AAAAAAAAAAAAJkFwAwAAAAAAAAAAYBIENwAAAAAAAAAAACZBcAMAAAAAAAAAAGASBDcAAAAAAAAAAAAmQXADAAAAAAAAAABgEgQ3AAAAAAAAAAAAJkFwAwAAAAAAAAAAYBIENwAAAAAAAAAAACZBcAMAAAAAAAAAAGASBDcAAAAAAAAAAAAmQXADAAAAAAAAAABgEgQ3AAAAAAAAAAAAJkFwAwAAAAAAAAAAYBIENwAAAAAAAAAAACZBcAMAAAAAAAAAAGASBDcAAAAAAAAAAAAmQXADAAAAAAAAAABgEgQ3AAAAAAAAAAAAJkFwAwAAAAAAAAAAYBIENwAAAAAAAAAAACZBcAMAAAAAAAAAAGASBDcAAAAAAAAAAAAmQXADAAAAAAAAAABgEgQ3AAAAAAAAAAAAJkFwAwAAAAAAAAAAYBIENwAAAAAAAAAAACZBcAMAAAAAAAAAAGASBDcAAAAAAAAAAAAmQXADAAAAAAAAAABgEgQ3AAAAAAAAAAAAJkFwAwAAAAAAAAAAYBIENwAAAAAAAAAAACZBcAMAAAAAAAAAAGASBDcAAAAAAAAAAAAmQXADAAAAAAAAAABgEgQ3AAAAAAAAAAAAJkFwAwAAAAAAAAAAYBIENwAAAAAAAAAAACZBcAMAAAAAAAAAAGASBDcAAAAAAAAAAAAmQXADAAAAAAAAAABgEgQ3AAAAAAAAAAAAJkFwAwAAAAAAAAAAYBIENwAAAAAAAAAAACZBcAMAAAAAAAAAAGASBDcAAAAAAAAAAAAmQXADAAAAAAAAAABgEgQ3AAAAAAAAAAAAJkFwAwAAAAAAAAAAYBIENwAAAAAAAAAAACZBcAMAAAAAAAAAAGASBDcAAAAAAAAAAAAmQXADAAAAAAAAAABgEgQ3AAAAAAAAAAAAJkFwAwAAAAAAAAAAYBIENwAAAAAAAAAAACZBcAMAAAAAAAAAAGASBDcAAAAAAAAAAAAmQXADAAAAAAAAAABgEgQ3AAAAAAAAAAAAJkFwAwAAAAAAAAAAYBJO6V3AozAMQ5J0Izw8nSsBzC/udmR6lwBkCHHR8b8rCZ8xQGZC7wTYLyYqIr1LAEwvNoq+CZkbvRNgPyMmKr1LAEzPiLkd/7929E4ZOri5ceOGJKlwgbzpXAkAILO5ceOGfHx80rsMIFXROwEA0gJ9EzIreicAQFqwp3eyGBn4qzFxcXE6d+6csmTJIovFkt7l4P+Fh4crb968CgkJkbe3d3qXA5gWvyvmZBiGbty4oVy5csnBgRVFkbnQO5kTnweAffhdMR/6JmR29E7mw2cBYD9+X8wnJb1Thr7ixsHBQXny5EnvMpAMb29v/lIA7MDvivnwjVFkVvRO5sbnAWAfflfMhb4JmRm9k3nxWQDYj98Xc7G3d+IrMQAAAAAAAAAAACZBcAMAAAAAAAAAAGASBDdIda6urho1apRcXV3TuxTA1PhdAQBIfB4A9uJ3BQDAZwFgP35fMjaLYRhGehcBAAAAAAAAAAAArrgBAAAAAAAAAAAwDYIbAAAAAAAAAAAAkyC4AQAAAAAAAAAAMAmCG6SqWbNmqUCBAnJzc1OlSpW0fv369C4JMJ2///5bLVu2VK5cuWSxWPTzzz+nd0kAgHRC7wQ8GL0TACABvRPwYPROmQPBDVLNokWLNGDAAA0fPly7du1S7dq11bRpU50+fTq9SwNMJSIiQuXKldPHH3+c3qUAANIRvRNgH3onAIBE7wTYi94pc7AYhmGkdxHIHKpVq6aKFStq9uzZ1rESJUqodevWmjhxYjpWBpiXxWLRkiVL1Lp16/QuBQDwmNE7ASlH7wQATy56JyDl6J0yLq64QaqIjo7Wjh071KhRI5vxRo0aaePGjelUFQAAgDnROwEAANiP3gnAk4bgBqni8uXLio2NVWBgoM14YGCgLly4kE5VAQAAmBO9EwAAgP3onQA8aQhukKosFovNY8MwEo0BAAAgHr0TAACA/eidADwpCG6QKvz9/eXo6JjoWw4XL15M9G0IAACAJx29EwAAgP3onQA8aQhukCpcXFxUqVIlrVy50mZ85cqVqlmzZjpVBQAAYE70TgAAAPajdwLwpHFK7wKQeQwcOFCdOnVS5cqVVaNGDX366ac6ffq0evXqld6lAaZy8+ZNHTt2zPr45MmT2r17t3x9fZUvX750rAwA8DjROwH2oXcCAEj0ToC96J0yB4thGEZ6F4HMY9asWZo8ebLOnz+v0qVL66OPPlKdOnXSuyzAVNatW6f69esnGu/cubPmzZv3+AsCAKQbeifgweidAAAJ6J2AB6N3yhwIbgAAAAAAAAAAAEyCe9wAAAAAAAAAAACYBMENAAAAAAAAAACASRDcAAAAAAAAAAAAmATBDQAAAAAAAAAAgEkQ3AAAAAAAAAAAAJgEwQ0AAAAAAAAAAIBJENwAAAAAAAAAAACYBMENAAAAAAAAAACASRDcACYyevRolS9f3vq4S5cuat269WOvIzg4WBaLRbt37052Tv78+TV16lS79zlv3jxlzZr1kWuzWCz6+eefH3k/AAAgY6NvejD6JgAAkIDe6cHonWAmBDfAA3Tp0kUWi0UWi0XOzs4qWLCgBg8erIiIiDR/7WnTpmnevHl2zbXngw8AACAt0TcBAADYj94JQHKc0rsAICNo0qSJ5s6dqzt37mj9+vXq3r27IiIiNHv27ERz79y5I2dn51R5XR8fn1TZDwAAwONC3wQAAGA/eicASeGKG8AOrq6uypEjh/LmzasOHTqoY8eO1ksnEy41/fLLL1WwYEG5urrKMAxdv35dPXv2VEBAgLy9vfX0009rz549Nvt97733FBgYqCxZsqhbt26Kioqyef7ey1bj4uI0adIkFS5cWK6ursqXL5/Gjx8vSSpQoIAkqUKFCrJYLKpXr551u7lz56pEiRJyc3NT8eLFNWvWLJvX2bp1qypUqCA3NzdVrlxZu3btSvF7NGXKFJUpU0aenp7Kmzev+vTpo5s3byaa9/PPP6to0aJyc3NTw4YNFRISYvP80qVLValSJbm5ualgwYIaM2aMYmJiUlwPAABIH/RND0bfBAAAEtA7PRi9E55EBDfAQ3B3d9edO3esj48dO6bFixfrxx9/tF422rx5c124cEHLli3Tjh07VLFiRTVo0EBXrlyRJC1evFijRo3S+PHjtX37duXMmTPRh9u9hg0bpkmTJmnEiBE6cOCAvvnmGwUGBkqK/yCUpFWrVun8+fP66aefJEmfffaZhg8frvHjx+vgwYOaMGGCRowYofnz50uSIiIi1KJFCxUrVkw7duzQ6NGjNXjw4BS/Jw4ODpo+fbr+/fdfzZ8/X2vWrNGQIUNs5kRGRmr8+PGaP3++NmzYoPDwcL344ovW5//44w+9/PLL6t+/vw4cOKBPPvlE8+bNszYKAAAg46FvSoy+CQAAJIfeKTF6JzyRDAD31blzZ6NVq1bWx1u2bDH8/PyMF154wTAMwxg1apTh7OxsXLx40Tpn9erVhre3txEVFWWzr0KFChmffPKJYRiGUaNGDaNXr142z1erVs0oV65ckq8dHh5uuLq6Gp999lmSdZ48edKQZOzatctmPG/evMY333xjMzZ27FijRo0ahmEYxieffGL4+voaERER1udnz56d5L7uFhQUZHz00UfJPr948WLDz8/P+nju3LmGJGPz5s3WsYMHDxqSjC1bthiGYRi1a9c2JkyYYLOfBQsWGDlz5rQ+lmQsWbIk2dcFAADph74pafRNAAAgKfROSaN3AgyDe9wAdvjtt9/k5eWlmJgY3blzR61atdKMGTOszwcFBSl79uzWxzt27NDNmzfl5+dns59bt27p+PHjkqSDBw+qV69eNs/XqFFDa9euTbKGgwcP6vbt22rQoIHddV+6dEkhISHq1q2bevToYR2PiYmxrmV68OBBlStXTh4eHjZ1pNTatWs1YcIEHThwQOHh4YqJiVFUVJQiIiLk6ekpSXJyclLlypWt2xQvXlxZs2bVwYMHVbVqVe3YsUPbtm2z+bZDbGysoqKiFBkZaVMjAAAwJ/qmB6NvAgAACeidHozeCU8ighvADvXr19fs2bPl7OysXLlyJboRXMKHRIK4uDjlzJlT69atS7SvrFmzPlQN7u7uKd4mLi5OUvylq9WqVbN5ztHRUZJkGMZD1XO3U6dOqVmzZurVq5fGjh0rX19f/fPPP+rWrZvN5b2SZLFYEm2fMBYXF6cxY8aobdu2iea4ubk9cp0AACDt0TfdH30TAAC4G73T/dE74UlFcAPYwdPTU4ULF7Z7fsWKFXXhwgU5OTkpf/78Sc4pUaKENm/erFdeecU6tnnz5mT3WaRIEbm7u2v16tXq3r17ouddXFwkxX9bIEFgYKBy586tEydOqGPHjknut2TJklqwYIFu3bpl/aC+Xx1J2b59u2JiYvThhx/KwSH+1lmLFy9ONC8mJkbbt29X1apVJUmHDx/WtWvXVLx4cUnx79vhw4dT9F4DAABzoW+6P/omAABwN3qn+6N3wpOK4AZIA88884xq1Kih1q1ba9KkSSpWrJjOnTunZcuWqXXr1qpcubLeeOMNde7cWZUrV9ZTTz2lhQsXav/+/SpYsGCS+3Rzc9PQoUM1ZMgQubi4qFatWrp06ZL279+vbt26KSAgQO7u7lqxYoXy5MkjNzc3+fj4aPTo0erfv7+8vb3VtGlT3b59W9u3b9fVq1c1cOBAdejQQcOHD1e3bt30v//9T8HBwfrggw9SdLyFChVSTEyMZsyYoZYtW2rDhg2aM2dOonnOzs7q16+fpk+fLmdnZ73++uuqXr269UN15MiRatGihfLmzavnn39eDg4O2rt3r/bt26dx48al/D8EAAAwPfom+iYAAGA/eid6JzwZHNK7ACAzslgsWrZsmerUqaOuXbuqaNGievHFFxUcHKzAwEBJUvv27TVy5EgNHTpUlSpV0qlTp9S7d+/77nfEiBEaNGiQRo4cqRIlSqh9+/a6ePGipPi1PKdPn65PPvlEuXLlUqtWrSRJ3bt31+eff6558+apTJkyqlu3rubNm6cCBQpIkry8vLR06VIdOHBAFSpU0PDhwzVp0qQUHW/58uU1ZcoUTZo0SaVLl9bChQs1ceLERPM8PDw0dOhQdejQQTVq1JC7u7u+++476/ONGzfWb7/9ppUrV6pKlSqqXr26pkyZoqCgoBTVAwAAMg76JvomAABgP3oneic8GSxGaiw2CAAAAAAAAAAAgEfGFTcAAAAAAAAAAAAmQXADAAAAAAAAAABgEgQ3AAAAAAAAAAAAJkFwAwAAAAAAAAAAYBIENwAAAAAAAAAAACZBcAMAAAAAAAAAAGASBDcAAAAAAAAAAAAmQXADAAAAAAAAAABgEgQ3AAAAAAAAAAAAJkFwAwAAAAAAAAAAYBIENwAAAAAAAAAAACZBcAMAAAAAAAAAAGAS/we7nzLcQFwC2gAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 1800x500 with 3 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Predictions\n",
    "y_pred_train = (y_pred_train > best_threshold).astype(int)\n",
    "y_pred_test = (y_pred_test > best_threshold).astype(int)\n",
    "y_pred_oot = (y_pred_oot > best_threshold).astype(int)\n",
    "\n",
    "# Confusion matrices\n",
    "cm_train = confusion_matrix(y_train, y_pred_train)\n",
    "cm_test = confusion_matrix(y_test, y_pred_test)\n",
    "cm_oot = confusion_matrix(y_oot, y_pred_oot)\n",
    "\n",
    "# Plotting\n",
    "fig, axs = plt.subplots(1, 3, figsize=(18, 5))\n",
    "\n",
    "# Train\n",
    "disp_train = ConfusionMatrixDisplay(confusion_matrix=cm_train)\n",
    "disp_train.plot(ax=axs[0], cmap='Blues', colorbar=False)\n",
    "axs[0].set_title(f\"Train (Threshold={best_threshold:.2f})\")\n",
    "axs[0].grid(False)\n",
    "\n",
    "# Test\n",
    "disp_test = ConfusionMatrixDisplay(confusion_matrix=cm_test)\n",
    "disp_test.plot(ax=axs[1], cmap='Blues', colorbar=False)\n",
    "axs[1].set_title(f\"Test (Threshold={best_threshold:.2f})\")\n",
    "axs[1].grid(False)\n",
    "\n",
    "# OOT\n",
    "disp_oot = ConfusionMatrixDisplay(confusion_matrix=cm_oot)\n",
    "disp_oot.plot(ax=axs[2], cmap='Blues', colorbar=False)\n",
    "axs[2].set_title(f\"OOT (Threshold={best_threshold:.2f})\")\n",
    "axs[2].grid(False)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "78c2e5ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== MODEL F1.5 SCORE ===\n",
      "Train F1.5 Score : 0.6601\n",
      "Test F1.5 Score  : 0.6277\n",
      "OOT F1.5 Score   : 0.6705\n"
     ]
    }
   ],
   "source": [
    "# Set beta\n",
    "beta = 1.5\n",
    "\n",
    "# Compute F1.5 scores\n",
    "f1_5_train = fbeta_score(y_train, y_pred_train, beta=beta)\n",
    "f1_5_test = fbeta_score(y_test, y_pred_test, beta=beta)\n",
    "f1_5_oot = fbeta_score(y_oot, y_pred_oot, beta=beta)\n",
    "\n",
    "# Print results\n",
    "print(\"\\n=== MODEL F1.5 SCORE ===\")\n",
    "print(f\"Train F1.5 Score : {f1_5_train:.4f}\")\n",
    "print(f\"Test F1.5 Score  : {f1_5_test:.4f}\")\n",
    "print(f\"OOT F1.5 Score   : {f1_5_oot:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63f6d051",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c6c313a7",
   "metadata": {},
   "source": [
    "#### Logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0630b2f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train AUC: 0.7118\n",
      "Test AUC: 0.6969\n",
      "OOT AUC: 0.6928\n"
     ]
    }
   ],
   "source": [
    "# Train model\n",
    "clf = LogisticRegression()\n",
    "clf.fit(X_train_processed, y_train)\n",
    "\n",
    "# Predict and evaluate\n",
    "y_pred_proba_train = clf.predict_proba(X_train_processed)[:, 1]\n",
    "train_auc = roc_auc_score(y_train, y_pred_proba_train)\n",
    "\n",
    "y_pred_proba_test = clf.predict_proba(X_test_processed)[:, 1]\n",
    "test_auc = roc_auc_score(y_test, y_pred_proba_test)\n",
    "\n",
    "y_pred_proba_oot = clf.predict_proba(X_oot_processed)[:, 1]\n",
    "oot_auc = roc_auc_score(y_oot, y_pred_proba_oot)\n",
    "\n",
    "print(f\"Train AUC: {train_auc:.4f}\")\n",
    "print(f\"Test AUC: {test_auc:.4f}\")\n",
    "print(f\"OOT AUC: {oot_auc:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4cf47a89",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# F2 score across thresholds\n",
    "thresholds = np.arange(0.0, 1.0, 0.01)\n",
    "beta = 1.5\n",
    "f1_scores_train = [fbeta_score(y_train, y_pred_proba_train > t, beta=beta) for t in thresholds]\n",
    "f1_scores_test = [fbeta_score(y_test, y_pred_proba_test > t, beta=beta) for t in thresholds]\n",
    "f1_scores_oot = [fbeta_score(y_oot, y_pred_proba_oot > t, beta=beta) for t in thresholds]\n",
    "best_threshold_reg = thresholds[np.argmax(f1_scores_train)]\n",
    "\n",
    "# Plot F1 Score vs. Threshold\n",
    "plt.figure(figsize=(10, 4))\n",
    "plt.plot(thresholds, f1_scores_train, label=f\"Train F-{beta} Score\")\n",
    "plt.plot(thresholds, f1_scores_test, label=f\"Test F-{beta} Score\")\n",
    "plt.plot(thresholds, f1_scores_oot, label=f\"OOT F-{beta} Score\")\n",
    "plt.axvline(x=best_threshold, color=\"red\", linestyle=\"--\", label=f\"Best Threshold: {best_threshold:.2f}\")\n",
    "plt.title(f\"F-{beta} Score vs. Probability Threshold\")\n",
    "plt.xlabel(\"Threshold\")\n",
    "plt.ylabel(f\"F-{beta} Score\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "63a3ae19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Train F1.5-Score: 0.6284\n",
      "Best Test F1.5-Score: 0.6209\n",
      "Best OOT F1.5-Score: 0.6829\n"
     ]
    }
   ],
   "source": [
    "print(f\"Best Train F{beta}-Score: {max(f1_scores_train):.4f}\")\n",
    "print(f\"Best Test F{beta}-Score: {max(f1_scores_test):.4f}\")\n",
    "print(f\"Best OOT F{beta}-Score: {max(f1_scores_oot):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ab945fdf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'data_dates': {'model_train_date': datetime.datetime(2017, 12, 4, 0, 0),\n",
      "                'model_train_date_str': '2017-12-04',\n",
      "                'oot_end_date': datetime.datetime(2017, 12, 3, 0, 0),\n",
      "                'oot_period_months': 3,\n",
      "                'oot_start_date': datetime.datetime(2017, 9, 4, 0, 0),\n",
      "                'train_test_end_date': datetime.datetime(2017, 9, 3, 0, 0),\n",
      "                'train_test_period_months': 12,\n",
      "                'train_test_ratio': 0.8,\n",
      "                'train_test_start_date': datetime.datetime(2016, 9, 4, 0, 0)},\n",
      " 'data_stats': {'X_oot': 16026,\n",
      "                'X_test': 18105,\n",
      "                'X_train': 4526,\n",
      "                'y_oot': 0.37,\n",
      "                'y_test': 0.32,\n",
      "                'y_train': 0.32},\n",
      " 'hp_params': {'C': 1.0,\n",
      "               'class_weight': None,\n",
      "               'dual': False,\n",
      "               'fit_intercept': True,\n",
      "               'intercept_scaling': 1,\n",
      "               'l1_ratio': None,\n",
      "               'max_iter': 100,\n",
      "               'multi_class': 'deprecated',\n",
      "               'n_jobs': None,\n",
      "               'penalty': 'l2',\n",
      "               'random_state': None,\n",
      "               'solver': 'lbfgs',\n",
      "               'tol': 0.0001,\n",
      "               'verbose': 0,\n",
      "               'warm_start': False},\n",
      " 'model': LogisticRegression(),\n",
      " 'model_version': 'reg_2017_12_04',\n",
      " 'preprocessing_transformers': {'stdscaler': StandardScaler()},\n",
      " 'results': {'f1_oot': 0.6828925768832969,\n",
      "             'f1_test': 0.6209199415394608,\n",
      "             'f1_train': 0.6284452505816017},\n",
      " 'threshold': 0.25}\n"
     ]
    }
   ],
   "source": [
    "model_artefact_reg = {}\n",
    "\n",
    "model_artefact_reg['model'] = clf\n",
    "model_artefact_reg['hp_params'] = clf.get_params()\n",
    "model_artefact_reg['model_version'] = \"reg_\"+config[\"model_train_date_str\"].replace('-','_')\n",
    "model_artefact_reg['preprocessing_transformers'] = {}\n",
    "model_artefact_reg['preprocessing_transformers']['stdscaler'] = transformer_stdscaler\n",
    "model_artefact_reg['data_dates'] = config\n",
    "model_artefact_reg['data_stats'] = {}\n",
    "model_artefact_reg['data_stats']['X_train'] = X_train_arr.shape[0]\n",
    "model_artefact_reg['data_stats']['X_test'] = X_test_arr.shape[0]\n",
    "model_artefact_reg['data_stats']['X_oot'] = X_oot_arr.shape[0]\n",
    "model_artefact_reg['data_stats']['y_train'] = round(y_train.mean(),2)\n",
    "model_artefact_reg['data_stats']['y_test'] = round(y_test.mean(),2)\n",
    "model_artefact_reg['data_stats']['y_oot'] = round(y_oot.mean(),2)\n",
    "model_artefact_reg['results'] = {}\n",
    "model_artefact_reg['results']['f1_train'] = max(f1_scores_train)\n",
    "model_artefact_reg['results']['f1_test'] =  max(f1_scores_test)\n",
    "model_artefact_reg['results']['f1_oot'] =  max(f1_scores_oot)\n",
    "model_artefact_reg['threshold'] = best_threshold_reg\n",
    "\n",
    "pprint.pprint(model_artefact_reg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "846548ca-a1bb-4625-854e-ac39068f3821",
   "metadata": {},
   "source": [
    "## prepare model artefact to save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "51a720c7-df26-41be-935e-06904983c6fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'data_dates': {'model_train_date': datetime.datetime(2017, 12, 4, 0, 0),\n",
      "                'model_train_date_str': '2017-12-04',\n",
      "                'oot_end_date': datetime.datetime(2017, 12, 3, 0, 0),\n",
      "                'oot_period_months': 3,\n",
      "                'oot_start_date': datetime.datetime(2017, 9, 4, 0, 0),\n",
      "                'train_test_end_date': datetime.datetime(2017, 9, 3, 0, 0),\n",
      "                'train_test_period_months': 12,\n",
      "                'train_test_ratio': 0.8,\n",
      "                'train_test_start_date': datetime.datetime(2016, 9, 4, 0, 0)},\n",
      " 'data_stats': {'X_oot': 16026,\n",
      "                'X_test': 18105,\n",
      "                'X_train': 4526,\n",
      "                'y_oot': 0.37,\n",
      "                'y_test': 0.32,\n",
      "                'y_train': 0.32},\n",
      " 'hp_params': {'colsample_bytree': 0.8,\n",
      "               'gamma': 0,\n",
      "               'learning_rate': 0.01,\n",
      "               'max_depth': 3,\n",
      "               'min_child_weight': 3,\n",
      "               'n_estimators': 300,\n",
      "               'reg_alpha': 3,\n",
      "               'reg_lambda': 1,\n",
      "               'subsample': 0.8},\n",
      " 'model': XGBClassifier(base_score=0.5, booster='gbtree', callbacks=None,\n",
      "              colsample_bylevel=1, colsample_bynode=1, colsample_bytree=0.8,\n",
      "              early_stopping_rounds=None, enable_categorical=False,\n",
      "              eval_metric='logloss', gamma=0, gpu_id=-1,\n",
      "              grow_policy='depthwise', importance_type=None,\n",
      "              interaction_constraints='', learning_rate=0.01, max_bin=256,\n",
      "              max_cat_to_onehot=4, max_delta_step=0, max_depth=3, max_leaves=0,\n",
      "              min_child_weight=3, missing=nan, monotone_constraints='()',\n",
      "              n_estimators=300, n_jobs=0, num_parallel_tree=1, predictor='auto',\n",
      "              random_state=42, reg_alpha=3, reg_lambda=1, ...),\n",
      " 'model_version': 'xgb_2017_12_04',\n",
      " 'preprocessing_transformers': {'stdscaler': StandardScaler()},\n",
      " 'results': {'auc_oot': 0.692782414492948,\n",
      "             'auc_test': 0.6969481296219737,\n",
      "             'auc_train': 0.7117597042488804,\n",
      "             'f1_oot': 0.6705267572013806,\n",
      "             'f1_test': 0.6276911500355337,\n",
      "             'f1_train': 0.6600861600234221,\n",
      "             'gini_oot': 0.386,\n",
      "             'gini_test': 0.394,\n",
      "             'gini_train': 0.424},\n",
      " 'threshold': 0.29}\n"
     ]
    }
   ],
   "source": [
    "model_artefact_xgb = {}\n",
    "\n",
    "model_artefact_xgb['model'] = model\n",
    "model_artefact_xgb['hp_params'] = params\n",
    "model_artefact_xgb['model_version'] = \"xgb_\"+config[\"model_train_date_str\"].replace('-','_')\n",
    "model_artefact_xgb['preprocessing_transformers'] = {}\n",
    "model_artefact_xgb['preprocessing_transformers']['stdscaler'] = transformer_stdscaler\n",
    "model_artefact_xgb['data_dates'] = config\n",
    "model_artefact_xgb['data_stats'] = {}\n",
    "model_artefact_xgb['data_stats']['X_train'] = X_train_arr.shape[0]\n",
    "model_artefact_xgb['data_stats']['X_test'] = X_test_arr.shape[0]\n",
    "model_artefact_xgb['data_stats']['X_oot'] = X_oot_arr.shape[0]\n",
    "model_artefact_xgb['data_stats']['y_train'] = round(y_train.mean(),2)\n",
    "model_artefact_xgb['data_stats']['y_test'] = round(y_test.mean(),2)\n",
    "model_artefact_xgb['data_stats']['y_oot'] = round(y_oot.mean(),2)\n",
    "model_artefact_xgb['results'] = {}\n",
    "model_artefact_xgb['results']['auc_train'] = train_auc\n",
    "model_artefact_xgb['results']['auc_test'] = test_auc\n",
    "model_artefact_xgb['results']['auc_oot'] = oot_auc\n",
    "model_artefact_xgb['results']['gini_train'] = round(2*train_auc-1,3)\n",
    "model_artefact_xgb['results']['gini_test'] = round(2*test_auc-1,3)\n",
    "model_artefact_xgb['results']['gini_oot'] = round(2*oot_auc-1,3)\n",
    "model_artefact_xgb['results']['f1_train'] = f1_5_train\n",
    "model_artefact_xgb['results']['f1_test'] = f1_5_test\n",
    "model_artefact_xgb['results']['f1_oot'] = f1_5_oot\n",
    "model_artefact_xgb['threshold'] = best_threshold\n",
    "\n",
    "pprint.pprint(model_artefact_xgb)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ea194e4-669d-43a6-b31f-ef14f0d188aa",
   "metadata": {},
   "source": [
    "## save artefact to model bank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "729aed57",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/baohongzhuang/Desktop/03 MLE/MLE_grp10/scripts'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "54ff1665-3eef-4b13-8c78-3cfe19fd1f56",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create model_bank dir\n",
    "model_bank_directory = \"model_bank/\"\n",
    "\n",
    "if not os.path.exists(model_bank_directory):\n",
    "    os.makedirs(model_bank_directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "73cdc348",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved to model_bank/reg_2017_12_04.pkl\n"
     ]
    }
   ],
   "source": [
    "# Full path to the file\n",
    "file_path = os.path.join(model_bank_directory, model_artefact_reg['model_version'] + '.pkl')\n",
    "\n",
    "# Write the model to a pickle file\n",
    "with open(file_path, 'wb') as file:\n",
    "    pickle.dump(model_artefact_reg, file)\n",
    "\n",
    "print(f\"Model saved to {file_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "7aebf078-449b-4e6c-81fa-496d901e97dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved to model_bank/xgb_2017_12_04.pkl\n"
     ]
    }
   ],
   "source": [
    "# Full path to the file\n",
    "file_path = os.path.join(model_bank_directory, model_artefact_xgb['model_version'] + '.pkl')\n",
    "\n",
    "# Write the model to a pickle file\n",
    "with open(file_path, 'wb') as file:\n",
    "    pickle.dump(model_artefact_xgb, file)\n",
    "\n",
    "print(f\"Model saved to {file_path}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c91f891-d285-46ef-8901-d19ec702176b",
   "metadata": {},
   "source": [
    "## test load pickle and make model inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36f1da5b-0766-4ac5-b643-115daad8e80d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OOT AUC score:  0.7084856781951092\n",
      "Model loaded successfully!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/06/20 10:59:51 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@10.232.169.110:49927\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/06/20 11:00:17 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@10.232.169.110:49927\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/06/20 11:00:36 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@10.232.169.110:49927\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/06/20 11:00:46 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@10.232.169.110:49927\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/06/20 11:01:06 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@10.232.169.110:49927\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/06/20 11:01:51 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@10.232.169.110:49927\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/06/20 11:02:01 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@10.232.169.110:49927\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/06/20 11:02:11 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@10.232.169.110:49927\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/06/20 11:02:21 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@10.232.169.110:49927\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/06/20 11:02:31 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@10.232.169.110:49927\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/06/20 11:02:41 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@10.232.169.110:49927\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/06/20 11:02:51 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@10.232.169.110:49927\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/06/20 11:03:01 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@10.232.169.110:49927\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/06/20 11:03:11 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@10.232.169.110:49927\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/06/20 11:03:21 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@10.232.169.110:49927\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/06/20 11:03:31 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@10.232.169.110:49927\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.dispatchOrAddCallback(Promise.scala:316)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.onComplete(Promise.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.transformWith(Promise.scala:40)\n",
      "\tat scala.concurrent.impl.Promise.transformWith$(Promise.scala:38)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.transformWith(Promise.scala:187)\n",
      "\tat scala.concurrent.Future.flatMap(Future.scala:306)\n",
      "\tat scala.concurrent.Future.flatMap$(Future.scala:306)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.flatMap(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.asyncSetupEndpointRefByURI(NettyRpcEnv.scala:150)\n",
      "\t... 17 more\n",
      "25/06/20 11:03:41 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@10.232.169.110:49927\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/06/20 11:03:51 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@10.232.169.110:49927\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/06/20 11:04:01 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@10.232.169.110:49927\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/06/20 11:04:11 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@10.232.169.110:49927\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/06/20 11:04:21 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@10.232.169.110:49927\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/06/20 11:04:31 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@10.232.169.110:49927\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/06/20 11:04:41 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@10.232.169.110:49927\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.dispatchOrAddCallback(Promise.scala:316)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.onComplete(Promise.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.transformWith(Promise.scala:40)\n",
      "\tat scala.concurrent.impl.Promise.transformWith$(Promise.scala:38)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.transformWith(Promise.scala:187)\n",
      "\tat scala.concurrent.Future.flatMap(Future.scala:306)\n",
      "\tat scala.concurrent.Future.flatMap$(Future.scala:306)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.flatMap(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.asyncSetupEndpointRefByURI(NettyRpcEnv.scala:150)\n",
      "\t... 17 more\n",
      "25/06/20 11:04:51 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@10.232.169.110:49927\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/06/20 11:05:01 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@10.232.169.110:49927\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/06/20 11:05:11 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@10.232.169.110:49927\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/06/20 11:05:21 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@10.232.169.110:49927\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.dispatchOrAddCallback(Promise.scala:316)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.onComplete(Promise.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.transformWith(Promise.scala:40)\n",
      "\tat scala.concurrent.impl.Promise.transformWith$(Promise.scala:38)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.transformWith(Promise.scala:187)\n",
      "\tat scala.concurrent.Future.flatMap(Future.scala:306)\n",
      "\tat scala.concurrent.Future.flatMap$(Future.scala:306)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.flatMap(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.asyncSetupEndpointRefByURI(NettyRpcEnv.scala:150)\n",
      "\t... 17 more\n",
      "25/06/20 11:05:31 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@10.232.169.110:49927\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/06/20 11:05:41 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@10.232.169.110:49927\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/06/20 11:05:51 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@10.232.169.110:49927\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.dispatchOrAddCallback(Promise.scala:316)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.onComplete(Promise.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.transformWith(Promise.scala:40)\n",
      "\tat scala.concurrent.impl.Promise.transformWith$(Promise.scala:38)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.transformWith(Promise.scala:187)\n",
      "\tat scala.concurrent.Future.flatMap(Future.scala:306)\n",
      "\tat scala.concurrent.Future.flatMap$(Future.scala:306)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.flatMap(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.asyncSetupEndpointRefByURI(NettyRpcEnv.scala:150)\n",
      "\t... 17 more\n",
      "25/06/20 11:06:01 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@10.232.169.110:49927\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/06/20 11:06:11 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@10.232.169.110:49927\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/06/20 11:06:21 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@10.232.169.110:49927\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/06/20 11:06:31 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@10.232.169.110:49927\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/06/20 11:06:41 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@10.232.169.110:49927\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/06/20 11:06:51 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@10.232.169.110:49927\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/06/20 11:07:01 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@10.232.169.110:49927\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/06/20 11:07:11 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@10.232.169.110:49927\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/06/20 11:07:21 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@10.232.169.110:49927\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/06/20 11:07:31 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@10.232.169.110:49927\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/06/20 11:07:41 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@10.232.169.110:49927\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/06/20 11:07:51 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@10.232.169.110:49927\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/06/20 11:08:01 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@10.232.169.110:49927\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/06/20 11:08:11 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@10.232.169.110:49927\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/06/20 11:08:21 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@10.232.169.110:49927\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/06/20 11:08:31 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@10.232.169.110:49927\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/06/20 11:08:41 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@10.232.169.110:49927\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/06/20 11:08:51 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@10.232.169.110:49927\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/06/20 11:09:01 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@10.232.169.110:49927\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/06/20 11:09:11 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@10.232.169.110:49927\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/06/20 11:09:21 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@10.232.169.110:49927\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/06/20 11:09:31 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@10.232.169.110:49927\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/06/20 11:09:41 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@10.232.169.110:49927\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/06/20 11:09:51 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@10.232.169.110:49927\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/06/20 11:10:01 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@10.232.169.110:49927\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/06/20 11:10:11 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@10.232.169.110:49927\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/06/20 11:10:21 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@10.232.169.110:49927\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/06/20 11:10:31 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@10.232.169.110:49927\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/06/20 11:10:41 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@10.232.169.110:49927\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/06/20 11:10:51 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@10.232.169.110:49927\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/06/20 11:10:51 ERROR Executor: Exit as unable to send heartbeats to driver more than 60 times\n"
     ]
    }
   ],
   "source": [
    "# Load the model from the pickle file\n",
    "with open(file_path, 'rb') as file:\n",
    "    loaded_model_artefact = pickle.load(file)\n",
    "\n",
    "y_pred_proba = loaded_model_artefact['model'].predict_proba(X_oot_processed)[:, 1]\n",
    "oot_auc_score = roc_auc_score(y_oot, y_pred_proba)\n",
    "print(\"OOT AUC score: \", oot_auc_score)\n",
    "\n",
    "print(\"Model loaded successfully!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mle_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
