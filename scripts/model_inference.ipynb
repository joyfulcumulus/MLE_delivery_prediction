{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f800477c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.6.2\n"
     ]
    }
   ],
   "source": [
    "import xgboost as xgb; \n",
    "print(xgb.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "b50484d2-bfa4-40b6-82cd-e8bf86187cfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import pandas as pd\n",
    "import pickle\n",
    "#import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import random\n",
    "from datetime import datetime, timedelta\n",
    "from dateutil.relativedelta import relativedelta\n",
    "import pprint\n",
    "import pyspark\n",
    "import pyspark.sql.functions as F\n",
    "\n",
    "from pyspark.sql.functions import col\n",
    "from pyspark.sql.types import StringType, IntegerType, FloatType, DateType\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "import xgboost as xgb\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.metrics import make_scorer, f1_score, roc_auc_score\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import model_inference\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fcac9436-de95-4ebf-9655-56df8e1eafd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build a .py script that takes a snapshot date, loads a model artefact and make an inference and save to datamart"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37c91bb1-bcf0-4195-90f3-dc88806ebf8c",
   "metadata": {},
   "source": [
    "## set up pyspark session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "32fb3bc6-4166-4893-88e1-0d3140df5a92",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize SparkSession\n",
    "spark = pyspark.sql.SparkSession.builder \\\n",
    "    .appName(\"dev\") \\\n",
    "    .master(\"local[*]\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "# Set log level to ERROR to hide warnings\n",
    "spark.sparkContext.setLogLevel(\"ERROR\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30206071-5f00-4c3b-be13-55c54db8e336",
   "metadata": {},
   "source": [
    "## set up config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3e158e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "execute command: python model_inference.py --snapshotdate \"2017-01-01\" --modelname \"reg_2018_04_01.pkl\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "25/06/26 23:34:19 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "25/06/26 23:34:19 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.\n",
      "25/06/26 23:34:19 WARN Utils: Service 'SparkUI' could not bind on port 4041. Attempting port 4042.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "---starting job---\n",
      "\n",
      "\n",
      "{'model_artefact_filepath': 'model_bank/reg_2018_04_01.pkl',\n",
      " 'model_bank_directory': 'model_bank/',\n",
      " 'model_name': 'reg_2018_04_01.pkl',\n",
      " 'snapshot_date': datetime.datetime(2017, 1, 1, 0, 0),\n",
      " 'snapshot_date_str': '2017-01-01'}\n",
      "Model loaded successfully! model_bank/reg_2018_04_01.pkl\n",
      "y_inference 0\n",
      "datamart/gold/model_predictions/reg_2018_04_01/\n",
      "No inference data to write. Skipping write step.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving labels: 100%|██████████| 1/1 [00:00<00:00, 484.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "---completed job---\n",
      "\n",
      "\n",
      "execute command: python model_inference.py --snapshotdate \"2017-01-02\" --modelname \"reg_2018_04_01.pkl\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "25/06/26 23:34:23 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "25/06/26 23:34:23 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.\n",
      "25/06/26 23:34:23 WARN Utils: Service 'SparkUI' could not bind on port 4041. Attempting port 4042.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "---starting job---\n",
      "\n",
      "\n",
      "{'model_artefact_filepath': 'model_bank/reg_2018_04_01.pkl',\n",
      " 'model_bank_directory': 'model_bank/',\n",
      " 'model_name': 'reg_2018_04_01.pkl',\n",
      " 'snapshot_date': datetime.datetime(2017, 1, 2, 0, 0),\n",
      " 'snapshot_date_str': '2017-01-02'}\n",
      "Model loaded successfully! model_bank/reg_2018_04_01.pkl\n",
      "y_inference 0\n",
      "datamart/gold/model_predictions/reg_2018_04_01/\n",
      "No inference data to write. Skipping write step.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving labels: 100%|██████████| 1/1 [00:00<00:00, 526.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "---completed job---\n",
      "\n",
      "\n",
      "execute command: python model_inference.py --snapshotdate \"2017-01-03\" --modelname \"reg_2018_04_01.pkl\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "25/06/26 23:34:27 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "25/06/26 23:34:27 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.\n",
      "25/06/26 23:34:27 WARN Utils: Service 'SparkUI' could not bind on port 4041. Attempting port 4042.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "---starting job---\n",
      "\n",
      "\n",
      "{'model_artefact_filepath': 'model_bank/reg_2018_04_01.pkl',\n",
      " 'model_bank_directory': 'model_bank/',\n",
      " 'model_name': 'reg_2018_04_01.pkl',\n",
      " 'snapshot_date': datetime.datetime(2017, 1, 3, 0, 0),\n",
      " 'snapshot_date_str': '2017-01-03'}\n",
      "Model loaded successfully! model_bank/reg_2018_04_01.pkl\n",
      "y_inference 0\n",
      "datamart/gold/model_predictions/reg_2018_04_01/\n",
      "No inference data to write. Skipping write step.\n",
      "\n",
      "\n",
      "---completed job---\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving labels: 100%|██████████| 1/1 [00:00<00:00, 491.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "execute command: python model_inference.py --snapshotdate \"2017-01-04\" --modelname \"reg_2018_04_01.pkl\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "25/06/26 23:34:31 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "25/06/26 23:34:31 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.\n",
      "25/06/26 23:34:31 WARN Utils: Service 'SparkUI' could not bind on port 4041. Attempting port 4042.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "---starting job---\n",
      "\n",
      "\n",
      "{'model_artefact_filepath': 'model_bank/reg_2018_04_01.pkl',\n",
      " 'model_bank_directory': 'model_bank/',\n",
      " 'model_name': 'reg_2018_04_01.pkl',\n",
      " 'snapshot_date': datetime.datetime(2017, 1, 4, 0, 0),\n",
      " 'snapshot_date_str': '2017-01-04'}\n",
      "Model loaded successfully! model_bank/reg_2018_04_01.pkl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving labels: 100%|██████████| 1/1 [00:00<00:00, 521.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y_inference 0\n",
      "datamart/gold/model_predictions/reg_2018_04_01/\n",
      "No inference data to write. Skipping write step.\n",
      "\n",
      "\n",
      "---completed job---\n",
      "\n",
      "\n",
      "execute command: python model_inference.py --snapshotdate \"2017-01-05\" --modelname \"reg_2018_04_01.pkl\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "25/06/26 23:34:35 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "25/06/26 23:34:35 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.\n",
      "25/06/26 23:34:35 WARN Utils: Service 'SparkUI' could not bind on port 4041. Attempting port 4042.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "---starting job---\n",
      "\n",
      "\n",
      "{'model_artefact_filepath': 'model_bank/reg_2018_04_01.pkl',\n",
      " 'model_bank_directory': 'model_bank/',\n",
      " 'model_name': 'reg_2018_04_01.pkl',\n",
      " 'snapshot_date': datetime.datetime(2017, 1, 5, 0, 0),\n",
      " 'snapshot_date_str': '2017-01-05'}\n",
      "Model loaded successfully! model_bank/reg_2018_04_01.pkl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving labels:   0%|          | 0/1 [00:00<?, ?it/s]/opt/anaconda3/envs/mle_env/lib/python3.10/site-packages/sklearn/utils/validation.py:2732: UserWarning: X has feature names, but StandardScaler was fitted without feature names\n",
      "  warnings.warn(\n",
      "Saving labels: 100%|██████████| 1/1 [00:02<00:00,  2.71s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_inference 32\n",
      "num of rows add:32\n",
      "datamart/gold/model_predictions/reg_2018_04_01/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved to: datamart/gold/model_predictions/reg_2018_04_01/reg_2018_04_01_predictions_2017_01_05.parquet\n",
      "rows added: 32\n",
      "\n",
      "\n",
      "---completed job---\n",
      "\n",
      "\n",
      "execute command: python model_inference.py --snapshotdate \"2017-01-06\" --modelname \"reg_2018_04_01.pkl\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "25/06/26 23:34:43 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "25/06/26 23:34:44 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.\n",
      "25/06/26 23:34:44 WARN Utils: Service 'SparkUI' could not bind on port 4041. Attempting port 4042.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "---starting job---\n",
      "\n",
      "\n",
      "{'model_artefact_filepath': 'model_bank/reg_2018_04_01.pkl',\n",
      " 'model_bank_directory': 'model_bank/',\n",
      " 'model_name': 'reg_2018_04_01.pkl',\n",
      " 'snapshot_date': datetime.datetime(2017, 1, 6, 0, 0),\n",
      " 'snapshot_date_str': '2017-01-06'}\n",
      "Model loaded successfully! model_bank/reg_2018_04_01.pkl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving labels:   0%|          | 0/1 [00:00<?, ?it/s]/opt/anaconda3/envs/mle_env/lib/python3.10/site-packages/sklearn/utils/validation.py:2732: UserWarning: X has feature names, but StandardScaler was fitted without feature names\n",
      "  warnings.warn(\n",
      "Saving labels: 100%|██████████| 1/1 [00:02<00:00,  2.63s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_inference 4\n",
      "num of rows add:4\n",
      "datamart/gold/model_predictions/reg_2018_04_01/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved to: datamart/gold/model_predictions/reg_2018_04_01/reg_2018_04_01_predictions_2017_01_06.parquet\n",
      "rows added: 4\n",
      "\n",
      "\n",
      "---completed job---\n",
      "\n",
      "\n",
      "execute command: python model_inference.py --snapshotdate \"2017-01-07\" --modelname \"reg_2018_04_01.pkl\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "25/06/26 23:34:52 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "25/06/26 23:34:52 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.\n",
      "25/06/26 23:34:52 WARN Utils: Service 'SparkUI' could not bind on port 4041. Attempting port 4042.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "---starting job---\n",
      "\n",
      "\n",
      "{'model_artefact_filepath': 'model_bank/reg_2018_04_01.pkl',\n",
      " 'model_bank_directory': 'model_bank/',\n",
      " 'model_name': 'reg_2018_04_01.pkl',\n",
      " 'snapshot_date': datetime.datetime(2017, 1, 7, 0, 0),\n",
      " 'snapshot_date_str': '2017-01-07'}\n",
      "Model loaded successfully! model_bank/reg_2018_04_01.pkl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving labels:   0%|          | 0/1 [00:00<?, ?it/s]/opt/anaconda3/envs/mle_env/lib/python3.10/site-packages/sklearn/utils/validation.py:2732: UserWarning: X has feature names, but StandardScaler was fitted without feature names\n",
      "  warnings.warn(\n",
      "Saving labels: 100%|██████████| 1/1 [00:02<00:00,  2.58s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_inference 4\n",
      "num of rows add:4\n",
      "datamart/gold/model_predictions/reg_2018_04_01/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved to: datamart/gold/model_predictions/reg_2018_04_01/reg_2018_04_01_predictions_2017_01_07.parquet\n",
      "rows added: 4\n",
      "\n",
      "\n",
      "---completed job---\n",
      "\n",
      "\n",
      "execute command: python model_inference.py --snapshotdate \"2017-01-08\" --modelname \"reg_2018_04_01.pkl\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "25/06/26 23:35:00 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "25/06/26 23:35:00 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.\n",
      "25/06/26 23:35:00 WARN Utils: Service 'SparkUI' could not bind on port 4041. Attempting port 4042.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "---starting job---\n",
      "\n",
      "\n",
      "{'model_artefact_filepath': 'model_bank/reg_2018_04_01.pkl',\n",
      " 'model_bank_directory': 'model_bank/',\n",
      " 'model_name': 'reg_2018_04_01.pkl',\n",
      " 'snapshot_date': datetime.datetime(2017, 1, 8, 0, 0),\n",
      " 'snapshot_date_str': '2017-01-08'}\n",
      "Model loaded successfully! model_bank/reg_2018_04_01.pkl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving labels:   0%|          | 0/1 [00:00<?, ?it/s]/opt/anaconda3/envs/mle_env/lib/python3.10/site-packages/sklearn/utils/validation.py:2732: UserWarning: X has feature names, but StandardScaler was fitted without feature names\n",
      "  warnings.warn(\n",
      "Saving labels: 100%|██████████| 1/1 [00:02<00:00,  2.53s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_inference 4\n",
      "num of rows add:4\n",
      "datamart/gold/model_predictions/reg_2018_04_01/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved to: datamart/gold/model_predictions/reg_2018_04_01/reg_2018_04_01_predictions_2017_01_08.parquet\n",
      "rows added: 4\n",
      "\n",
      "\n",
      "---completed job---\n",
      "\n",
      "\n",
      "execute command: python model_inference.py --snapshotdate \"2017-01-09\" --modelname \"reg_2018_04_01.pkl\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "25/06/26 23:35:08 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "25/06/26 23:35:09 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.\n",
      "25/06/26 23:35:09 WARN Utils: Service 'SparkUI' could not bind on port 4041. Attempting port 4042.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "---starting job---\n",
      "\n",
      "\n",
      "{'model_artefact_filepath': 'model_bank/reg_2018_04_01.pkl',\n",
      " 'model_bank_directory': 'model_bank/',\n",
      " 'model_name': 'reg_2018_04_01.pkl',\n",
      " 'snapshot_date': datetime.datetime(2017, 1, 9, 0, 0),\n",
      " 'snapshot_date_str': '2017-01-09'}\n",
      "Model loaded successfully! model_bank/reg_2018_04_01.pkl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving labels:   0%|          | 0/1 [00:00<?, ?it/s]/opt/anaconda3/envs/mle_env/lib/python3.10/site-packages/sklearn/utils/validation.py:2732: UserWarning: X has feature names, but StandardScaler was fitted without feature names\n",
      "  warnings.warn(\n",
      "Saving labels: 100%|██████████| 1/1 [00:02<00:00,  2.61s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_inference 5\n",
      "num of rows add:5\n",
      "datamart/gold/model_predictions/reg_2018_04_01/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved to: datamart/gold/model_predictions/reg_2018_04_01/reg_2018_04_01_predictions_2017_01_09.parquet\n",
      "rows added: 5\n",
      "\n",
      "\n",
      "---completed job---\n",
      "\n",
      "\n",
      "execute command: python model_inference.py --snapshotdate \"2017-01-10\" --modelname \"reg_2018_04_01.pkl\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "25/06/26 23:35:17 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "25/06/26 23:35:17 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.\n",
      "25/06/26 23:35:17 WARN Utils: Service 'SparkUI' could not bind on port 4041. Attempting port 4042.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "---starting job---\n",
      "\n",
      "\n",
      "{'model_artefact_filepath': 'model_bank/reg_2018_04_01.pkl',\n",
      " 'model_bank_directory': 'model_bank/',\n",
      " 'model_name': 'reg_2018_04_01.pkl',\n",
      " 'snapshot_date': datetime.datetime(2017, 1, 10, 0, 0),\n",
      " 'snapshot_date_str': '2017-01-10'}\n",
      "Model loaded successfully! model_bank/reg_2018_04_01.pkl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving labels:   0%|          | 0/1 [00:00<?, ?it/s]/opt/anaconda3/envs/mle_env/lib/python3.10/site-packages/sklearn/utils/validation.py:2732: UserWarning: X has feature names, but StandardScaler was fitted without feature names\n",
      "  warnings.warn(\n",
      "Saving labels: 100%|██████████| 1/1 [00:02<00:00,  2.76s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_inference 6\n",
      "num of rows add:6\n",
      "datamart/gold/model_predictions/reg_2018_04_01/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved to: datamart/gold/model_predictions/reg_2018_04_01/reg_2018_04_01_predictions_2017_01_10.parquet\n",
      "rows added: 6\n",
      "\n",
      "\n",
      "---completed job---\n",
      "\n",
      "\n",
      "execute command: python model_inference.py --snapshotdate \"2017-01-11\" --modelname \"reg_2018_04_01.pkl\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "25/06/26 23:35:25 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "25/06/26 23:35:26 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.\n",
      "25/06/26 23:35:26 WARN Utils: Service 'SparkUI' could not bind on port 4041. Attempting port 4042.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "---starting job---\n",
      "\n",
      "\n",
      "{'model_artefact_filepath': 'model_bank/reg_2018_04_01.pkl',\n",
      " 'model_bank_directory': 'model_bank/',\n",
      " 'model_name': 'reg_2018_04_01.pkl',\n",
      " 'snapshot_date': datetime.datetime(2017, 1, 11, 0, 0),\n",
      " 'snapshot_date_str': '2017-01-11'}\n",
      "Model loaded successfully! model_bank/reg_2018_04_01.pkl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving labels:   0%|          | 0/1 [00:00<?, ?it/s]/opt/anaconda3/envs/mle_env/lib/python3.10/site-packages/sklearn/utils/validation.py:2732: UserWarning: X has feature names, but StandardScaler was fitted without feature names\n",
      "  warnings.warn(\n",
      "Saving labels: 100%|██████████| 1/1 [00:02<00:00,  2.74s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_inference 10\n",
      "num of rows add:10\n",
      "datamart/gold/model_predictions/reg_2018_04_01/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved to: datamart/gold/model_predictions/reg_2018_04_01/reg_2018_04_01_predictions_2017_01_11.parquet\n",
      "rows added: 10\n",
      "\n",
      "\n",
      "---completed job---\n",
      "\n",
      "\n",
      "execute command: python model_inference.py --snapshotdate \"2017-01-12\" --modelname \"reg_2018_04_01.pkl\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "25/06/26 23:35:34 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "25/06/26 23:35:35 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.\n",
      "25/06/26 23:35:35 WARN Utils: Service 'SparkUI' could not bind on port 4041. Attempting port 4042.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "---starting job---\n",
      "\n",
      "\n",
      "{'model_artefact_filepath': 'model_bank/reg_2018_04_01.pkl',\n",
      " 'model_bank_directory': 'model_bank/',\n",
      " 'model_name': 'reg_2018_04_01.pkl',\n",
      " 'snapshot_date': datetime.datetime(2017, 1, 12, 0, 0),\n",
      " 'snapshot_date_str': '2017-01-12'}\n",
      "Model loaded successfully! model_bank/reg_2018_04_01.pkl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving labels:   0%|          | 0/1 [00:00<?, ?it/s]/opt/anaconda3/envs/mle_env/lib/python3.10/site-packages/sklearn/utils/validation.py:2732: UserWarning: X has feature names, but StandardScaler was fitted without feature names\n",
      "  warnings.warn(\n",
      "Saving labels: 100%|██████████| 1/1 [00:02<00:00,  2.63s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_inference 12\n",
      "num of rows add:12\n",
      "datamart/gold/model_predictions/reg_2018_04_01/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved to: datamart/gold/model_predictions/reg_2018_04_01/reg_2018_04_01_predictions_2017_01_12.parquet\n",
      "rows added: 12\n",
      "\n",
      "\n",
      "---completed job---\n",
      "\n",
      "\n",
      "execute command: python model_inference.py --snapshotdate \"2017-01-13\" --modelname \"reg_2018_04_01.pkl\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "25/06/26 23:35:43 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "25/06/26 23:35:43 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.\n",
      "25/06/26 23:35:43 WARN Utils: Service 'SparkUI' could not bind on port 4041. Attempting port 4042.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "---starting job---\n",
      "\n",
      "\n",
      "{'model_artefact_filepath': 'model_bank/reg_2018_04_01.pkl',\n",
      " 'model_bank_directory': 'model_bank/',\n",
      " 'model_name': 'reg_2018_04_01.pkl',\n",
      " 'snapshot_date': datetime.datetime(2017, 1, 13, 0, 0),\n",
      " 'snapshot_date_str': '2017-01-13'}\n",
      "Model loaded successfully! model_bank/reg_2018_04_01.pkl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving labels:   0%|          | 0/1 [00:00<?, ?it/s]/opt/anaconda3/envs/mle_env/lib/python3.10/site-packages/sklearn/utils/validation.py:2732: UserWarning: X has feature names, but StandardScaler was fitted without feature names\n",
      "  warnings.warn(\n",
      "Saving labels: 100%|██████████| 1/1 [00:02<00:00,  2.80s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_inference 10\n",
      "num of rows add:10\n",
      "datamart/gold/model_predictions/reg_2018_04_01/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved to: datamart/gold/model_predictions/reg_2018_04_01/reg_2018_04_01_predictions_2017_01_13.parquet\n",
      "rows added: 10\n",
      "\n",
      "\n",
      "---completed job---\n",
      "\n",
      "\n",
      "execute command: python model_inference.py --snapshotdate \"2017-01-14\" --modelname \"reg_2018_04_01.pkl\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "25/06/26 23:35:52 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "25/06/26 23:35:53 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.\n",
      "25/06/26 23:35:53 WARN Utils: Service 'SparkUI' could not bind on port 4041. Attempting port 4042.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "---starting job---\n",
      "\n",
      "\n",
      "{'model_artefact_filepath': 'model_bank/reg_2018_04_01.pkl',\n",
      " 'model_bank_directory': 'model_bank/',\n",
      " 'model_name': 'reg_2018_04_01.pkl',\n",
      " 'snapshot_date': datetime.datetime(2017, 1, 14, 0, 0),\n",
      " 'snapshot_date_str': '2017-01-14'}\n",
      "Model loaded successfully! model_bank/reg_2018_04_01.pkl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving labels:   0%|          | 0/1 [00:00<?, ?it/s]/opt/anaconda3/envs/mle_env/lib/python3.10/site-packages/sklearn/utils/validation.py:2732: UserWarning: X has feature names, but StandardScaler was fitted without feature names\n",
      "  warnings.warn(\n",
      "Saving labels: 100%|██████████| 1/1 [00:02<00:00,  2.67s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_inference 16\n",
      "num of rows add:16\n",
      "datamart/gold/model_predictions/reg_2018_04_01/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved to: datamart/gold/model_predictions/reg_2018_04_01/reg_2018_04_01_predictions_2017_01_14.parquet\n",
      "rows added: 16\n",
      "\n",
      "\n",
      "---completed job---\n",
      "\n",
      "\n",
      "execute command: python model_inference.py --snapshotdate \"2017-01-15\" --modelname \"reg_2018_04_01.pkl\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "25/06/26 23:36:01 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "25/06/26 23:36:01 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.\n",
      "25/06/26 23:36:01 WARN Utils: Service 'SparkUI' could not bind on port 4041. Attempting port 4042.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "---starting job---\n",
      "\n",
      "\n",
      "{'model_artefact_filepath': 'model_bank/reg_2018_04_01.pkl',\n",
      " 'model_bank_directory': 'model_bank/',\n",
      " 'model_name': 'reg_2018_04_01.pkl',\n",
      " 'snapshot_date': datetime.datetime(2017, 1, 15, 0, 0),\n",
      " 'snapshot_date_str': '2017-01-15'}\n",
      "Model loaded successfully! model_bank/reg_2018_04_01.pkl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving labels:   0%|          | 0/1 [00:00<?, ?it/s]/opt/anaconda3/envs/mle_env/lib/python3.10/site-packages/sklearn/utils/validation.py:2732: UserWarning: X has feature names, but StandardScaler was fitted without feature names\n",
      "  warnings.warn(\n",
      "Saving labels: 100%|██████████| 1/1 [00:02<00:00,  2.77s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_inference 14\n",
      "num of rows add:14\n",
      "datamart/gold/model_predictions/reg_2018_04_01/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved to: datamart/gold/model_predictions/reg_2018_04_01/reg_2018_04_01_predictions_2017_01_15.parquet\n",
      "rows added: 14\n",
      "\n",
      "\n",
      "---completed job---\n",
      "\n",
      "\n",
      "execute command: python model_inference.py --snapshotdate \"2017-01-16\" --modelname \"reg_2018_04_01.pkl\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "25/06/26 23:36:09 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "25/06/26 23:36:10 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.\n",
      "25/06/26 23:36:10 WARN Utils: Service 'SparkUI' could not bind on port 4041. Attempting port 4042.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "---starting job---\n",
      "\n",
      "\n",
      "{'model_artefact_filepath': 'model_bank/reg_2018_04_01.pkl',\n",
      " 'model_bank_directory': 'model_bank/',\n",
      " 'model_name': 'reg_2018_04_01.pkl',\n",
      " 'snapshot_date': datetime.datetime(2017, 1, 16, 0, 0),\n",
      " 'snapshot_date_str': '2017-01-16'}\n",
      "Model loaded successfully! model_bank/reg_2018_04_01.pkl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving labels:   0%|          | 0/1 [00:00<?, ?it/s]/opt/anaconda3/envs/mle_env/lib/python3.10/site-packages/sklearn/utils/validation.py:2732: UserWarning: X has feature names, but StandardScaler was fitted without feature names\n",
      "  warnings.warn(\n",
      "Saving labels: 100%|██████████| 1/1 [00:02<00:00,  2.65s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_inference 18\n",
      "num of rows add:18\n",
      "datamart/gold/model_predictions/reg_2018_04_01/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved to: datamart/gold/model_predictions/reg_2018_04_01/reg_2018_04_01_predictions_2017_01_16.parquet\n",
      "rows added: 18\n",
      "\n",
      "\n",
      "---completed job---\n",
      "\n",
      "\n",
      "execute command: python model_inference.py --snapshotdate \"2017-01-17\" --modelname \"reg_2018_04_01.pkl\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "25/06/26 23:36:18 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "25/06/26 23:36:18 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.\n",
      "25/06/26 23:36:18 WARN Utils: Service 'SparkUI' could not bind on port 4041. Attempting port 4042.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "---starting job---\n",
      "\n",
      "\n",
      "{'model_artefact_filepath': 'model_bank/reg_2018_04_01.pkl',\n",
      " 'model_bank_directory': 'model_bank/',\n",
      " 'model_name': 'reg_2018_04_01.pkl',\n",
      " 'snapshot_date': datetime.datetime(2017, 1, 17, 0, 0),\n",
      " 'snapshot_date_str': '2017-01-17'}\n",
      "Model loaded successfully! model_bank/reg_2018_04_01.pkl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving labels:   0%|          | 0/1 [00:00<?, ?it/s]/opt/anaconda3/envs/mle_env/lib/python3.10/site-packages/sklearn/utils/validation.py:2732: UserWarning: X has feature names, but StandardScaler was fitted without feature names\n",
      "  warnings.warn(\n",
      "Saving labels: 100%|██████████| 1/1 [00:02<00:00,  2.64s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_inference 32\n",
      "num of rows add:32\n",
      "datamart/gold/model_predictions/reg_2018_04_01/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved to: datamart/gold/model_predictions/reg_2018_04_01/reg_2018_04_01_predictions_2017_01_17.parquet\n",
      "rows added: 32\n",
      "\n",
      "\n",
      "---completed job---\n",
      "\n",
      "\n",
      "execute command: python model_inference.py --snapshotdate \"2017-01-18\" --modelname \"reg_2018_04_01.pkl\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "25/06/26 23:36:26 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "25/06/26 23:36:27 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.\n",
      "25/06/26 23:36:27 WARN Utils: Service 'SparkUI' could not bind on port 4041. Attempting port 4042.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "---starting job---\n",
      "\n",
      "\n",
      "{'model_artefact_filepath': 'model_bank/reg_2018_04_01.pkl',\n",
      " 'model_bank_directory': 'model_bank/',\n",
      " 'model_name': 'reg_2018_04_01.pkl',\n",
      " 'snapshot_date': datetime.datetime(2017, 1, 18, 0, 0),\n",
      " 'snapshot_date_str': '2017-01-18'}\n",
      "Model loaded successfully! model_bank/reg_2018_04_01.pkl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving labels:   0%|          | 0/1 [00:00<?, ?it/s]/opt/anaconda3/envs/mle_env/lib/python3.10/site-packages/sklearn/utils/validation.py:2732: UserWarning: X has feature names, but StandardScaler was fitted without feature names\n",
      "  warnings.warn(\n",
      "Saving labels: 100%|██████████| 1/1 [00:02<00:00,  2.67s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_inference 30\n",
      "num of rows add:30\n",
      "datamart/gold/model_predictions/reg_2018_04_01/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved to: datamart/gold/model_predictions/reg_2018_04_01/reg_2018_04_01_predictions_2017_01_18.parquet\n",
      "rows added: 30\n",
      "\n",
      "\n",
      "---completed job---\n",
      "\n",
      "\n",
      "execute command: python model_inference.py --snapshotdate \"2017-01-19\" --modelname \"reg_2018_04_01.pkl\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "25/06/26 23:36:35 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "25/06/26 23:36:35 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.\n",
      "25/06/26 23:36:35 WARN Utils: Service 'SparkUI' could not bind on port 4041. Attempting port 4042.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "---starting job---\n",
      "\n",
      "\n",
      "{'model_artefact_filepath': 'model_bank/reg_2018_04_01.pkl',\n",
      " 'model_bank_directory': 'model_bank/',\n",
      " 'model_name': 'reg_2018_04_01.pkl',\n",
      " 'snapshot_date': datetime.datetime(2017, 1, 19, 0, 0),\n",
      " 'snapshot_date_str': '2017-01-19'}\n",
      "Model loaded successfully! model_bank/reg_2018_04_01.pkl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving labels:   0%|          | 0/1 [00:00<?, ?it/s]/opt/anaconda3/envs/mle_env/lib/python3.10/site-packages/sklearn/utils/validation.py:2732: UserWarning: X has feature names, but StandardScaler was fitted without feature names\n",
      "  warnings.warn(\n",
      "Saving labels: 100%|██████████| 1/1 [00:02<00:00,  2.61s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_inference 29\n",
      "num of rows add:29\n",
      "datamart/gold/model_predictions/reg_2018_04_01/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved to: datamart/gold/model_predictions/reg_2018_04_01/reg_2018_04_01_predictions_2017_01_19.parquet\n",
      "rows added: 29\n",
      "\n",
      "\n",
      "---completed job---\n",
      "\n",
      "\n",
      "execute command: python model_inference.py --snapshotdate \"2017-01-20\" --modelname \"reg_2018_04_01.pkl\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "25/06/26 23:36:43 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "25/06/26 23:36:44 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.\n",
      "25/06/26 23:36:44 WARN Utils: Service 'SparkUI' could not bind on port 4041. Attempting port 4042.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "---starting job---\n",
      "\n",
      "\n",
      "{'model_artefact_filepath': 'model_bank/reg_2018_04_01.pkl',\n",
      " 'model_bank_directory': 'model_bank/',\n",
      " 'model_name': 'reg_2018_04_01.pkl',\n",
      " 'snapshot_date': datetime.datetime(2017, 1, 20, 0, 0),\n",
      " 'snapshot_date_str': '2017-01-20'}\n",
      "Model loaded successfully! model_bank/reg_2018_04_01.pkl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/mle_env/lib/python3.10/site-packages/sklearn/utils/validation.py:2732: UserWarning: X has feature names, but StandardScaler was fitted without feature names\n",
      "  warnings.warn(\n",
      "Saving labels: 100%|██████████| 1/1 [00:03<00:00,  3.09s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_inference 28\n",
      "num of rows add:28\n",
      "datamart/gold/model_predictions/reg_2018_04_01/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved to: datamart/gold/model_predictions/reg_2018_04_01/reg_2018_04_01_predictions_2017_01_20.parquet\n",
      "rows added: 28\n",
      "\n",
      "\n",
      "---completed job---\n",
      "\n",
      "\n",
      "execute command: python model_inference.py --snapshotdate \"2017-01-21\" --modelname \"reg_2018_04_01.pkl\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "25/06/26 23:36:52 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "25/06/26 23:36:53 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.\n",
      "25/06/26 23:36:53 WARN Utils: Service 'SparkUI' could not bind on port 4041. Attempting port 4042.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "---starting job---\n",
      "\n",
      "\n",
      "{'model_artefact_filepath': 'model_bank/reg_2018_04_01.pkl',\n",
      " 'model_bank_directory': 'model_bank/',\n",
      " 'model_name': 'reg_2018_04_01.pkl',\n",
      " 'snapshot_date': datetime.datetime(2017, 1, 21, 0, 0),\n",
      " 'snapshot_date_str': '2017-01-21'}\n",
      "Model loaded successfully! model_bank/reg_2018_04_01.pkl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving labels:   0%|          | 0/1 [00:00<?, ?it/s]/opt/anaconda3/envs/mle_env/lib/python3.10/site-packages/sklearn/utils/validation.py:2732: UserWarning: X has feature names, but StandardScaler was fitted without feature names\n",
      "  warnings.warn(\n",
      "Saving labels: 100%|██████████| 1/1 [00:02<00:00,  2.98s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_inference 22\n",
      "num of rows add:22\n",
      "datamart/gold/model_predictions/reg_2018_04_01/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved to: datamart/gold/model_predictions/reg_2018_04_01/reg_2018_04_01_predictions_2017_01_21.parquet\n",
      "rows added: 22\n",
      "\n",
      "\n",
      "---completed job---\n",
      "\n",
      "\n",
      "execute command: python model_inference.py --snapshotdate \"2017-01-22\" --modelname \"reg_2018_04_01.pkl\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "25/06/26 23:37:02 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "25/06/26 23:37:02 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.\n",
      "25/06/26 23:37:02 WARN Utils: Service 'SparkUI' could not bind on port 4041. Attempting port 4042.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "---starting job---\n",
      "\n",
      "\n",
      "{'model_artefact_filepath': 'model_bank/reg_2018_04_01.pkl',\n",
      " 'model_bank_directory': 'model_bank/',\n",
      " 'model_name': 'reg_2018_04_01.pkl',\n",
      " 'snapshot_date': datetime.datetime(2017, 1, 22, 0, 0),\n",
      " 'snapshot_date_str': '2017-01-22'}\n",
      "Model loaded successfully! model_bank/reg_2018_04_01.pkl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/mle_env/lib/python3.10/site-packages/sklearn/utils/validation.py:2732: UserWarning: X has feature names, but StandardScaler was fitted without feature names\n",
      "  warnings.warn(\n",
      "Saving labels: 100%|██████████| 1/1 [00:02<00:00,  2.71s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_inference 30\n",
      "num of rows add:30\n",
      "datamart/gold/model_predictions/reg_2018_04_01/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved to: datamart/gold/model_predictions/reg_2018_04_01/reg_2018_04_01_predictions_2017_01_22.parquet\n",
      "rows added: 30\n",
      "\n",
      "\n",
      "---completed job---\n",
      "\n",
      "\n",
      "execute command: python model_inference.py --snapshotdate \"2017-01-23\" --modelname \"reg_2018_04_01.pkl\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "25/06/26 23:37:12 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "25/06/26 23:37:13 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.\n",
      "25/06/26 23:37:13 WARN Utils: Service 'SparkUI' could not bind on port 4041. Attempting port 4042.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "---starting job---\n",
      "\n",
      "\n",
      "{'model_artefact_filepath': 'model_bank/reg_2018_04_01.pkl',\n",
      " 'model_bank_directory': 'model_bank/',\n",
      " 'model_name': 'reg_2018_04_01.pkl',\n",
      " 'snapshot_date': datetime.datetime(2017, 1, 23, 0, 0),\n",
      " 'snapshot_date_str': '2017-01-23'}\n",
      "Model loaded successfully! model_bank/reg_2018_04_01.pkl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving labels:   0%|          | 0/1 [00:00<?, ?it/s]/opt/anaconda3/envs/mle_env/lib/python3.10/site-packages/sklearn/utils/validation.py:2732: UserWarning: X has feature names, but StandardScaler was fitted without feature names\n",
      "  warnings.warn(\n",
      "Saving labels: 100%|██████████| 1/1 [00:02<00:00,  2.72s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_inference 36\n",
      "num of rows add:36\n",
      "datamart/gold/model_predictions/reg_2018_04_01/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved to: datamart/gold/model_predictions/reg_2018_04_01/reg_2018_04_01_predictions_2017_01_23.parquet\n",
      "rows added: 36\n",
      "\n",
      "\n",
      "---completed job---\n",
      "\n",
      "\n",
      "execute command: python model_inference.py --snapshotdate \"2017-01-24\" --modelname \"reg_2018_04_01.pkl\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "25/06/26 23:37:21 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "25/06/26 23:37:21 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.\n",
      "25/06/26 23:37:21 WARN Utils: Service 'SparkUI' could not bind on port 4041. Attempting port 4042.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "---starting job---\n",
      "\n",
      "\n",
      "{'model_artefact_filepath': 'model_bank/reg_2018_04_01.pkl',\n",
      " 'model_bank_directory': 'model_bank/',\n",
      " 'model_name': 'reg_2018_04_01.pkl',\n",
      " 'snapshot_date': datetime.datetime(2017, 1, 24, 0, 0),\n",
      " 'snapshot_date_str': '2017-01-24'}\n",
      "Model loaded successfully! model_bank/reg_2018_04_01.pkl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving labels:   0%|          | 0/1 [00:00<?, ?it/s]/opt/anaconda3/envs/mle_env/lib/python3.10/site-packages/sklearn/utils/validation.py:2732: UserWarning: X has feature names, but StandardScaler was fitted without feature names\n",
      "  warnings.warn(\n",
      "Saving labels: 100%|██████████| 1/1 [00:02<00:00,  2.60s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_inference 38\n",
      "num of rows add:38\n",
      "datamart/gold/model_predictions/reg_2018_04_01/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved to: datamart/gold/model_predictions/reg_2018_04_01/reg_2018_04_01_predictions_2017_01_24.parquet\n",
      "rows added: 38\n",
      "\n",
      "\n",
      "---completed job---\n",
      "\n",
      "\n",
      "execute command: python model_inference.py --snapshotdate \"2017-01-25\" --modelname \"reg_2018_04_01.pkl\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "25/06/26 23:37:29 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "25/06/26 23:37:30 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.\n",
      "25/06/26 23:37:30 WARN Utils: Service 'SparkUI' could not bind on port 4041. Attempting port 4042.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "---starting job---\n",
      "\n",
      "\n",
      "{'model_artefact_filepath': 'model_bank/reg_2018_04_01.pkl',\n",
      " 'model_bank_directory': 'model_bank/',\n",
      " 'model_name': 'reg_2018_04_01.pkl',\n",
      " 'snapshot_date': datetime.datetime(2017, 1, 25, 0, 0),\n",
      " 'snapshot_date_str': '2017-01-25'}\n",
      "Model loaded successfully! model_bank/reg_2018_04_01.pkl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving labels:   0%|          | 0/1 [00:00<?, ?it/s]/opt/anaconda3/envs/mle_env/lib/python3.10/site-packages/sklearn/utils/validation.py:2732: UserWarning: X has feature names, but StandardScaler was fitted without feature names\n",
      "  warnings.warn(\n",
      "Saving labels: 100%|██████████| 1/1 [00:02<00:00,  2.66s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_inference 57\n",
      "num of rows add:57\n",
      "datamart/gold/model_predictions/reg_2018_04_01/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved to: datamart/gold/model_predictions/reg_2018_04_01/reg_2018_04_01_predictions_2017_01_25.parquet\n",
      "rows added: 57\n",
      "\n",
      "\n",
      "---completed job---\n",
      "\n",
      "\n",
      "execute command: python model_inference.py --snapshotdate \"2017-01-26\" --modelname \"reg_2018_04_01.pkl\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "25/06/26 23:37:37 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "25/06/26 23:37:38 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.\n",
      "25/06/26 23:37:38 WARN Utils: Service 'SparkUI' could not bind on port 4041. Attempting port 4042.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "---starting job---\n",
      "\n",
      "\n",
      "{'model_artefact_filepath': 'model_bank/reg_2018_04_01.pkl',\n",
      " 'model_bank_directory': 'model_bank/',\n",
      " 'model_name': 'reg_2018_04_01.pkl',\n",
      " 'snapshot_date': datetime.datetime(2017, 1, 26, 0, 0),\n",
      " 'snapshot_date_str': '2017-01-26'}\n",
      "Model loaded successfully! model_bank/reg_2018_04_01.pkl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving labels:   0%|          | 0/1 [00:00<?, ?it/s]/opt/anaconda3/envs/mle_env/lib/python3.10/site-packages/sklearn/utils/validation.py:2732: UserWarning: X has feature names, but StandardScaler was fitted without feature names\n",
      "  warnings.warn(\n",
      "Saving labels: 100%|██████████| 1/1 [00:02<00:00,  2.57s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_inference 82\n",
      "num of rows add:82\n",
      "datamart/gold/model_predictions/reg_2018_04_01/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved to: datamart/gold/model_predictions/reg_2018_04_01/reg_2018_04_01_predictions_2017_01_26.parquet\n",
      "rows added: 82\n",
      "\n",
      "\n",
      "---completed job---\n",
      "\n",
      "\n",
      "execute command: python model_inference.py --snapshotdate \"2017-01-27\" --modelname \"reg_2018_04_01.pkl\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "25/06/26 23:37:46 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "25/06/26 23:37:46 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.\n",
      "25/06/26 23:37:46 WARN Utils: Service 'SparkUI' could not bind on port 4041. Attempting port 4042.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "---starting job---\n",
      "\n",
      "\n",
      "{'model_artefact_filepath': 'model_bank/reg_2018_04_01.pkl',\n",
      " 'model_bank_directory': 'model_bank/',\n",
      " 'model_name': 'reg_2018_04_01.pkl',\n",
      " 'snapshot_date': datetime.datetime(2017, 1, 27, 0, 0),\n",
      " 'snapshot_date_str': '2017-01-27'}\n",
      "Model loaded successfully! model_bank/reg_2018_04_01.pkl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving labels:   0%|          | 0/1 [00:00<?, ?it/s]/opt/anaconda3/envs/mle_env/lib/python3.10/site-packages/sklearn/utils/validation.py:2732: UserWarning: X has feature names, but StandardScaler was fitted without feature names\n",
      "  warnings.warn(\n",
      "Saving labels: 100%|██████████| 1/1 [00:02<00:00,  2.69s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_inference 59\n",
      "num of rows add:59\n",
      "datamart/gold/model_predictions/reg_2018_04_01/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved to: datamart/gold/model_predictions/reg_2018_04_01/reg_2018_04_01_predictions_2017_01_27.parquet\n",
      "rows added: 59\n",
      "\n",
      "\n",
      "---completed job---\n",
      "\n",
      "\n",
      "execute command: python model_inference.py --snapshotdate \"2017-01-28\" --modelname \"reg_2018_04_01.pkl\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "25/06/26 23:37:54 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "25/06/26 23:37:55 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.\n",
      "25/06/26 23:37:55 WARN Utils: Service 'SparkUI' could not bind on port 4041. Attempting port 4042.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "---starting job---\n",
      "\n",
      "\n",
      "{'model_artefact_filepath': 'model_bank/reg_2018_04_01.pkl',\n",
      " 'model_bank_directory': 'model_bank/',\n",
      " 'model_name': 'reg_2018_04_01.pkl',\n",
      " 'snapshot_date': datetime.datetime(2017, 1, 28, 0, 0),\n",
      " 'snapshot_date_str': '2017-01-28'}\n",
      "Model loaded successfully! model_bank/reg_2018_04_01.pkl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving labels:   0%|          | 0/1 [00:00<?, ?it/s]/opt/anaconda3/envs/mle_env/lib/python3.10/site-packages/sklearn/utils/validation.py:2732: UserWarning: X has feature names, but StandardScaler was fitted without feature names\n",
      "  warnings.warn(\n",
      "Saving labels: 100%|██████████| 1/1 [00:02<00:00,  2.71s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_inference 28\n",
      "num of rows add:28\n",
      "datamart/gold/model_predictions/reg_2018_04_01/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved to: datamart/gold/model_predictions/reg_2018_04_01/reg_2018_04_01_predictions_2017_01_28.parquet\n",
      "rows added: 28\n",
      "\n",
      "\n",
      "---completed job---\n",
      "\n",
      "\n",
      "execute command: python model_inference.py --snapshotdate \"2017-01-29\" --modelname \"reg_2018_04_01.pkl\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "25/06/26 23:38:03 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "25/06/26 23:38:03 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.\n",
      "25/06/26 23:38:03 WARN Utils: Service 'SparkUI' could not bind on port 4041. Attempting port 4042.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "---starting job---\n",
      "\n",
      "\n",
      "{'model_artefact_filepath': 'model_bank/reg_2018_04_01.pkl',\n",
      " 'model_bank_directory': 'model_bank/',\n",
      " 'model_name': 'reg_2018_04_01.pkl',\n",
      " 'snapshot_date': datetime.datetime(2017, 1, 29, 0, 0),\n",
      " 'snapshot_date_str': '2017-01-29'}\n",
      "Model loaded successfully! model_bank/reg_2018_04_01.pkl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/mle_env/lib/python3.10/site-packages/sklearn/utils/validation.py:2732: UserWarning: X has feature names, but StandardScaler was fitted without feature names\n",
      "  warnings.warn(\n",
      "Saving labels: 100%|██████████| 1/1 [00:02<00:00,  2.75s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_inference 31\n",
      "num of rows add:31\n",
      "datamart/gold/model_predictions/reg_2018_04_01/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved to: datamart/gold/model_predictions/reg_2018_04_01/reg_2018_04_01_predictions_2017_01_29.parquet\n",
      "rows added: 31\n",
      "\n",
      "\n",
      "---completed job---\n",
      "\n",
      "\n",
      "execute command: python model_inference.py --snapshotdate \"2017-01-30\" --modelname \"reg_2018_04_01.pkl\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "25/06/26 23:38:12 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "25/06/26 23:38:12 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.\n",
      "25/06/26 23:38:12 WARN Utils: Service 'SparkUI' could not bind on port 4041. Attempting port 4042.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "---starting job---\n",
      "\n",
      "\n",
      "{'model_artefact_filepath': 'model_bank/reg_2018_04_01.pkl',\n",
      " 'model_bank_directory': 'model_bank/',\n",
      " 'model_name': 'reg_2018_04_01.pkl',\n",
      " 'snapshot_date': datetime.datetime(2017, 1, 30, 0, 0),\n",
      " 'snapshot_date_str': '2017-01-30'}\n",
      "Model loaded successfully! model_bank/reg_2018_04_01.pkl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving labels:   0%|          | 0/1 [00:00<?, ?it/s]/opt/anaconda3/envs/mle_env/lib/python3.10/site-packages/sklearn/utils/validation.py:2732: UserWarning: X has feature names, but StandardScaler was fitted without feature names\n",
      "  warnings.warn(\n",
      "Saving labels: 100%|██████████| 1/1 [00:02<00:00,  2.63s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_inference 48\n",
      "num of rows add:48\n",
      "datamart/gold/model_predictions/reg_2018_04_01/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved to: datamart/gold/model_predictions/reg_2018_04_01/reg_2018_04_01_predictions_2017_01_30.parquet\n",
      "rows added: 48\n",
      "\n",
      "\n",
      "---completed job---\n",
      "\n",
      "\n",
      "execute command: python model_inference.py --snapshotdate \"2017-01-31\" --modelname \"reg_2018_04_01.pkl\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "25/06/26 23:38:20 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "25/06/26 23:38:21 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.\n",
      "25/06/26 23:38:21 WARN Utils: Service 'SparkUI' could not bind on port 4041. Attempting port 4042.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "---starting job---\n",
      "\n",
      "\n",
      "{'model_artefact_filepath': 'model_bank/reg_2018_04_01.pkl',\n",
      " 'model_bank_directory': 'model_bank/',\n",
      " 'model_name': 'reg_2018_04_01.pkl',\n",
      " 'snapshot_date': datetime.datetime(2017, 1, 31, 0, 0),\n",
      " 'snapshot_date_str': '2017-01-31'}\n",
      "Model loaded successfully! model_bank/reg_2018_04_01.pkl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving labels:   0%|          | 0/1 [00:00<?, ?it/s]/opt/anaconda3/envs/mle_env/lib/python3.10/site-packages/sklearn/utils/validation.py:2732: UserWarning: X has feature names, but StandardScaler was fitted without feature names\n",
      "  warnings.warn(\n",
      "Saving labels: 100%|██████████| 1/1 [00:02<00:00,  2.68s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_inference 64\n",
      "num of rows add:64\n",
      "datamart/gold/model_predictions/reg_2018_04_01/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved to: datamart/gold/model_predictions/reg_2018_04_01/reg_2018_04_01_predictions_2017_01_31.parquet\n",
      "rows added: 64\n",
      "\n",
      "\n",
      "---completed job---\n",
      "\n",
      "\n",
      "execute command: python model_inference.py --snapshotdate \"2017-02-01\" --modelname \"reg_2018_04_01.pkl\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "25/06/26 23:38:29 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "25/06/26 23:38:29 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.\n",
      "25/06/26 23:38:29 WARN Utils: Service 'SparkUI' could not bind on port 4041. Attempting port 4042.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "---starting job---\n",
      "\n",
      "\n",
      "{'model_artefact_filepath': 'model_bank/reg_2018_04_01.pkl',\n",
      " 'model_bank_directory': 'model_bank/',\n",
      " 'model_name': 'reg_2018_04_01.pkl',\n",
      " 'snapshot_date': datetime.datetime(2017, 2, 1, 0, 0),\n",
      " 'snapshot_date_str': '2017-02-01'}\n",
      "Model loaded successfully! model_bank/reg_2018_04_01.pkl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving labels:   0%|          | 0/1 [00:00<?, ?it/s]/opt/anaconda3/envs/mle_env/lib/python3.10/site-packages/sklearn/utils/validation.py:2732: UserWarning: X has feature names, but StandardScaler was fitted without feature names\n",
      "  warnings.warn(\n",
      "Saving labels: 100%|██████████| 1/1 [00:02<00:00,  2.56s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_inference 61\n",
      "num of rows add:61\n",
      "datamart/gold/model_predictions/reg_2018_04_01/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved to: datamart/gold/model_predictions/reg_2018_04_01/reg_2018_04_01_predictions_2017_02_01.parquet\n",
      "rows added: 61\n",
      "\n",
      "\n",
      "---completed job---\n",
      "\n",
      "\n",
      "execute command: python model_inference.py --snapshotdate \"2017-02-02\" --modelname \"reg_2018_04_01.pkl\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "25/06/26 23:38:37 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "25/06/26 23:38:37 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.\n",
      "25/06/26 23:38:37 WARN Utils: Service 'SparkUI' could not bind on port 4041. Attempting port 4042.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "---starting job---\n",
      "\n",
      "\n",
      "{'model_artefact_filepath': 'model_bank/reg_2018_04_01.pkl',\n",
      " 'model_bank_directory': 'model_bank/',\n",
      " 'model_name': 'reg_2018_04_01.pkl',\n",
      " 'snapshot_date': datetime.datetime(2017, 2, 2, 0, 0),\n",
      " 'snapshot_date_str': '2017-02-02'}\n",
      "Model loaded successfully! model_bank/reg_2018_04_01.pkl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/mle_env/lib/python3.10/site-packages/sklearn/utils/validation.py:2732: UserWarning: X has feature names, but StandardScaler was fitted without feature names\n",
      "  warnings.warn(\n",
      "Saving labels: 100%|██████████| 1/1 [00:06<00:00,  6.73s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_inference 67\n",
      "num of rows add:67\n",
      "datamart/gold/model_predictions/reg_2018_04_01/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved to: datamart/gold/model_predictions/reg_2018_04_01/reg_2018_04_01_predictions_2017_02_02.parquet\n",
      "rows added: 67\n",
      "\n",
      "\n",
      "---completed job---\n",
      "\n",
      "\n",
      "execute command: python model_inference.py --snapshotdate \"2017-02-03\" --modelname \"reg_2018_04_01.pkl\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "25/06/26 23:38:51 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "25/06/26 23:38:51 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.\n",
      "25/06/26 23:38:51 WARN Utils: Service 'SparkUI' could not bind on port 4041. Attempting port 4042.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "---starting job---\n",
      "\n",
      "\n",
      "{'model_artefact_filepath': 'model_bank/reg_2018_04_01.pkl',\n",
      " 'model_bank_directory': 'model_bank/',\n",
      " 'model_name': 'reg_2018_04_01.pkl',\n",
      " 'snapshot_date': datetime.datetime(2017, 2, 3, 0, 0),\n",
      " 'snapshot_date_str': '2017-02-03'}\n",
      "Model loaded successfully! model_bank/reg_2018_04_01.pkl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving labels:   0%|          | 0/1 [00:00<?, ?it/s]/opt/anaconda3/envs/mle_env/lib/python3.10/site-packages/sklearn/utils/validation.py:2732: UserWarning: X has feature names, but StandardScaler was fitted without feature names\n",
      "  warnings.warn(\n",
      "Saving labels: 100%|██████████| 1/1 [00:02<00:00,  2.76s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_inference 54\n",
      "num of rows add:54\n",
      "datamart/gold/model_predictions/reg_2018_04_01/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved to: datamart/gold/model_predictions/reg_2018_04_01/reg_2018_04_01_predictions_2017_02_03.parquet\n",
      "rows added: 54\n",
      "\n",
      "\n",
      "---completed job---\n",
      "\n",
      "\n",
      "execute command: python model_inference.py --snapshotdate \"2017-02-04\" --modelname \"reg_2018_04_01.pkl\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "25/06/26 23:39:00 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "25/06/26 23:39:01 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.\n",
      "25/06/26 23:39:01 WARN Utils: Service 'SparkUI' could not bind on port 4041. Attempting port 4042.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "---starting job---\n",
      "\n",
      "\n",
      "{'model_artefact_filepath': 'model_bank/reg_2018_04_01.pkl',\n",
      " 'model_bank_directory': 'model_bank/',\n",
      " 'model_name': 'reg_2018_04_01.pkl',\n",
      " 'snapshot_date': datetime.datetime(2017, 2, 4, 0, 0),\n",
      " 'snapshot_date_str': '2017-02-04'}\n",
      "Model loaded successfully! model_bank/reg_2018_04_01.pkl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving labels:   0%|          | 0/1 [00:00<?, ?it/s]/opt/anaconda3/envs/mle_env/lib/python3.10/site-packages/sklearn/utils/validation.py:2732: UserWarning: X has feature names, but StandardScaler was fitted without feature names\n",
      "  warnings.warn(\n",
      "Saving labels: 100%|██████████| 1/1 [00:02<00:00,  2.53s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_inference 64\n",
      "num of rows add:64\n",
      "datamart/gold/model_predictions/reg_2018_04_01/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved to: datamart/gold/model_predictions/reg_2018_04_01/reg_2018_04_01_predictions_2017_02_04.parquet\n",
      "rows added: 64\n",
      "\n",
      "\n",
      "---completed job---\n",
      "\n",
      "\n",
      "execute command: python model_inference.py --snapshotdate \"2017-02-05\" --modelname \"reg_2018_04_01.pkl\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "25/06/26 23:39:09 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "25/06/26 23:39:09 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.\n",
      "25/06/26 23:39:09 WARN Utils: Service 'SparkUI' could not bind on port 4041. Attempting port 4042.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "---starting job---\n",
      "\n",
      "\n",
      "{'model_artefact_filepath': 'model_bank/reg_2018_04_01.pkl',\n",
      " 'model_bank_directory': 'model_bank/',\n",
      " 'model_name': 'reg_2018_04_01.pkl',\n",
      " 'snapshot_date': datetime.datetime(2017, 2, 5, 0, 0),\n",
      " 'snapshot_date_str': '2017-02-05'}\n",
      "Model loaded successfully! model_bank/reg_2018_04_01.pkl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving labels:   0%|          | 0/1 [00:00<?, ?it/s]/opt/anaconda3/envs/mle_env/lib/python3.10/site-packages/sklearn/utils/validation.py:2732: UserWarning: X has feature names, but StandardScaler was fitted without feature names\n",
      "  warnings.warn(\n",
      "Saving labels: 100%|██████████| 1/1 [00:02<00:00,  2.59s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_inference 74\n",
      "num of rows add:74\n",
      "datamart/gold/model_predictions/reg_2018_04_01/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved to: datamart/gold/model_predictions/reg_2018_04_01/reg_2018_04_01_predictions_2017_02_05.parquet\n",
      "rows added: 74\n",
      "\n",
      "\n",
      "---completed job---\n",
      "\n",
      "\n",
      "execute command: python model_inference.py --snapshotdate \"2017-02-06\" --modelname \"reg_2018_04_01.pkl\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "25/06/26 23:39:17 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "25/06/26 23:39:18 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.\n",
      "25/06/26 23:39:18 WARN Utils: Service 'SparkUI' could not bind on port 4041. Attempting port 4042.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "---starting job---\n",
      "\n",
      "\n",
      "{'model_artefact_filepath': 'model_bank/reg_2018_04_01.pkl',\n",
      " 'model_bank_directory': 'model_bank/',\n",
      " 'model_name': 'reg_2018_04_01.pkl',\n",
      " 'snapshot_date': datetime.datetime(2017, 2, 6, 0, 0),\n",
      " 'snapshot_date_str': '2017-02-06'}\n",
      "Model loaded successfully! model_bank/reg_2018_04_01.pkl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving labels:   0%|          | 0/1 [00:00<?, ?it/s]/opt/anaconda3/envs/mle_env/lib/python3.10/site-packages/sklearn/utils/validation.py:2732: UserWarning: X has feature names, but StandardScaler was fitted without feature names\n",
      "  warnings.warn(\n",
      "Saving labels: 100%|██████████| 1/1 [00:02<00:00,  2.57s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_inference 78\n",
      "num of rows add:78\n",
      "datamart/gold/model_predictions/reg_2018_04_01/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved to: datamart/gold/model_predictions/reg_2018_04_01/reg_2018_04_01_predictions_2017_02_06.parquet\n",
      "rows added: 78\n",
      "\n",
      "\n",
      "---completed job---\n",
      "\n",
      "\n",
      "execute command: python model_inference.py --snapshotdate \"2017-02-07\" --modelname \"reg_2018_04_01.pkl\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "25/06/26 23:39:26 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "25/06/26 23:39:26 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.\n",
      "25/06/26 23:39:26 WARN Utils: Service 'SparkUI' could not bind on port 4041. Attempting port 4042.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "---starting job---\n",
      "\n",
      "\n",
      "{'model_artefact_filepath': 'model_bank/reg_2018_04_01.pkl',\n",
      " 'model_bank_directory': 'model_bank/',\n",
      " 'model_name': 'reg_2018_04_01.pkl',\n",
      " 'snapshot_date': datetime.datetime(2017, 2, 7, 0, 0),\n",
      " 'snapshot_date_str': '2017-02-07'}\n",
      "Model loaded successfully! model_bank/reg_2018_04_01.pkl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/mle_env/lib/python3.10/site-packages/sklearn/utils/validation.py:2732: UserWarning: X has feature names, but StandardScaler was fitted without feature names\n",
      "  warnings.warn(\n",
      "Saving labels: 100%|██████████| 1/1 [00:02<00:00,  2.65s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_inference 108\n",
      "num of rows add:108\n",
      "datamart/gold/model_predictions/reg_2018_04_01/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved to: datamart/gold/model_predictions/reg_2018_04_01/reg_2018_04_01_predictions_2017_02_07.parquet\n",
      "rows added: 108\n",
      "\n",
      "\n",
      "---completed job---\n",
      "\n",
      "\n",
      "execute command: python model_inference.py --snapshotdate \"2017-02-08\" --modelname \"reg_2018_04_01.pkl\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "25/06/26 23:39:34 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "25/06/26 23:39:35 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.\n",
      "25/06/26 23:39:35 WARN Utils: Service 'SparkUI' could not bind on port 4041. Attempting port 4042.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "---starting job---\n",
      "\n",
      "\n",
      "{'model_artefact_filepath': 'model_bank/reg_2018_04_01.pkl',\n",
      " 'model_bank_directory': 'model_bank/',\n",
      " 'model_name': 'reg_2018_04_01.pkl',\n",
      " 'snapshot_date': datetime.datetime(2017, 2, 8, 0, 0),\n",
      " 'snapshot_date_str': '2017-02-08'}\n",
      "Model loaded successfully! model_bank/reg_2018_04_01.pkl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving labels:   0%|          | 0/1 [00:00<?, ?it/s]/opt/anaconda3/envs/mle_env/lib/python3.10/site-packages/sklearn/utils/validation.py:2732: UserWarning: X has feature names, but StandardScaler was fitted without feature names\n",
      "  warnings.warn(\n",
      "Saving labels: 100%|██████████| 1/1 [00:02<00:00,  2.60s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_inference 83\n",
      "num of rows add:83\n",
      "datamart/gold/model_predictions/reg_2018_04_01/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved to: datamart/gold/model_predictions/reg_2018_04_01/reg_2018_04_01_predictions_2017_02_08.parquet\n",
      "rows added: 83\n",
      "\n",
      "\n",
      "---completed job---\n",
      "\n",
      "\n",
      "execute command: python model_inference.py --snapshotdate \"2017-02-09\" --modelname \"reg_2018_04_01.pkl\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "25/06/26 23:39:44 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "25/06/26 23:39:45 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.\n",
      "25/06/26 23:39:45 WARN Utils: Service 'SparkUI' could not bind on port 4041. Attempting port 4042.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "---starting job---\n",
      "\n",
      "\n",
      "{'model_artefact_filepath': 'model_bank/reg_2018_04_01.pkl',\n",
      " 'model_bank_directory': 'model_bank/',\n",
      " 'model_name': 'reg_2018_04_01.pkl',\n",
      " 'snapshot_date': datetime.datetime(2017, 2, 9, 0, 0),\n",
      " 'snapshot_date_str': '2017-02-09'}\n",
      "Model loaded successfully! model_bank/reg_2018_04_01.pkl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving labels:   0%|          | 0/1 [00:00<?, ?it/s]/opt/anaconda3/envs/mle_env/lib/python3.10/site-packages/sklearn/utils/validation.py:2732: UserWarning: X has feature names, but StandardScaler was fitted without feature names\n",
      "  warnings.warn(\n",
      "Saving labels: 100%|██████████| 1/1 [00:02<00:00,  2.60s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_inference 73\n",
      "num of rows add:73\n",
      "datamart/gold/model_predictions/reg_2018_04_01/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved to: datamart/gold/model_predictions/reg_2018_04_01/reg_2018_04_01_predictions_2017_02_09.parquet\n",
      "rows added: 73\n",
      "\n",
      "\n",
      "---completed job---\n",
      "\n",
      "\n",
      "execute command: python model_inference.py --snapshotdate \"2017-02-10\" --modelname \"reg_2018_04_01.pkl\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "25/06/26 23:39:53 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "25/06/26 23:39:53 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.\n",
      "25/06/26 23:39:53 WARN Utils: Service 'SparkUI' could not bind on port 4041. Attempting port 4042.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "---starting job---\n",
      "\n",
      "\n",
      "{'model_artefact_filepath': 'model_bank/reg_2018_04_01.pkl',\n",
      " 'model_bank_directory': 'model_bank/',\n",
      " 'model_name': 'reg_2018_04_01.pkl',\n",
      " 'snapshot_date': datetime.datetime(2017, 2, 10, 0, 0),\n",
      " 'snapshot_date_str': '2017-02-10'}\n",
      "Model loaded successfully! model_bank/reg_2018_04_01.pkl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/mle_env/lib/python3.10/site-packages/sklearn/utils/validation.py:2732: UserWarning: X has feature names, but StandardScaler was fitted without feature names\n",
      "  warnings.warn(\n",
      "Saving labels: 100%|██████████| 1/1 [00:02<00:00,  2.77s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_inference 63\n",
      "num of rows add:63\n",
      "datamart/gold/model_predictions/reg_2018_04_01/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved to: datamart/gold/model_predictions/reg_2018_04_01/reg_2018_04_01_predictions_2017_02_10.parquet\n",
      "rows added: 63\n",
      "\n",
      "\n",
      "---completed job---\n",
      "\n",
      "\n",
      "execute command: python model_inference.py --snapshotdate \"2017-02-11\" --modelname \"reg_2018_04_01.pkl\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "25/06/26 23:40:01 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "25/06/26 23:40:02 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.\n",
      "25/06/26 23:40:02 WARN Utils: Service 'SparkUI' could not bind on port 4041. Attempting port 4042.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "---starting job---\n",
      "\n",
      "\n",
      "{'model_artefact_filepath': 'model_bank/reg_2018_04_01.pkl',\n",
      " 'model_bank_directory': 'model_bank/',\n",
      " 'model_name': 'reg_2018_04_01.pkl',\n",
      " 'snapshot_date': datetime.datetime(2017, 2, 11, 0, 0),\n",
      " 'snapshot_date_str': '2017-02-11'}\n",
      "Model loaded successfully! model_bank/reg_2018_04_01.pkl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving labels:   0%|          | 0/1 [00:00<?, ?it/s]/opt/anaconda3/envs/mle_env/lib/python3.10/site-packages/sklearn/utils/validation.py:2732: UserWarning: X has feature names, but StandardScaler was fitted without feature names\n",
      "  warnings.warn(\n",
      "Saving labels: 100%|██████████| 1/1 [00:02<00:00,  2.76s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_inference 45\n",
      "num of rows add:45\n",
      "datamart/gold/model_predictions/reg_2018_04_01/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved to: datamart/gold/model_predictions/reg_2018_04_01/reg_2018_04_01_predictions_2017_02_11.parquet\n",
      "rows added: 45\n",
      "\n",
      "\n",
      "---completed job---\n",
      "\n",
      "\n",
      "execute command: python model_inference.py --snapshotdate \"2017-02-12\" --modelname \"reg_2018_04_01.pkl\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "25/06/26 23:40:10 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "25/06/26 23:40:11 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.\n",
      "25/06/26 23:40:11 WARN Utils: Service 'SparkUI' could not bind on port 4041. Attempting port 4042.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "---starting job---\n",
      "\n",
      "\n",
      "{'model_artefact_filepath': 'model_bank/reg_2018_04_01.pkl',\n",
      " 'model_bank_directory': 'model_bank/',\n",
      " 'model_name': 'reg_2018_04_01.pkl',\n",
      " 'snapshot_date': datetime.datetime(2017, 2, 12, 0, 0),\n",
      " 'snapshot_date_str': '2017-02-12'}\n",
      "Model loaded successfully! model_bank/reg_2018_04_01.pkl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving labels:   0%|          | 0/1 [00:00<?, ?it/s]/opt/anaconda3/envs/mle_env/lib/python3.10/site-packages/sklearn/utils/validation.py:2732: UserWarning: X has feature names, but StandardScaler was fitted without feature names\n",
      "  warnings.warn(\n",
      "Saving labels: 100%|██████████| 1/1 [00:02<00:00,  2.83s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_inference 61\n",
      "num of rows add:61\n",
      "datamart/gold/model_predictions/reg_2018_04_01/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved to: datamart/gold/model_predictions/reg_2018_04_01/reg_2018_04_01_predictions_2017_02_12.parquet\n",
      "rows added: 61\n",
      "\n",
      "\n",
      "---completed job---\n",
      "\n",
      "\n",
      "execute command: python model_inference.py --snapshotdate \"2017-02-13\" --modelname \"reg_2018_04_01.pkl\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "25/06/26 23:40:19 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "25/06/26 23:40:20 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.\n",
      "25/06/26 23:40:20 WARN Utils: Service 'SparkUI' could not bind on port 4041. Attempting port 4042.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "---starting job---\n",
      "\n",
      "\n",
      "{'model_artefact_filepath': 'model_bank/reg_2018_04_01.pkl',\n",
      " 'model_bank_directory': 'model_bank/',\n",
      " 'model_name': 'reg_2018_04_01.pkl',\n",
      " 'snapshot_date': datetime.datetime(2017, 2, 13, 0, 0),\n",
      " 'snapshot_date_str': '2017-02-13'}\n",
      "Model loaded successfully! model_bank/reg_2018_04_01.pkl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving labels:   0%|          | 0/1 [00:00<?, ?it/s]/opt/anaconda3/envs/mle_env/lib/python3.10/site-packages/sklearn/utils/validation.py:2732: UserWarning: X has feature names, but StandardScaler was fitted without feature names\n",
      "  warnings.warn(\n",
      "Saving labels: 100%|██████████| 1/1 [00:02<00:00,  2.57s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_inference 74\n",
      "num of rows add:74\n",
      "datamart/gold/model_predictions/reg_2018_04_01/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved to: datamart/gold/model_predictions/reg_2018_04_01/reg_2018_04_01_predictions_2017_02_13.parquet\n",
      "rows added: 74\n",
      "\n",
      "\n",
      "---completed job---\n",
      "\n",
      "\n",
      "execute command: python model_inference.py --snapshotdate \"2017-02-14\" --modelname \"reg_2018_04_01.pkl\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "25/06/26 23:40:28 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "25/06/26 23:40:28 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.\n",
      "25/06/26 23:40:28 WARN Utils: Service 'SparkUI' could not bind on port 4041. Attempting port 4042.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "---starting job---\n",
      "\n",
      "\n",
      "{'model_artefact_filepath': 'model_bank/reg_2018_04_01.pkl',\n",
      " 'model_bank_directory': 'model_bank/',\n",
      " 'model_name': 'reg_2018_04_01.pkl',\n",
      " 'snapshot_date': datetime.datetime(2017, 2, 14, 0, 0),\n",
      " 'snapshot_date_str': '2017-02-14'}\n",
      "Model loaded successfully! model_bank/reg_2018_04_01.pkl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving labels:   0%|          | 0/1 [00:00<?, ?it/s]/opt/anaconda3/envs/mle_env/lib/python3.10/site-packages/sklearn/utils/validation.py:2732: UserWarning: X has feature names, but StandardScaler was fitted without feature names\n",
      "  warnings.warn(\n",
      "Saving labels: 100%|██████████| 1/1 [00:02<00:00,  2.78s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_inference 66\n",
      "num of rows add:66\n",
      "datamart/gold/model_predictions/reg_2018_04_01/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved to: datamart/gold/model_predictions/reg_2018_04_01/reg_2018_04_01_predictions_2017_02_14.parquet\n",
      "rows added: 66\n",
      "\n",
      "\n",
      "---completed job---\n",
      "\n",
      "\n",
      "execute command: python model_inference.py --snapshotdate \"2017-02-15\" --modelname \"reg_2018_04_01.pkl\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "25/06/26 23:40:36 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "25/06/26 23:40:37 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.\n",
      "25/06/26 23:40:37 WARN Utils: Service 'SparkUI' could not bind on port 4041. Attempting port 4042.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "---starting job---\n",
      "\n",
      "\n",
      "{'model_artefact_filepath': 'model_bank/reg_2018_04_01.pkl',\n",
      " 'model_bank_directory': 'model_bank/',\n",
      " 'model_name': 'reg_2018_04_01.pkl',\n",
      " 'snapshot_date': datetime.datetime(2017, 2, 15, 0, 0),\n",
      " 'snapshot_date_str': '2017-02-15'}\n",
      "Model loaded successfully! model_bank/reg_2018_04_01.pkl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving labels:   0%|          | 0/1 [00:00<?, ?it/s]/opt/anaconda3/envs/mle_env/lib/python3.10/site-packages/sklearn/utils/validation.py:2732: UserWarning: X has feature names, but StandardScaler was fitted without feature names\n",
      "  warnings.warn(\n",
      "Saving labels: 100%|██████████| 1/1 [00:02<00:00,  2.65s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_inference 56\n",
      "num of rows add:56\n",
      "datamart/gold/model_predictions/reg_2018_04_01/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved to: datamart/gold/model_predictions/reg_2018_04_01/reg_2018_04_01_predictions_2017_02_15.parquet\n",
      "rows added: 56\n",
      "\n",
      "\n",
      "---completed job---\n",
      "\n",
      "\n",
      "execute command: python model_inference.py --snapshotdate \"2017-02-16\" --modelname \"reg_2018_04_01.pkl\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "25/06/26 23:40:45 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "25/06/26 23:40:45 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.\n",
      "25/06/26 23:40:45 WARN Utils: Service 'SparkUI' could not bind on port 4041. Attempting port 4042.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "---starting job---\n",
      "\n",
      "\n",
      "{'model_artefact_filepath': 'model_bank/reg_2018_04_01.pkl',\n",
      " 'model_bank_directory': 'model_bank/',\n",
      " 'model_name': 'reg_2018_04_01.pkl',\n",
      " 'snapshot_date': datetime.datetime(2017, 2, 16, 0, 0),\n",
      " 'snapshot_date_str': '2017-02-16'}\n",
      "Model loaded successfully! model_bank/reg_2018_04_01.pkl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving labels:   0%|          | 0/1 [00:00<?, ?it/s]/opt/anaconda3/envs/mle_env/lib/python3.10/site-packages/sklearn/utils/validation.py:2732: UserWarning: X has feature names, but StandardScaler was fitted without feature names\n",
      "  warnings.warn(\n",
      "Saving labels: 100%|██████████| 1/1 [00:02<00:00,  2.56s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_inference 49\n",
      "num of rows add:49\n",
      "datamart/gold/model_predictions/reg_2018_04_01/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved to: datamart/gold/model_predictions/reg_2018_04_01/reg_2018_04_01_predictions_2017_02_16.parquet\n",
      "rows added: 49\n",
      "\n",
      "\n",
      "---completed job---\n",
      "\n",
      "\n",
      "execute command: python model_inference.py --snapshotdate \"2017-02-17\" --modelname \"reg_2018_04_01.pkl\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "25/06/26 23:40:53 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "25/06/26 23:40:53 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.\n",
      "25/06/26 23:40:53 WARN Utils: Service 'SparkUI' could not bind on port 4041. Attempting port 4042.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "---starting job---\n",
      "\n",
      "\n",
      "{'model_artefact_filepath': 'model_bank/reg_2018_04_01.pkl',\n",
      " 'model_bank_directory': 'model_bank/',\n",
      " 'model_name': 'reg_2018_04_01.pkl',\n",
      " 'snapshot_date': datetime.datetime(2017, 2, 17, 0, 0),\n",
      " 'snapshot_date_str': '2017-02-17'}\n",
      "Model loaded successfully! model_bank/reg_2018_04_01.pkl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving labels:   0%|          | 0/1 [00:00<?, ?it/s]/opt/anaconda3/envs/mle_env/lib/python3.10/site-packages/sklearn/utils/validation.py:2732: UserWarning: X has feature names, but StandardScaler was fitted without feature names\n",
      "  warnings.warn(\n",
      "Saving labels: 100%|██████████| 1/1 [00:02<00:00,  2.58s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_inference 45\n",
      "num of rows add:45\n",
      "datamart/gold/model_predictions/reg_2018_04_01/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved to: datamart/gold/model_predictions/reg_2018_04_01/reg_2018_04_01_predictions_2017_02_17.parquet\n",
      "rows added: 45\n",
      "\n",
      "\n",
      "---completed job---\n",
      "\n",
      "\n",
      "execute command: python model_inference.py --snapshotdate \"2017-02-18\" --modelname \"reg_2018_04_01.pkl\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "25/06/26 23:41:01 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "25/06/26 23:41:01 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.\n",
      "25/06/26 23:41:01 WARN Utils: Service 'SparkUI' could not bind on port 4041. Attempting port 4042.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "---starting job---\n",
      "\n",
      "\n",
      "{'model_artefact_filepath': 'model_bank/reg_2018_04_01.pkl',\n",
      " 'model_bank_directory': 'model_bank/',\n",
      " 'model_name': 'reg_2018_04_01.pkl',\n",
      " 'snapshot_date': datetime.datetime(2017, 2, 18, 0, 0),\n",
      " 'snapshot_date_str': '2017-02-18'}\n",
      "Model loaded successfully! model_bank/reg_2018_04_01.pkl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving labels:   0%|          | 0/1 [00:00<?, ?it/s]/opt/anaconda3/envs/mle_env/lib/python3.10/site-packages/sklearn/utils/validation.py:2732: UserWarning: X has feature names, but StandardScaler was fitted without feature names\n",
      "  warnings.warn(\n",
      "Saving labels: 100%|██████████| 1/1 [00:02<00:00,  2.63s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_inference 52\n",
      "num of rows add:52\n",
      "datamart/gold/model_predictions/reg_2018_04_01/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved to: datamart/gold/model_predictions/reg_2018_04_01/reg_2018_04_01_predictions_2017_02_18.parquet\n",
      "rows added: 52\n",
      "\n",
      "\n",
      "---completed job---\n",
      "\n",
      "\n",
      "execute command: python model_inference.py --snapshotdate \"2017-02-19\" --modelname \"reg_2018_04_01.pkl\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "25/06/26 23:41:09 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "25/06/26 23:41:10 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.\n",
      "25/06/26 23:41:10 WARN Utils: Service 'SparkUI' could not bind on port 4041. Attempting port 4042.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "---starting job---\n",
      "\n",
      "\n",
      "{'model_artefact_filepath': 'model_bank/reg_2018_04_01.pkl',\n",
      " 'model_bank_directory': 'model_bank/',\n",
      " 'model_name': 'reg_2018_04_01.pkl',\n",
      " 'snapshot_date': datetime.datetime(2017, 2, 19, 0, 0),\n",
      " 'snapshot_date_str': '2017-02-19'}\n",
      "Model loaded successfully! model_bank/reg_2018_04_01.pkl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving labels:   0%|          | 0/1 [00:00<?, ?it/s]/opt/anaconda3/envs/mle_env/lib/python3.10/site-packages/sklearn/utils/validation.py:2732: UserWarning: X has feature names, but StandardScaler was fitted without feature names\n",
      "  warnings.warn(\n",
      "Saving labels: 100%|██████████| 1/1 [00:02<00:00,  2.59s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_inference 37\n",
      "num of rows add:37\n",
      "datamart/gold/model_predictions/reg_2018_04_01/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved to: datamart/gold/model_predictions/reg_2018_04_01/reg_2018_04_01_predictions_2017_02_19.parquet\n",
      "rows added: 37\n",
      "\n",
      "\n",
      "---completed job---\n",
      "\n",
      "\n",
      "execute command: python model_inference.py --snapshotdate \"2017-02-20\" --modelname \"reg_2018_04_01.pkl\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "25/06/26 23:41:17 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "25/06/26 23:41:18 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.\n",
      "25/06/26 23:41:18 WARN Utils: Service 'SparkUI' could not bind on port 4041. Attempting port 4042.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "---starting job---\n",
      "\n",
      "\n",
      "{'model_artefact_filepath': 'model_bank/reg_2018_04_01.pkl',\n",
      " 'model_bank_directory': 'model_bank/',\n",
      " 'model_name': 'reg_2018_04_01.pkl',\n",
      " 'snapshot_date': datetime.datetime(2017, 2, 20, 0, 0),\n",
      " 'snapshot_date_str': '2017-02-20'}\n",
      "Model loaded successfully! model_bank/reg_2018_04_01.pkl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving labels:   0%|          | 0/1 [00:00<?, ?it/s]/opt/anaconda3/envs/mle_env/lib/python3.10/site-packages/sklearn/utils/validation.py:2732: UserWarning: X has feature names, but StandardScaler was fitted without feature names\n",
      "  warnings.warn(\n",
      "Saving labels: 100%|██████████| 1/1 [00:02<00:00,  2.61s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_inference 59\n",
      "num of rows add:59\n",
      "datamart/gold/model_predictions/reg_2018_04_01/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved to: datamart/gold/model_predictions/reg_2018_04_01/reg_2018_04_01_predictions_2017_02_20.parquet\n",
      "rows added: 59\n",
      "\n",
      "\n",
      "---completed job---\n",
      "\n",
      "\n",
      "execute command: python model_inference.py --snapshotdate \"2017-02-21\" --modelname \"reg_2018_04_01.pkl\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "25/06/26 23:41:26 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "25/06/26 23:41:26 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.\n",
      "25/06/26 23:41:26 WARN Utils: Service 'SparkUI' could not bind on port 4041. Attempting port 4042.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "---starting job---\n",
      "\n",
      "\n",
      "{'model_artefact_filepath': 'model_bank/reg_2018_04_01.pkl',\n",
      " 'model_bank_directory': 'model_bank/',\n",
      " 'model_name': 'reg_2018_04_01.pkl',\n",
      " 'snapshot_date': datetime.datetime(2017, 2, 21, 0, 0),\n",
      " 'snapshot_date_str': '2017-02-21'}\n",
      "Model loaded successfully! model_bank/reg_2018_04_01.pkl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving labels:   0%|          | 0/1 [00:00<?, ?it/s]/opt/anaconda3/envs/mle_env/lib/python3.10/site-packages/sklearn/utils/validation.py:2732: UserWarning: X has feature names, but StandardScaler was fitted without feature names\n",
      "  warnings.warn(\n",
      "Saving labels: 100%|██████████| 1/1 [00:03<00:00,  3.12s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_inference 39\n",
      "num of rows add:39\n",
      "datamart/gold/model_predictions/reg_2018_04_01/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved to: datamart/gold/model_predictions/reg_2018_04_01/reg_2018_04_01_predictions_2017_02_21.parquet\n",
      "rows added: 39\n",
      "\n",
      "\n",
      "---completed job---\n",
      "\n",
      "\n",
      "execute command: python model_inference.py --snapshotdate \"2017-02-22\" --modelname \"reg_2018_04_01.pkl\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "25/06/26 23:41:35 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "25/06/26 23:41:36 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.\n",
      "25/06/26 23:41:36 WARN Utils: Service 'SparkUI' could not bind on port 4041. Attempting port 4042.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "---starting job---\n",
      "\n",
      "\n",
      "{'model_artefact_filepath': 'model_bank/reg_2018_04_01.pkl',\n",
      " 'model_bank_directory': 'model_bank/',\n",
      " 'model_name': 'reg_2018_04_01.pkl',\n",
      " 'snapshot_date': datetime.datetime(2017, 2, 22, 0, 0),\n",
      " 'snapshot_date_str': '2017-02-22'}\n",
      "Model loaded successfully! model_bank/reg_2018_04_01.pkl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving labels:   0%|          | 0/1 [00:00<?, ?it/s]/opt/anaconda3/envs/mle_env/lib/python3.10/site-packages/sklearn/utils/validation.py:2732: UserWarning: X has feature names, but StandardScaler was fitted without feature names\n",
      "  warnings.warn(\n",
      "Saving labels: 100%|██████████| 1/1 [00:03<00:00,  3.09s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_inference 53\n",
      "num of rows add:53\n",
      "datamart/gold/model_predictions/reg_2018_04_01/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved to: datamart/gold/model_predictions/reg_2018_04_01/reg_2018_04_01_predictions_2017_02_22.parquet\n",
      "rows added: 53\n",
      "\n",
      "\n",
      "---completed job---\n",
      "\n",
      "\n",
      "execute command: python model_inference.py --snapshotdate \"2017-02-23\" --modelname \"reg_2018_04_01.pkl\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "25/06/26 23:41:44 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "25/06/26 23:41:45 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.\n",
      "25/06/26 23:41:45 WARN Utils: Service 'SparkUI' could not bind on port 4041. Attempting port 4042.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "---starting job---\n",
      "\n",
      "\n",
      "{'model_artefact_filepath': 'model_bank/reg_2018_04_01.pkl',\n",
      " 'model_bank_directory': 'model_bank/',\n",
      " 'model_name': 'reg_2018_04_01.pkl',\n",
      " 'snapshot_date': datetime.datetime(2017, 2, 23, 0, 0),\n",
      " 'snapshot_date_str': '2017-02-23'}\n",
      "Model loaded successfully! model_bank/reg_2018_04_01.pkl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving labels:   0%|          | 0/1 [00:00<?, ?it/s]/opt/anaconda3/envs/mle_env/lib/python3.10/site-packages/sklearn/utils/validation.py:2732: UserWarning: X has feature names, but StandardScaler was fitted without feature names\n",
      "  warnings.warn(\n",
      "Saving labels: 100%|██████████| 1/1 [00:02<00:00,  2.54s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_inference 57\n",
      "num of rows add:57\n",
      "datamart/gold/model_predictions/reg_2018_04_01/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved to: datamart/gold/model_predictions/reg_2018_04_01/reg_2018_04_01_predictions_2017_02_23.parquet\n",
      "rows added: 57\n",
      "\n",
      "\n",
      "---completed job---\n",
      "\n",
      "\n",
      "execute command: python model_inference.py --snapshotdate \"2017-02-24\" --modelname \"reg_2018_04_01.pkl\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "25/06/26 23:41:53 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "25/06/26 23:41:53 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.\n",
      "25/06/26 23:41:53 WARN Utils: Service 'SparkUI' could not bind on port 4041. Attempting port 4042.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "---starting job---\n",
      "\n",
      "\n",
      "{'model_artefact_filepath': 'model_bank/reg_2018_04_01.pkl',\n",
      " 'model_bank_directory': 'model_bank/',\n",
      " 'model_name': 'reg_2018_04_01.pkl',\n",
      " 'snapshot_date': datetime.datetime(2017, 2, 24, 0, 0),\n",
      " 'snapshot_date_str': '2017-02-24'}\n",
      "Model loaded successfully! model_bank/reg_2018_04_01.pkl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving labels:   0%|          | 0/1 [00:00<?, ?it/s]/opt/anaconda3/envs/mle_env/lib/python3.10/site-packages/sklearn/utils/validation.py:2732: UserWarning: X has feature names, but StandardScaler was fitted without feature names\n",
      "  warnings.warn(\n",
      "Saving labels: 100%|██████████| 1/1 [00:02<00:00,  2.61s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_inference 60\n",
      "num of rows add:60\n",
      "datamart/gold/model_predictions/reg_2018_04_01/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved to: datamart/gold/model_predictions/reg_2018_04_01/reg_2018_04_01_predictions_2017_02_24.parquet\n",
      "rows added: 60\n",
      "\n",
      "\n",
      "---completed job---\n",
      "\n",
      "\n",
      "execute command: python model_inference.py --snapshotdate \"2017-02-25\" --modelname \"reg_2018_04_01.pkl\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "25/06/26 23:42:01 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "25/06/26 23:42:02 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.\n",
      "25/06/26 23:42:02 WARN Utils: Service 'SparkUI' could not bind on port 4041. Attempting port 4042.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "---starting job---\n",
      "\n",
      "\n",
      "{'model_artefact_filepath': 'model_bank/reg_2018_04_01.pkl',\n",
      " 'model_bank_directory': 'model_bank/',\n",
      " 'model_name': 'reg_2018_04_01.pkl',\n",
      " 'snapshot_date': datetime.datetime(2017, 2, 25, 0, 0),\n",
      " 'snapshot_date_str': '2017-02-25'}\n",
      "Model loaded successfully! model_bank/reg_2018_04_01.pkl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving labels:   0%|          | 0/1 [00:00<?, ?it/s]/opt/anaconda3/envs/mle_env/lib/python3.10/site-packages/sklearn/utils/validation.py:2732: UserWarning: X has feature names, but StandardScaler was fitted without feature names\n",
      "  warnings.warn(\n",
      "Saving labels: 100%|██████████| 1/1 [00:02<00:00,  2.73s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_inference 39\n",
      "num of rows add:39\n",
      "datamart/gold/model_predictions/reg_2018_04_01/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved to: datamart/gold/model_predictions/reg_2018_04_01/reg_2018_04_01_predictions_2017_02_25.parquet\n",
      "rows added: 39\n",
      "\n",
      "\n",
      "---completed job---\n",
      "\n",
      "\n",
      "execute command: python model_inference.py --snapshotdate \"2017-02-26\" --modelname \"reg_2018_04_01.pkl\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "25/06/26 23:42:10 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "25/06/26 23:42:10 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.\n",
      "25/06/26 23:42:10 WARN Utils: Service 'SparkUI' could not bind on port 4041. Attempting port 4042.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "---starting job---\n",
      "\n",
      "\n",
      "{'model_artefact_filepath': 'model_bank/reg_2018_04_01.pkl',\n",
      " 'model_bank_directory': 'model_bank/',\n",
      " 'model_name': 'reg_2018_04_01.pkl',\n",
      " 'snapshot_date': datetime.datetime(2017, 2, 26, 0, 0),\n",
      " 'snapshot_date_str': '2017-02-26'}\n",
      "Model loaded successfully! model_bank/reg_2018_04_01.pkl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving labels:   0%|          | 0/1 [00:00<?, ?it/s]/opt/anaconda3/envs/mle_env/lib/python3.10/site-packages/sklearn/utils/validation.py:2732: UserWarning: X has feature names, but StandardScaler was fitted without feature names\n",
      "  warnings.warn(\n",
      "Saving labels: 100%|██████████| 1/1 [00:02<00:00,  2.59s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_inference 42\n",
      "num of rows add:42\n",
      "datamart/gold/model_predictions/reg_2018_04_01/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved to: datamart/gold/model_predictions/reg_2018_04_01/reg_2018_04_01_predictions_2017_02_26.parquet\n",
      "rows added: 42\n",
      "\n",
      "\n",
      "---completed job---\n",
      "\n",
      "\n",
      "execute command: python model_inference.py --snapshotdate \"2017-02-27\" --modelname \"reg_2018_04_01.pkl\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "25/06/26 23:42:19 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "25/06/26 23:42:19 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.\n",
      "25/06/26 23:42:19 WARN Utils: Service 'SparkUI' could not bind on port 4041. Attempting port 4042.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "---starting job---\n",
      "\n",
      "\n",
      "{'model_artefact_filepath': 'model_bank/reg_2018_04_01.pkl',\n",
      " 'model_bank_directory': 'model_bank/',\n",
      " 'model_name': 'reg_2018_04_01.pkl',\n",
      " 'snapshot_date': datetime.datetime(2017, 2, 27, 0, 0),\n",
      " 'snapshot_date_str': '2017-02-27'}\n",
      "Model loaded successfully! model_bank/reg_2018_04_01.pkl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving labels:   0%|          | 0/1 [00:00<?, ?it/s]/opt/anaconda3/envs/mle_env/lib/python3.10/site-packages/sklearn/utils/validation.py:2732: UserWarning: X has feature names, but StandardScaler was fitted without feature names\n",
      "  warnings.warn(\n",
      "Saving labels: 100%|██████████| 1/1 [00:02<00:00,  2.59s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_inference 41\n",
      "num of rows add:41\n",
      "datamart/gold/model_predictions/reg_2018_04_01/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved to: datamart/gold/model_predictions/reg_2018_04_01/reg_2018_04_01_predictions_2017_02_27.parquet\n",
      "rows added: 41\n",
      "\n",
      "\n",
      "---completed job---\n",
      "\n",
      "\n",
      "execute command: python model_inference.py --snapshotdate \"2017-02-28\" --modelname \"reg_2018_04_01.pkl\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "25/06/26 23:42:28 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "25/06/26 23:42:28 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.\n",
      "25/06/26 23:42:28 WARN Utils: Service 'SparkUI' could not bind on port 4041. Attempting port 4042.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "---starting job---\n",
      "\n",
      "\n",
      "{'model_artefact_filepath': 'model_bank/reg_2018_04_01.pkl',\n",
      " 'model_bank_directory': 'model_bank/',\n",
      " 'model_name': 'reg_2018_04_01.pkl',\n",
      " 'snapshot_date': datetime.datetime(2017, 2, 28, 0, 0),\n",
      " 'snapshot_date_str': '2017-02-28'}\n",
      "Model loaded successfully! model_bank/reg_2018_04_01.pkl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving labels:   0%|          | 0/1 [00:00<?, ?it/s]/opt/anaconda3/envs/mle_env/lib/python3.10/site-packages/sklearn/utils/validation.py:2732: UserWarning: X has feature names, but StandardScaler was fitted without feature names\n",
      "  warnings.warn(\n",
      "Saving labels: 100%|██████████| 1/1 [00:02<00:00,  2.54s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_inference 53\n",
      "num of rows add:53\n",
      "datamart/gold/model_predictions/reg_2018_04_01/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved to: datamart/gold/model_predictions/reg_2018_04_01/reg_2018_04_01_predictions_2017_02_28.parquet\n",
      "rows added: 53\n",
      "\n",
      "\n",
      "---completed job---\n",
      "\n",
      "\n",
      "execute command: python model_inference.py --snapshotdate \"2017-03-01\" --modelname \"reg_2018_04_01.pkl\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "25/06/26 23:42:36 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "25/06/26 23:42:37 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.\n",
      "25/06/26 23:42:37 WARN Utils: Service 'SparkUI' could not bind on port 4041. Attempting port 4042.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "---starting job---\n",
      "\n",
      "\n",
      "{'model_artefact_filepath': 'model_bank/reg_2018_04_01.pkl',\n",
      " 'model_bank_directory': 'model_bank/',\n",
      " 'model_name': 'reg_2018_04_01.pkl',\n",
      " 'snapshot_date': datetime.datetime(2017, 3, 1, 0, 0),\n",
      " 'snapshot_date_str': '2017-03-01'}\n",
      "Model loaded successfully! model_bank/reg_2018_04_01.pkl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving labels:   0%|          | 0/1 [00:00<?, ?it/s]/opt/anaconda3/envs/mle_env/lib/python3.10/site-packages/sklearn/utils/validation.py:2732: UserWarning: X has feature names, but StandardScaler was fitted without feature names\n",
      "  warnings.warn(\n",
      "Saving labels: 100%|██████████| 1/1 [00:02<00:00,  2.62s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_inference 93\n",
      "num of rows add:93\n",
      "datamart/gold/model_predictions/reg_2018_04_01/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved to: datamart/gold/model_predictions/reg_2018_04_01/reg_2018_04_01_predictions_2017_03_01.parquet\n",
      "rows added: 93\n",
      "\n",
      "\n",
      "---completed job---\n",
      "\n",
      "\n",
      "execute command: python model_inference.py --snapshotdate \"2017-03-02\" --modelname \"reg_2018_04_01.pkl\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "25/06/26 23:42:45 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "25/06/26 23:42:45 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.\n",
      "25/06/26 23:42:45 WARN Utils: Service 'SparkUI' could not bind on port 4041. Attempting port 4042.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "---starting job---\n",
      "\n",
      "\n",
      "{'model_artefact_filepath': 'model_bank/reg_2018_04_01.pkl',\n",
      " 'model_bank_directory': 'model_bank/',\n",
      " 'model_name': 'reg_2018_04_01.pkl',\n",
      " 'snapshot_date': datetime.datetime(2017, 3, 2, 0, 0),\n",
      " 'snapshot_date_str': '2017-03-02'}\n",
      "Model loaded successfully! model_bank/reg_2018_04_01.pkl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving labels:   0%|          | 0/1 [00:00<?, ?it/s]/opt/anaconda3/envs/mle_env/lib/python3.10/site-packages/sklearn/utils/validation.py:2732: UserWarning: X has feature names, but StandardScaler was fitted without feature names\n",
      "  warnings.warn(\n",
      "Saving labels: 100%|██████████| 1/1 [00:02<00:00,  2.69s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_inference 66\n",
      "num of rows add:66\n",
      "datamart/gold/model_predictions/reg_2018_04_01/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved to: datamart/gold/model_predictions/reg_2018_04_01/reg_2018_04_01_predictions_2017_03_02.parquet\n",
      "rows added: 66\n",
      "\n",
      "\n",
      "---completed job---\n",
      "\n",
      "\n",
      "execute command: python model_inference.py --snapshotdate \"2017-03-03\" --modelname \"reg_2018_04_01.pkl\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "25/06/26 23:42:53 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "25/06/26 23:42:54 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.\n",
      "25/06/26 23:42:54 WARN Utils: Service 'SparkUI' could not bind on port 4041. Attempting port 4042.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "---starting job---\n",
      "\n",
      "\n",
      "{'model_artefact_filepath': 'model_bank/reg_2018_04_01.pkl',\n",
      " 'model_bank_directory': 'model_bank/',\n",
      " 'model_name': 'reg_2018_04_01.pkl',\n",
      " 'snapshot_date': datetime.datetime(2017, 3, 3, 0, 0),\n",
      " 'snapshot_date_str': '2017-03-03'}\n",
      "Model loaded successfully! model_bank/reg_2018_04_01.pkl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving labels:   0%|          | 0/1 [00:00<?, ?it/s]/opt/anaconda3/envs/mle_env/lib/python3.10/site-packages/sklearn/utils/validation.py:2732: UserWarning: X has feature names, but StandardScaler was fitted without feature names\n",
      "  warnings.warn(\n",
      "Saving labels: 100%|██████████| 1/1 [00:02<00:00,  2.69s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_inference 72\n",
      "num of rows add:72\n",
      "datamart/gold/model_predictions/reg_2018_04_01/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved to: datamart/gold/model_predictions/reg_2018_04_01/reg_2018_04_01_predictions_2017_03_03.parquet\n",
      "rows added: 72\n",
      "\n",
      "\n",
      "---completed job---\n",
      "\n",
      "\n",
      "execute command: python model_inference.py --snapshotdate \"2017-03-04\" --modelname \"reg_2018_04_01.pkl\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "25/06/26 23:43:02 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "25/06/26 23:43:02 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.\n",
      "25/06/26 23:43:02 WARN Utils: Service 'SparkUI' could not bind on port 4041. Attempting port 4042.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "---starting job---\n",
      "\n",
      "\n",
      "{'model_artefact_filepath': 'model_bank/reg_2018_04_01.pkl',\n",
      " 'model_bank_directory': 'model_bank/',\n",
      " 'model_name': 'reg_2018_04_01.pkl',\n",
      " 'snapshot_date': datetime.datetime(2017, 3, 4, 0, 0),\n",
      " 'snapshot_date_str': '2017-03-04'}\n",
      "Model loaded successfully! model_bank/reg_2018_04_01.pkl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving labels:   0%|          | 0/1 [00:00<?, ?it/s]/opt/anaconda3/envs/mle_env/lib/python3.10/site-packages/sklearn/utils/validation.py:2732: UserWarning: X has feature names, but StandardScaler was fitted without feature names\n",
      "  warnings.warn(\n",
      "Saving labels: 100%|██████████| 1/1 [00:02<00:00,  2.74s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_inference 69\n",
      "num of rows add:69\n",
      "datamart/gold/model_predictions/reg_2018_04_01/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved to: datamart/gold/model_predictions/reg_2018_04_01/reg_2018_04_01_predictions_2017_03_04.parquet\n",
      "rows added: 69\n",
      "\n",
      "\n",
      "---completed job---\n",
      "\n",
      "\n",
      "execute command: python model_inference.py --snapshotdate \"2017-03-05\" --modelname \"reg_2018_04_01.pkl\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "25/06/26 23:43:11 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "25/06/26 23:43:11 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.\n",
      "25/06/26 23:43:11 WARN Utils: Service 'SparkUI' could not bind on port 4041. Attempting port 4042.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "---starting job---\n",
      "\n",
      "\n",
      "{'model_artefact_filepath': 'model_bank/reg_2018_04_01.pkl',\n",
      " 'model_bank_directory': 'model_bank/',\n",
      " 'model_name': 'reg_2018_04_01.pkl',\n",
      " 'snapshot_date': datetime.datetime(2017, 3, 5, 0, 0),\n",
      " 'snapshot_date_str': '2017-03-05'}\n",
      "Model loaded successfully! model_bank/reg_2018_04_01.pkl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving labels:   0%|          | 0/1 [00:00<?, ?it/s]/opt/anaconda3/envs/mle_env/lib/python3.10/site-packages/sklearn/utils/validation.py:2732: UserWarning: X has feature names, but StandardScaler was fitted without feature names\n",
      "  warnings.warn(\n",
      "Saving labels: 100%|██████████| 1/1 [00:02<00:00,  2.67s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_inference 67\n",
      "num of rows add:67\n",
      "datamart/gold/model_predictions/reg_2018_04_01/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved to: datamart/gold/model_predictions/reg_2018_04_01/reg_2018_04_01_predictions_2017_03_05.parquet\n",
      "rows added: 67\n",
      "\n",
      "\n",
      "---completed job---\n",
      "\n",
      "\n",
      "execute command: python model_inference.py --snapshotdate \"2017-03-06\" --modelname \"reg_2018_04_01.pkl\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "25/06/26 23:43:20 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "25/06/26 23:43:20 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.\n",
      "25/06/26 23:43:20 WARN Utils: Service 'SparkUI' could not bind on port 4041. Attempting port 4042.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "---starting job---\n",
      "\n",
      "\n",
      "{'model_artefact_filepath': 'model_bank/reg_2018_04_01.pkl',\n",
      " 'model_bank_directory': 'model_bank/',\n",
      " 'model_name': 'reg_2018_04_01.pkl',\n",
      " 'snapshot_date': datetime.datetime(2017, 3, 6, 0, 0),\n",
      " 'snapshot_date_str': '2017-03-06'}\n",
      "Model loaded successfully! model_bank/reg_2018_04_01.pkl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving labels:   0%|          | 0/1 [00:00<?, ?it/s]/opt/anaconda3/envs/mle_env/lib/python3.10/site-packages/sklearn/utils/validation.py:2732: UserWarning: X has feature names, but StandardScaler was fitted without feature names\n",
      "  warnings.warn(\n",
      "Saving labels: 100%|██████████| 1/1 [00:02<00:00,  2.71s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_inference 94\n",
      "num of rows add:94\n",
      "datamart/gold/model_predictions/reg_2018_04_01/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved to: datamart/gold/model_predictions/reg_2018_04_01/reg_2018_04_01_predictions_2017_03_06.parquet\n",
      "rows added: 94\n",
      "\n",
      "\n",
      "---completed job---\n",
      "\n",
      "\n",
      "execute command: python model_inference.py --snapshotdate \"2017-03-07\" --modelname \"reg_2018_04_01.pkl\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "25/06/26 23:43:29 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "25/06/26 23:43:31 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.\n",
      "25/06/26 23:43:31 WARN Utils: Service 'SparkUI' could not bind on port 4041. Attempting port 4042.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "---starting job---\n",
      "\n",
      "\n",
      "{'model_artefact_filepath': 'model_bank/reg_2018_04_01.pkl',\n",
      " 'model_bank_directory': 'model_bank/',\n",
      " 'model_name': 'reg_2018_04_01.pkl',\n",
      " 'snapshot_date': datetime.datetime(2017, 3, 7, 0, 0),\n",
      " 'snapshot_date_str': '2017-03-07'}\n",
      "Model loaded successfully! model_bank/reg_2018_04_01.pkl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving labels:   0%|          | 0/1 [00:00<?, ?it/s]/opt/anaconda3/envs/mle_env/lib/python3.10/site-packages/sklearn/utils/validation.py:2732: UserWarning: X has feature names, but StandardScaler was fitted without feature names\n",
      "  warnings.warn(\n",
      "Saving labels: 100%|██████████| 1/1 [00:02<00:00,  2.81s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_inference 78\n",
      "num of rows add:78\n",
      "datamart/gold/model_predictions/reg_2018_04_01/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved to: datamart/gold/model_predictions/reg_2018_04_01/reg_2018_04_01_predictions_2017_03_07.parquet\n",
      "rows added: 78\n",
      "\n",
      "\n",
      "---completed job---\n",
      "\n",
      "\n",
      "execute command: python model_inference.py --snapshotdate \"2017-03-08\" --modelname \"reg_2018_04_01.pkl\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "25/06/26 23:43:40 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "25/06/26 23:43:42 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.\n",
      "25/06/26 23:43:42 WARN Utils: Service 'SparkUI' could not bind on port 4041. Attempting port 4042.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "---starting job---\n",
      "\n",
      "\n",
      "{'model_artefact_filepath': 'model_bank/reg_2018_04_01.pkl',\n",
      " 'model_bank_directory': 'model_bank/',\n",
      " 'model_name': 'reg_2018_04_01.pkl',\n",
      " 'snapshot_date': datetime.datetime(2017, 3, 8, 0, 0),\n",
      " 'snapshot_date_str': '2017-03-08'}\n",
      "Model loaded successfully! model_bank/reg_2018_04_01.pkl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/mle_env/lib/python3.10/site-packages/sklearn/utils/validation.py:2732: UserWarning: X has feature names, but StandardScaler was fitted without feature names\n",
      "  warnings.warn(\n",
      "Saving labels: 100%|██████████| 1/1 [00:05<00:00,  5.66s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_inference 73\n",
      "num of rows add:73\n",
      "datamart/gold/model_predictions/reg_2018_04_01/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved to: datamart/gold/model_predictions/reg_2018_04_01/reg_2018_04_01_predictions_2017_03_08.parquet\n",
      "rows added: 73\n",
      "\n",
      "\n",
      "---completed job---\n",
      "\n",
      "\n",
      "execute command: python model_inference.py --snapshotdate \"2017-03-09\" --modelname \"reg_2018_04_01.pkl\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "25/06/26 23:43:54 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "25/06/26 23:43:55 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.\n",
      "25/06/26 23:43:55 WARN Utils: Service 'SparkUI' could not bind on port 4041. Attempting port 4042.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "---starting job---\n",
      "\n",
      "\n",
      "{'model_artefact_filepath': 'model_bank/reg_2018_04_01.pkl',\n",
      " 'model_bank_directory': 'model_bank/',\n",
      " 'model_name': 'reg_2018_04_01.pkl',\n",
      " 'snapshot_date': datetime.datetime(2017, 3, 9, 0, 0),\n",
      " 'snapshot_date_str': '2017-03-09'}\n",
      "Model loaded successfully! model_bank/reg_2018_04_01.pkl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/mle_env/lib/python3.10/site-packages/sklearn/utils/validation.py:2732: UserWarning: X has feature names, but StandardScaler was fitted without feature names\n",
      "  warnings.warn(\n",
      "Saving labels: 100%|██████████| 1/1 [00:03<00:00,  3.85s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_inference 88\n",
      "num of rows add:88\n",
      "datamart/gold/model_predictions/reg_2018_04_01/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved to: datamart/gold/model_predictions/reg_2018_04_01/reg_2018_04_01_predictions_2017_03_09.parquet\n",
      "rows added: 88\n",
      "\n",
      "\n",
      "---completed job---\n",
      "\n",
      "\n",
      "execute command: python model_inference.py --snapshotdate \"2017-03-10\" --modelname \"reg_2018_04_01.pkl\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "25/06/26 23:44:05 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "25/06/26 23:44:05 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.\n",
      "25/06/26 23:44:05 WARN Utils: Service 'SparkUI' could not bind on port 4041. Attempting port 4042.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "---starting job---\n",
      "\n",
      "\n",
      "{'model_artefact_filepath': 'model_bank/reg_2018_04_01.pkl',\n",
      " 'model_bank_directory': 'model_bank/',\n",
      " 'model_name': 'reg_2018_04_01.pkl',\n",
      " 'snapshot_date': datetime.datetime(2017, 3, 10, 0, 0),\n",
      " 'snapshot_date_str': '2017-03-10'}\n",
      "Model loaded successfully! model_bank/reg_2018_04_01.pkl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving labels:   0%|          | 0/1 [00:00<?, ?it/s]/opt/anaconda3/envs/mle_env/lib/python3.10/site-packages/sklearn/utils/validation.py:2732: UserWarning: X has feature names, but StandardScaler was fitted without feature names\n",
      "  warnings.warn(\n",
      "Saving labels: 100%|██████████| 1/1 [00:03<00:00,  3.16s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_inference 84\n",
      "num of rows add:84\n",
      "datamart/gold/model_predictions/reg_2018_04_01/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved to: datamart/gold/model_predictions/reg_2018_04_01/reg_2018_04_01_predictions_2017_03_10.parquet\n",
      "rows added: 84\n",
      "\n",
      "\n",
      "---completed job---\n",
      "\n",
      "\n",
      "execute command: python model_inference.py --snapshotdate \"2017-03-11\" --modelname \"reg_2018_04_01.pkl\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "25/06/26 23:44:14 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "25/06/26 23:44:15 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.\n",
      "25/06/26 23:44:15 WARN Utils: Service 'SparkUI' could not bind on port 4041. Attempting port 4042.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "---starting job---\n",
      "\n",
      "\n",
      "{'model_artefact_filepath': 'model_bank/reg_2018_04_01.pkl',\n",
      " 'model_bank_directory': 'model_bank/',\n",
      " 'model_name': 'reg_2018_04_01.pkl',\n",
      " 'snapshot_date': datetime.datetime(2017, 3, 11, 0, 0),\n",
      " 'snapshot_date_str': '2017-03-11'}\n",
      "Model loaded successfully! model_bank/reg_2018_04_01.pkl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/mle_env/lib/python3.10/site-packages/sklearn/utils/validation.py:2732: UserWarning: X has feature names, but StandardScaler was fitted without feature names\n",
      "  warnings.warn(\n",
      "Saving labels: 100%|██████████| 1/1 [00:03<00:00,  3.10s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_inference 68\n",
      "num of rows add:68\n",
      "datamart/gold/model_predictions/reg_2018_04_01/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved to: datamart/gold/model_predictions/reg_2018_04_01/reg_2018_04_01_predictions_2017_03_11.parquet\n",
      "rows added: 68\n",
      "\n",
      "\n",
      "---completed job---\n",
      "\n",
      "\n",
      "execute command: python model_inference.py --snapshotdate \"2017-03-12\" --modelname \"reg_2018_04_01.pkl\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "25/06/26 23:44:23 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "25/06/26 23:44:24 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.\n",
      "25/06/26 23:44:24 WARN Utils: Service 'SparkUI' could not bind on port 4041. Attempting port 4042.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "---starting job---\n",
      "\n",
      "\n",
      "{'model_artefact_filepath': 'model_bank/reg_2018_04_01.pkl',\n",
      " 'model_bank_directory': 'model_bank/',\n",
      " 'model_name': 'reg_2018_04_01.pkl',\n",
      " 'snapshot_date': datetime.datetime(2017, 3, 12, 0, 0),\n",
      " 'snapshot_date_str': '2017-03-12'}\n",
      "Model loaded successfully! model_bank/reg_2018_04_01.pkl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/mle_env/lib/python3.10/site-packages/sklearn/utils/validation.py:2732: UserWarning: X has feature names, but StandardScaler was fitted without feature names\n",
      "  warnings.warn(\n",
      "Saving labels: 100%|██████████| 1/1 [00:03<00:00,  3.16s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_inference 63\n",
      "num of rows add:63\n",
      "datamart/gold/model_predictions/reg_2018_04_01/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved to: datamart/gold/model_predictions/reg_2018_04_01/reg_2018_04_01_predictions_2017_03_12.parquet\n",
      "rows added: 63\n",
      "\n",
      "\n",
      "---completed job---\n",
      "\n",
      "\n",
      "execute command: python model_inference.py --snapshotdate \"2017-03-13\" --modelname \"reg_2018_04_01.pkl\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "25/06/26 23:44:33 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "25/06/26 23:44:33 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.\n",
      "25/06/26 23:44:33 WARN Utils: Service 'SparkUI' could not bind on port 4041. Attempting port 4042.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "---starting job---\n",
      "\n",
      "\n",
      "{'model_artefact_filepath': 'model_bank/reg_2018_04_01.pkl',\n",
      " 'model_bank_directory': 'model_bank/',\n",
      " 'model_name': 'reg_2018_04_01.pkl',\n",
      " 'snapshot_date': datetime.datetime(2017, 3, 13, 0, 0),\n",
      " 'snapshot_date_str': '2017-03-13'}\n",
      "Model loaded successfully! model_bank/reg_2018_04_01.pkl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving labels:   0%|          | 0/1 [00:00<?, ?it/s]/opt/anaconda3/envs/mle_env/lib/python3.10/site-packages/sklearn/utils/validation.py:2732: UserWarning: X has feature names, but StandardScaler was fitted without feature names\n",
      "  warnings.warn(\n",
      "Saving labels: 100%|██████████| 1/1 [00:02<00:00,  2.68s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_inference 104\n",
      "num of rows add:104\n",
      "datamart/gold/model_predictions/reg_2018_04_01/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved to: datamart/gold/model_predictions/reg_2018_04_01/reg_2018_04_01_predictions_2017_03_13.parquet\n",
      "rows added: 104\n",
      "\n",
      "\n",
      "---completed job---\n",
      "\n",
      "\n",
      "execute command: python model_inference.py --snapshotdate \"2017-03-14\" --modelname \"reg_2018_04_01.pkl\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "25/06/26 23:44:42 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "25/06/26 23:44:43 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.\n",
      "25/06/26 23:44:43 WARN Utils: Service 'SparkUI' could not bind on port 4041. Attempting port 4042.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "---starting job---\n",
      "\n",
      "\n",
      "{'model_artefact_filepath': 'model_bank/reg_2018_04_01.pkl',\n",
      " 'model_bank_directory': 'model_bank/',\n",
      " 'model_name': 'reg_2018_04_01.pkl',\n",
      " 'snapshot_date': datetime.datetime(2017, 3, 14, 0, 0),\n",
      " 'snapshot_date_str': '2017-03-14'}\n",
      "Model loaded successfully! model_bank/reg_2018_04_01.pkl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving labels:   0%|          | 0/1 [00:00<?, ?it/s]/opt/anaconda3/envs/mle_env/lib/python3.10/site-packages/sklearn/utils/validation.py:2732: UserWarning: X has feature names, but StandardScaler was fitted without feature names\n",
      "  warnings.warn(\n",
      "Saving labels: 100%|██████████| 1/1 [00:02<00:00,  2.75s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_inference 95\n",
      "num of rows add:95\n",
      "datamart/gold/model_predictions/reg_2018_04_01/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved to: datamart/gold/model_predictions/reg_2018_04_01/reg_2018_04_01_predictions_2017_03_14.parquet\n",
      "rows added: 95\n",
      "\n",
      "\n",
      "---completed job---\n",
      "\n",
      "\n",
      "execute command: python model_inference.py --snapshotdate \"2017-03-15\" --modelname \"reg_2018_04_01.pkl\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "25/06/26 23:44:51 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "25/06/26 23:44:52 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.\n",
      "25/06/26 23:44:52 WARN Utils: Service 'SparkUI' could not bind on port 4041. Attempting port 4042.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "---starting job---\n",
      "\n",
      "\n",
      "{'model_artefact_filepath': 'model_bank/reg_2018_04_01.pkl',\n",
      " 'model_bank_directory': 'model_bank/',\n",
      " 'model_name': 'reg_2018_04_01.pkl',\n",
      " 'snapshot_date': datetime.datetime(2017, 3, 15, 0, 0),\n",
      " 'snapshot_date_str': '2017-03-15'}\n",
      "Model loaded successfully! model_bank/reg_2018_04_01.pkl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving labels:   0%|          | 0/1 [00:00<?, ?it/s]/opt/anaconda3/envs/mle_env/lib/python3.10/site-packages/sklearn/utils/validation.py:2732: UserWarning: X has feature names, but StandardScaler was fitted without feature names\n",
      "  warnings.warn(\n",
      "Saving labels: 100%|██████████| 1/1 [00:02<00:00,  2.61s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_inference 101\n",
      "num of rows add:101\n",
      "datamart/gold/model_predictions/reg_2018_04_01/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved to: datamart/gold/model_predictions/reg_2018_04_01/reg_2018_04_01_predictions_2017_03_15.parquet\n",
      "rows added: 101\n",
      "\n",
      "\n",
      "---completed job---\n",
      "\n",
      "\n",
      "execute command: python model_inference.py --snapshotdate \"2017-03-16\" --modelname \"reg_2018_04_01.pkl\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "25/06/26 23:45:01 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "25/06/26 23:45:02 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.\n",
      "25/06/26 23:45:02 WARN Utils: Service 'SparkUI' could not bind on port 4041. Attempting port 4042.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "---starting job---\n",
      "\n",
      "\n",
      "{'model_artefact_filepath': 'model_bank/reg_2018_04_01.pkl',\n",
      " 'model_bank_directory': 'model_bank/',\n",
      " 'model_name': 'reg_2018_04_01.pkl',\n",
      " 'snapshot_date': datetime.datetime(2017, 3, 16, 0, 0),\n",
      " 'snapshot_date_str': '2017-03-16'}\n",
      "Model loaded successfully! model_bank/reg_2018_04_01.pkl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving labels:   0%|          | 0/1 [00:00<?, ?it/s]/opt/anaconda3/envs/mle_env/lib/python3.10/site-packages/sklearn/utils/validation.py:2732: UserWarning: X has feature names, but StandardScaler was fitted without feature names\n",
      "  warnings.warn(\n",
      "Saving labels: 100%|██████████| 1/1 [00:02<00:00,  2.90s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_inference 100\n",
      "num of rows add:100\n",
      "datamart/gold/model_predictions/reg_2018_04_01/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved to: datamart/gold/model_predictions/reg_2018_04_01/reg_2018_04_01_predictions_2017_03_16.parquet\n",
      "rows added: 100\n",
      "\n",
      "\n",
      "---completed job---\n",
      "\n",
      "\n",
      "execute command: python model_inference.py --snapshotdate \"2017-03-17\" --modelname \"reg_2018_04_01.pkl\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "25/06/26 23:45:11 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "25/06/26 23:45:12 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.\n",
      "25/06/26 23:45:12 WARN Utils: Service 'SparkUI' could not bind on port 4041. Attempting port 4042.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "---starting job---\n",
      "\n",
      "\n",
      "{'model_artefact_filepath': 'model_bank/reg_2018_04_01.pkl',\n",
      " 'model_bank_directory': 'model_bank/',\n",
      " 'model_name': 'reg_2018_04_01.pkl',\n",
      " 'snapshot_date': datetime.datetime(2017, 3, 17, 0, 0),\n",
      " 'snapshot_date_str': '2017-03-17'}\n",
      "Model loaded successfully! model_bank/reg_2018_04_01.pkl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving labels:   0%|          | 0/1 [00:00<?, ?it/s]/opt/anaconda3/envs/mle_env/lib/python3.10/site-packages/sklearn/utils/validation.py:2732: UserWarning: X has feature names, but StandardScaler was fitted without feature names\n",
      "  warnings.warn(\n",
      "Saving labels: 100%|██████████| 1/1 [00:02<00:00,  2.64s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_inference 64\n",
      "num of rows add:64\n",
      "datamart/gold/model_predictions/reg_2018_04_01/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved to: datamart/gold/model_predictions/reg_2018_04_01/reg_2018_04_01_predictions_2017_03_17.parquet\n",
      "rows added: 64\n",
      "\n",
      "\n",
      "---completed job---\n",
      "\n",
      "\n",
      "execute command: python model_inference.py --snapshotdate \"2017-03-18\" --modelname \"reg_2018_04_01.pkl\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "25/06/26 23:45:20 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "25/06/26 23:45:20 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.\n",
      "25/06/26 23:45:20 WARN Utils: Service 'SparkUI' could not bind on port 4041. Attempting port 4042.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "---starting job---\n",
      "\n",
      "\n",
      "{'model_artefact_filepath': 'model_bank/reg_2018_04_01.pkl',\n",
      " 'model_bank_directory': 'model_bank/',\n",
      " 'model_name': 'reg_2018_04_01.pkl',\n",
      " 'snapshot_date': datetime.datetime(2017, 3, 18, 0, 0),\n",
      " 'snapshot_date_str': '2017-03-18'}\n",
      "Model loaded successfully! model_bank/reg_2018_04_01.pkl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving labels:   0%|          | 0/1 [00:00<?, ?it/s]/opt/anaconda3/envs/mle_env/lib/python3.10/site-packages/sklearn/utils/validation.py:2732: UserWarning: X has feature names, but StandardScaler was fitted without feature names\n",
      "  warnings.warn(\n",
      "Saving labels: 100%|██████████| 1/1 [00:02<00:00,  2.67s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_inference 71\n",
      "num of rows add:71\n",
      "datamart/gold/model_predictions/reg_2018_04_01/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved to: datamart/gold/model_predictions/reg_2018_04_01/reg_2018_04_01_predictions_2017_03_18.parquet\n",
      "rows added: 71\n",
      "\n",
      "\n",
      "---completed job---\n",
      "\n",
      "\n",
      "execute command: python model_inference.py --snapshotdate \"2017-03-19\" --modelname \"reg_2018_04_01.pkl\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "25/06/26 23:45:29 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "25/06/26 23:45:30 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.\n",
      "25/06/26 23:45:30 WARN Utils: Service 'SparkUI' could not bind on port 4041. Attempting port 4042.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "---starting job---\n",
      "\n",
      "\n",
      "{'model_artefact_filepath': 'model_bank/reg_2018_04_01.pkl',\n",
      " 'model_bank_directory': 'model_bank/',\n",
      " 'model_name': 'reg_2018_04_01.pkl',\n",
      " 'snapshot_date': datetime.datetime(2017, 3, 19, 0, 0),\n",
      " 'snapshot_date_str': '2017-03-19'}\n",
      "Model loaded successfully! model_bank/reg_2018_04_01.pkl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving labels:   0%|          | 0/1 [00:00<?, ?it/s]/opt/anaconda3/envs/mle_env/lib/python3.10/site-packages/sklearn/utils/validation.py:2732: UserWarning: X has feature names, but StandardScaler was fitted without feature names\n",
      "  warnings.warn(\n",
      "Saving labels: 100%|██████████| 1/1 [00:02<00:00,  2.93s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_inference 56\n",
      "num of rows add:56\n",
      "datamart/gold/model_predictions/reg_2018_04_01/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved to: datamart/gold/model_predictions/reg_2018_04_01/reg_2018_04_01_predictions_2017_03_19.parquet\n",
      "rows added: 56\n",
      "\n",
      "\n",
      "---completed job---\n",
      "\n",
      "\n",
      "execute command: python model_inference.py --snapshotdate \"2017-03-20\" --modelname \"reg_2018_04_01.pkl\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "25/06/26 23:45:39 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "25/06/26 23:45:39 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.\n",
      "25/06/26 23:45:39 WARN Utils: Service 'SparkUI' could not bind on port 4041. Attempting port 4042.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "---starting job---\n",
      "\n",
      "\n",
      "{'model_artefact_filepath': 'model_bank/reg_2018_04_01.pkl',\n",
      " 'model_bank_directory': 'model_bank/',\n",
      " 'model_name': 'reg_2018_04_01.pkl',\n",
      " 'snapshot_date': datetime.datetime(2017, 3, 20, 0, 0),\n",
      " 'snapshot_date_str': '2017-03-20'}\n",
      "Model loaded successfully! model_bank/reg_2018_04_01.pkl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving labels:   0%|          | 0/1 [00:00<?, ?it/s]/opt/anaconda3/envs/mle_env/lib/python3.10/site-packages/sklearn/utils/validation.py:2732: UserWarning: X has feature names, but StandardScaler was fitted without feature names\n",
      "  warnings.warn(\n",
      "Saving labels: 100%|██████████| 1/1 [00:02<00:00,  2.75s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_inference 113\n",
      "num of rows add:113\n",
      "datamart/gold/model_predictions/reg_2018_04_01/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved to: datamart/gold/model_predictions/reg_2018_04_01/reg_2018_04_01_predictions_2017_03_20.parquet\n",
      "rows added: 113\n",
      "\n",
      "\n",
      "---completed job---\n",
      "\n",
      "\n",
      "execute command: python model_inference.py --snapshotdate \"2017-03-21\" --modelname \"reg_2018_04_01.pkl\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "25/06/26 23:45:51 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "25/06/26 23:45:51 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.\n",
      "25/06/26 23:45:51 WARN Utils: Service 'SparkUI' could not bind on port 4041. Attempting port 4042.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "---starting job---\n",
      "\n",
      "\n",
      "{'model_artefact_filepath': 'model_bank/reg_2018_04_01.pkl',\n",
      " 'model_bank_directory': 'model_bank/',\n",
      " 'model_name': 'reg_2018_04_01.pkl',\n",
      " 'snapshot_date': datetime.datetime(2017, 3, 21, 0, 0),\n",
      " 'snapshot_date_str': '2017-03-21'}\n",
      "Model loaded successfully! model_bank/reg_2018_04_01.pkl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/mle_env/lib/python3.10/site-packages/sklearn/utils/validation.py:2732: UserWarning: X has feature names, but StandardScaler was fitted without feature names\n",
      "  warnings.warn(\n",
      "Saving labels: 100%|██████████| 1/1 [00:04<00:00,  4.97s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_inference 92\n",
      "num of rows add:92\n",
      "datamart/gold/model_predictions/reg_2018_04_01/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved to: datamart/gold/model_predictions/reg_2018_04_01/reg_2018_04_01_predictions_2017_03_21.parquet\n",
      "rows added: 92\n",
      "\n",
      "\n",
      "---completed job---\n",
      "\n",
      "\n",
      "execute command: python model_inference.py --snapshotdate \"2017-03-22\" --modelname \"reg_2018_04_01.pkl\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "25/06/26 23:46:03 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "25/06/26 23:46:03 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.\n",
      "25/06/26 23:46:03 WARN Utils: Service 'SparkUI' could not bind on port 4041. Attempting port 4042.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "---starting job---\n",
      "\n",
      "\n",
      "{'model_artefact_filepath': 'model_bank/reg_2018_04_01.pkl',\n",
      " 'model_bank_directory': 'model_bank/',\n",
      " 'model_name': 'reg_2018_04_01.pkl',\n",
      " 'snapshot_date': datetime.datetime(2017, 3, 22, 0, 0),\n",
      " 'snapshot_date_str': '2017-03-22'}\n",
      "Model loaded successfully! model_bank/reg_2018_04_01.pkl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving labels:   0%|          | 0/1 [00:00<?, ?it/s]/opt/anaconda3/envs/mle_env/lib/python3.10/site-packages/sklearn/utils/validation.py:2732: UserWarning: X has feature names, but StandardScaler was fitted without feature names\n",
      "  warnings.warn(\n",
      "Saving labels: 100%|██████████| 1/1 [00:02<00:00,  2.78s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_inference 104\n",
      "num of rows add:104\n",
      "datamart/gold/model_predictions/reg_2018_04_01/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved to: datamart/gold/model_predictions/reg_2018_04_01/reg_2018_04_01_predictions_2017_03_22.parquet\n",
      "rows added: 104\n",
      "\n",
      "\n",
      "---completed job---\n",
      "\n",
      "\n",
      "execute command: python model_inference.py --snapshotdate \"2017-03-23\" --modelname \"reg_2018_04_01.pkl\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "25/06/26 23:46:12 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "25/06/26 23:46:13 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.\n",
      "25/06/26 23:46:13 WARN Utils: Service 'SparkUI' could not bind on port 4041. Attempting port 4042.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "---starting job---\n",
      "\n",
      "\n",
      "{'model_artefact_filepath': 'model_bank/reg_2018_04_01.pkl',\n",
      " 'model_bank_directory': 'model_bank/',\n",
      " 'model_name': 'reg_2018_04_01.pkl',\n",
      " 'snapshot_date': datetime.datetime(2017, 3, 23, 0, 0),\n",
      " 'snapshot_date_str': '2017-03-23'}\n",
      "Model loaded successfully! model_bank/reg_2018_04_01.pkl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving labels:   0%|          | 0/1 [00:00<?, ?it/s]/opt/anaconda3/envs/mle_env/lib/python3.10/site-packages/sklearn/utils/validation.py:2732: UserWarning: X has feature names, but StandardScaler was fitted without feature names\n",
      "  warnings.warn(\n",
      "Saving labels: 100%|██████████| 1/1 [00:02<00:00,  2.89s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_inference 104\n",
      "num of rows add:104\n",
      "datamart/gold/model_predictions/reg_2018_04_01/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved to: datamart/gold/model_predictions/reg_2018_04_01/reg_2018_04_01_predictions_2017_03_23.parquet\n",
      "rows added: 104\n",
      "\n",
      "\n",
      "---completed job---\n",
      "\n",
      "\n",
      "execute command: python model_inference.py --snapshotdate \"2017-03-24\" --modelname \"reg_2018_04_01.pkl\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "25/06/26 23:46:21 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "25/06/26 23:46:21 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.\n",
      "25/06/26 23:46:21 WARN Utils: Service 'SparkUI' could not bind on port 4041. Attempting port 4042.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "---starting job---\n",
      "\n",
      "\n",
      "{'model_artefact_filepath': 'model_bank/reg_2018_04_01.pkl',\n",
      " 'model_bank_directory': 'model_bank/',\n",
      " 'model_name': 'reg_2018_04_01.pkl',\n",
      " 'snapshot_date': datetime.datetime(2017, 3, 24, 0, 0),\n",
      " 'snapshot_date_str': '2017-03-24'}\n",
      "Model loaded successfully! model_bank/reg_2018_04_01.pkl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving labels:   0%|          | 0/1 [00:00<?, ?it/s]/opt/anaconda3/envs/mle_env/lib/python3.10/site-packages/sklearn/utils/validation.py:2732: UserWarning: X has feature names, but StandardScaler was fitted without feature names\n",
      "  warnings.warn(\n",
      "Saving labels: 100%|██████████| 1/1 [00:02<00:00,  2.82s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_inference 75\n",
      "num of rows add:75\n",
      "datamart/gold/model_predictions/reg_2018_04_01/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved to: datamart/gold/model_predictions/reg_2018_04_01/reg_2018_04_01_predictions_2017_03_24.parquet\n",
      "rows added: 75\n",
      "\n",
      "\n",
      "---completed job---\n",
      "\n",
      "\n",
      "execute command: python model_inference.py --snapshotdate \"2017-03-25\" --modelname \"reg_2018_04_01.pkl\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "25/06/26 23:46:30 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "25/06/26 23:46:30 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.\n",
      "25/06/26 23:46:30 WARN Utils: Service 'SparkUI' could not bind on port 4041. Attempting port 4042.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "---starting job---\n",
      "\n",
      "\n",
      "{'model_artefact_filepath': 'model_bank/reg_2018_04_01.pkl',\n",
      " 'model_bank_directory': 'model_bank/',\n",
      " 'model_name': 'reg_2018_04_01.pkl',\n",
      " 'snapshot_date': datetime.datetime(2017, 3, 25, 0, 0),\n",
      " 'snapshot_date_str': '2017-03-25'}\n",
      "Model loaded successfully! model_bank/reg_2018_04_01.pkl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving labels:   0%|          | 0/1 [00:00<?, ?it/s]/opt/anaconda3/envs/mle_env/lib/python3.10/site-packages/sklearn/utils/validation.py:2732: UserWarning: X has feature names, but StandardScaler was fitted without feature names\n",
      "  warnings.warn(\n",
      "Saving labels: 100%|██████████| 1/1 [00:03<00:00,  3.00s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_inference 72\n",
      "num of rows add:72\n",
      "datamart/gold/model_predictions/reg_2018_04_01/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved to: datamart/gold/model_predictions/reg_2018_04_01/reg_2018_04_01_predictions_2017_03_25.parquet\n",
      "rows added: 72\n",
      "\n",
      "\n",
      "---completed job---\n",
      "\n",
      "\n",
      "execute command: python model_inference.py --snapshotdate \"2017-03-26\" --modelname \"reg_2018_04_01.pkl\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "25/06/26 23:46:39 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "25/06/26 23:46:39 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.\n",
      "25/06/26 23:46:39 WARN Utils: Service 'SparkUI' could not bind on port 4041. Attempting port 4042.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "---starting job---\n",
      "\n",
      "\n",
      "{'model_artefact_filepath': 'model_bank/reg_2018_04_01.pkl',\n",
      " 'model_bank_directory': 'model_bank/',\n",
      " 'model_name': 'reg_2018_04_01.pkl',\n",
      " 'snapshot_date': datetime.datetime(2017, 3, 26, 0, 0),\n",
      " 'snapshot_date_str': '2017-03-26'}\n",
      "Model loaded successfully! model_bank/reg_2018_04_01.pkl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving labels:   0%|          | 0/1 [00:00<?, ?it/s]/opt/anaconda3/envs/mle_env/lib/python3.10/site-packages/sklearn/utils/validation.py:2732: UserWarning: X has feature names, but StandardScaler was fitted without feature names\n",
      "  warnings.warn(\n",
      "Saving labels: 100%|██████████| 1/1 [00:02<00:00,  2.82s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_inference 63\n",
      "num of rows add:63\n",
      "datamart/gold/model_predictions/reg_2018_04_01/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved to: datamart/gold/model_predictions/reg_2018_04_01/reg_2018_04_01_predictions_2017_03_26.parquet\n",
      "rows added: 63\n",
      "\n",
      "\n",
      "---completed job---\n",
      "\n",
      "\n",
      "execute command: python model_inference.py --snapshotdate \"2017-03-27\" --modelname \"reg_2018_04_01.pkl\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "25/06/26 23:46:48 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "25/06/26 23:46:48 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.\n",
      "25/06/26 23:46:48 WARN Utils: Service 'SparkUI' could not bind on port 4041. Attempting port 4042.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "---starting job---\n",
      "\n",
      "\n",
      "{'model_artefact_filepath': 'model_bank/reg_2018_04_01.pkl',\n",
      " 'model_bank_directory': 'model_bank/',\n",
      " 'model_name': 'reg_2018_04_01.pkl',\n",
      " 'snapshot_date': datetime.datetime(2017, 3, 27, 0, 0),\n",
      " 'snapshot_date_str': '2017-03-27'}\n",
      "Model loaded successfully! model_bank/reg_2018_04_01.pkl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving labels:   0%|          | 0/1 [00:00<?, ?it/s]/opt/anaconda3/envs/mle_env/lib/python3.10/site-packages/sklearn/utils/validation.py:2732: UserWarning: X has feature names, but StandardScaler was fitted without feature names\n",
      "  warnings.warn(\n",
      "Saving labels: 100%|██████████| 1/1 [00:02<00:00,  2.78s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_inference 107\n",
      "num of rows add:107\n",
      "datamart/gold/model_predictions/reg_2018_04_01/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved to: datamart/gold/model_predictions/reg_2018_04_01/reg_2018_04_01_predictions_2017_03_27.parquet\n",
      "rows added: 107\n",
      "\n",
      "\n",
      "---completed job---\n",
      "\n",
      "\n",
      "execute command: python model_inference.py --snapshotdate \"2017-03-28\" --modelname \"reg_2018_04_01.pkl\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "25/06/26 23:46:57 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "25/06/26 23:46:58 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.\n",
      "25/06/26 23:46:58 WARN Utils: Service 'SparkUI' could not bind on port 4041. Attempting port 4042.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "---starting job---\n",
      "\n",
      "\n",
      "{'model_artefact_filepath': 'model_bank/reg_2018_04_01.pkl',\n",
      " 'model_bank_directory': 'model_bank/',\n",
      " 'model_name': 'reg_2018_04_01.pkl',\n",
      " 'snapshot_date': datetime.datetime(2017, 3, 28, 0, 0),\n",
      " 'snapshot_date_str': '2017-03-28'}\n",
      "Model loaded successfully! model_bank/reg_2018_04_01.pkl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/mle_env/lib/python3.10/site-packages/sklearn/utils/validation.py:2732: UserWarning: X has feature names, but StandardScaler was fitted without feature names\n",
      "  warnings.warn(\n",
      "Saving labels: 100%|██████████| 1/1 [00:02<00:00,  2.76s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_inference 96\n",
      "num of rows add:96\n",
      "datamart/gold/model_predictions/reg_2018_04_01/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved to: datamart/gold/model_predictions/reg_2018_04_01/reg_2018_04_01_predictions_2017_03_28.parquet\n",
      "rows added: 96\n",
      "\n",
      "\n",
      "---completed job---\n",
      "\n",
      "\n",
      "execute command: python model_inference.py --snapshotdate \"2017-03-29\" --modelname \"reg_2018_04_01.pkl\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "25/06/26 23:47:06 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "25/06/26 23:47:07 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.\n",
      "25/06/26 23:47:07 WARN Utils: Service 'SparkUI' could not bind on port 4041. Attempting port 4042.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "---starting job---\n",
      "\n",
      "\n",
      "{'model_artefact_filepath': 'model_bank/reg_2018_04_01.pkl',\n",
      " 'model_bank_directory': 'model_bank/',\n",
      " 'model_name': 'reg_2018_04_01.pkl',\n",
      " 'snapshot_date': datetime.datetime(2017, 3, 29, 0, 0),\n",
      " 'snapshot_date_str': '2017-03-29'}\n",
      "Model loaded successfully! model_bank/reg_2018_04_01.pkl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/mle_env/lib/python3.10/site-packages/sklearn/utils/validation.py:2732: UserWarning: X has feature names, but StandardScaler was fitted without feature names\n",
      "  warnings.warn(\n",
      "Saving labels: 100%|██████████| 1/1 [00:02<00:00,  2.89s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_inference 72\n",
      "num of rows add:72\n",
      "datamart/gold/model_predictions/reg_2018_04_01/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved to: datamart/gold/model_predictions/reg_2018_04_01/reg_2018_04_01_predictions_2017_03_29.parquet\n",
      "rows added: 72\n",
      "\n",
      "\n",
      "---completed job---\n",
      "\n",
      "\n",
      "execute command: python model_inference.py --snapshotdate \"2017-03-30\" --modelname \"reg_2018_04_01.pkl\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "25/06/26 23:47:15 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "25/06/26 23:47:16 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.\n",
      "25/06/26 23:47:16 WARN Utils: Service 'SparkUI' could not bind on port 4041. Attempting port 4042.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "---starting job---\n",
      "\n",
      "\n",
      "{'model_artefact_filepath': 'model_bank/reg_2018_04_01.pkl',\n",
      " 'model_bank_directory': 'model_bank/',\n",
      " 'model_name': 'reg_2018_04_01.pkl',\n",
      " 'snapshot_date': datetime.datetime(2017, 3, 30, 0, 0),\n",
      " 'snapshot_date_str': '2017-03-30'}\n",
      "Model loaded successfully! model_bank/reg_2018_04_01.pkl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving labels:   0%|          | 0/1 [00:00<?, ?it/s]/opt/anaconda3/envs/mle_env/lib/python3.10/site-packages/sklearn/utils/validation.py:2732: UserWarning: X has feature names, but StandardScaler was fitted without feature names\n",
      "  warnings.warn(\n",
      "Saving labels: 100%|██████████| 1/1 [00:02<00:00,  2.84s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_inference 70\n",
      "num of rows add:70\n",
      "datamart/gold/model_predictions/reg_2018_04_01/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 2:>                                                          (0 + 8) / 8]\r"
     ]
    }
   ],
   "source": [
    "import datetime\n",
    "import os\n",
    "\n",
    "start_date = datetime.date(2017, 1, 1)\n",
    "end_date = datetime.date(2018, 10, 1)\n",
    "\n",
    "modelname = 'reg_2018_04_01.pkl'\n",
    "\n",
    "for i in range((end_date - start_date).days + 1):\n",
    "    day = start_date + datetime.timedelta(days=i)\n",
    "    day_str = day.strftime(\"%Y-%m-%d\")\n",
    "    cmd = f'python model_inference.py --snapshotdate \"{day_str}\" --modelname \"{modelname}\"'\n",
    "    print(f'execute command: {cmd}')\n",
    "    os.system(cmd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d5851eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "import os\n",
    "\n",
    "start_date = datetime.date(2017, 1, 1)\n",
    "end_date = datetime.date(2018, 10, 1)\n",
    "\n",
    "model = ''\n",
    "\n",
    "for i in range((end_date - start_date).days + 1):\n",
    "    day = start_date + datetime.timedelta(days=i)\n",
    "    day_str = day.strftime(\"%Y-%m-%d\")\n",
    "    cmd = f'python model_monitoring.py --snapshotdate \"{day_str}\" --model \"{modelname}\"'\n",
    "    print(f'execute command: {cmd}')\n",
    "    os.system(cmd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "5ca7d9f0-cfbc-4098-826c-5537ba56b108",
   "metadata": {},
   "outputs": [],
   "source": [
    "snapshot_date_str = \"2017-01-04\"\n",
    "model_name = \"reg_2018_04_01.pkl\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "75f0bb22-745b-4342-9779-4425795dc752",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {}\n",
    "config[\"snapshot_date_str\"] = snapshot_date_str\n",
    "config[\"snapshot_date\"] = datetime.strptime(config[\"snapshot_date_str\"], \"%Y-%m-%d\")\n",
    "config[\"model_name\"] = model_name\n",
    "config[\"model_bank_directory\"] = \"model_bank/\"\n",
    "config[\"model_artefact_filepath\"] = config[\"model_bank_directory\"] + config[\"model_name\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bea8c974-7a80-44ec-a73f-b72c46b70972",
   "metadata": {},
   "source": [
    "## load model artefact from model bank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "e4704571-1729-49ef-b2fb-e7346fc37d84",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded successfully! model_bank/reg_2018_04_01.pkl\n"
     ]
    }
   ],
   "source": [
    "# Load the model from the pickle file\n",
    "with open(config[\"model_artefact_filepath\"], 'rb') as file:\n",
    "    model_artefact = pickle.load(file)\n",
    "\n",
    "print(\"Model loaded successfully! \" + config[\"model_artefact_filepath\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "441303bb-1736-4589-8537-c914d8d843b1",
   "metadata": {},
   "source": [
    "## load feature store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bf8b317e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'model_artefact_filepath': 'model_bank/reg_2018_04_01.pkl',\n",
      " 'model_bank_directory': 'model_bank/',\n",
      " 'model_name': 'reg_2018_04_01.pkl',\n",
      " 'snapshot_date': datetime.datetime(2017, 1, 1, 0, 0),\n",
      " 'snapshot_date_str': '2017-01-01'}\n",
      "Model loaded successfully! model_bank/reg_2018_04_01.pkl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving labels: 100%|██████████| 1/1 [00:00<00:00, 107.91it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y_inference 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>order_id</th>\n",
       "      <th>order_status</th>\n",
       "      <th>model_name</th>\n",
       "      <th>model_predictions</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [order_id, order_status, model_name, model_predictions]\n",
       "Index: []"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "def main(snapshotdate, modelname):\n",
    "    # --- set up config ---\n",
    "    config = {}\n",
    "    config[\"snapshot_date_str\"] = snapshotdate\n",
    "    config[\"snapshot_date\"] = datetime.strptime(config[\"snapshot_date_str\"], \"%Y-%m-%d\")\n",
    "    config[\"model_name\"] = modelname\n",
    "    config[\"model_bank_directory\"] = \"model_bank/\"\n",
    "    config[\"model_artefact_filepath\"] = config[\"model_bank_directory\"] + config[\"model_name\"]\n",
    "    \n",
    "    pprint.pprint(config)\n",
    "    \n",
    "    # --- load model artefact from model bank ---\n",
    "    # Load the model from the pickle file\n",
    "    with open(config[\"model_artefact_filepath\"], 'rb') as file:\n",
    "        model_artefact = pickle.load(file)\n",
    "    \n",
    "    print(\"Model loaded successfully! \" + config[\"model_artefact_filepath\"])\n",
    "    date_lst = [snapshotdate]\n",
    "    for date_str in tqdm(date_lst, total=len(date_lst), desc=\"Saving labels\"):\n",
    "        partition_name = date_str.replace('-','_') + '.parquet'\n",
    "        feature_location = \"datamart/gold/feature_store/\"\n",
    "        files_list = os.path.join(feature_location, partition_name)\n",
    "        if os.path.exists(files_list):\n",
    "            features_store_sdf = spark.read.parquet(files_list)\n",
    "            features_store_sdf = features_store_sdf.drop(\"avg_rating\",\"snapshot_date\",\"avg_delay_rate\",\"concentration\",\"act_days_to_deliver\",\"total_freight_value\",\"avg_processing_time\",\"same_state\",\"total_volume_cm3\",\"seller_city\",\"seller_state\")\n",
    "            features_sdf = features_store_sdf.toPandas()\n",
    "            features_sdf = features_sdf.dropna(how='any')\n",
    "            features_sdf = features_sdf[features_sdf[\"order_status\"] == \"delivered\"]\n",
    "            if features_sdf.empty:\n",
    "                y_inference_pdf = pd.DataFrame(columns=['order_id', 'order_status', 'model_name', 'model_predictions'])\n",
    "                print('y_inference', y_inference_pdf.shape[0])\n",
    "            else:\n",
    "                # prepare X_inference\n",
    "                #encoder = OneHotEncoder(drop = 'first', sparse=False, handle_unknown='ignore')\n",
    "                encoder = OneHotEncoder(drop = 'first', sparse_output=False, handle_unknown='ignore')\n",
    "                encoder.fit(features_sdf[['season']])  # Only fit on training data\n",
    "                encoded_feature = encoder.transform(features_sdf[['season']])\n",
    "                encoded_f = pd.DataFrame(encoded_feature, columns=encoder.get_feature_names_out(['season']), index=features_sdf.index)\n",
    "                features_sdf = pd.concat([features_sdf.drop(columns=['season']), encoded_f], axis=1)\n",
    "                expected_columns = ['season_Spring', 'season_Summer', 'season_Winter']\n",
    "                for col in expected_columns:\n",
    "                    if col not in features_sdf.columns:\n",
    "                        features_sdf[col] = 0\n",
    "                features_pdf = features_sdf.select_dtypes(include='number')\n",
    "                \n",
    "                #features_pdf = features_sdf.drop(columns=['order_id', 'order_status']).values\n",
    "                # apply transformer - standard scaler\n",
    "                transformer_stdscaler = model_artefact[\"preprocessing_transformers\"][\"stdscaler\"]\n",
    "                X_inference = transformer_stdscaler.transform(features_pdf)\n",
    "                print('X_inference', X_inference.shape[0])\n",
    "        \n",
    "                # --- model prediction inference ---\n",
    "                # load model\n",
    "                model = model_artefact[\"model\"]\n",
    "                threshold = model_artefact['threshold']\n",
    "                \n",
    "                # predict model\n",
    "                y_inference = model.predict_proba(X_inference)[:, 1]\n",
    "                \n",
    "                # prepare output\n",
    "                y_inference_pdf = features_sdf[[\"order_id\",\"order_status\",]].copy()\n",
    "                y_inference_pdf[\"model_predictions\"] = y_inference.round(4)\n",
    "                y_inference_pdf[\"model_predictions\"] = (y_inference_pdf[\"model_predictions\"] > threshold).astype(int)\n",
    "                y_inference_pdf[\"snapshot_date\"] = snapshotdate\n",
    "                y_inference_pdf[\"model_name\"] = config[\"model_name\"]\n",
    "                row_count = y_inference_pdf.shape[0]\n",
    "                print(f'num of rows add:{row_count}')\n",
    "        else:\n",
    "            y_inference_pdf = pd.DataFrame(columns=['order_id', 'order_status', 'model_name', 'model_predictions'])\n",
    "            print('y_inference', y_inference_pdf.shape[0])\n",
    "\n",
    "    return y_inference_pdf\n",
    "\n",
    "partitions_list = '2017-01-01'\n",
    "test = main(partitions_list, 'reg_2018_04_01.pkl')\n",
    "\n",
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d002feb1-30f5-415a-91ef-b686ee8de99a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "row_count for features: 98356 \n",
      "\n",
      "row_count for features: 96212 \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DataFrame[order_id: string, order_status: string, total_qty: bigint, total_price: double, total_weight_g: double, total_density: double, delivery_distance: double, same_city: int, is_weekend: int, day_of_week: int, season: string]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from functools import reduce\n",
    "date_str = '2018-01-05'\n",
    "feature_location = \"datamart/gold/feature_store/\"\n",
    "# Load CSV into DataFrame - connect to feature store\n",
    "files_list = glob.glob(os.path.join(feature_location,date_str,'.parquet'))\n",
    "files_list = glob.glob(os.path.join(feature_location, date_str, '*.parquet'))\n",
    "features_store_sdf = spark.read.option(\"header\", \"true\").parquet(*files_list)\n",
    "print(\"row_count for features:\",features_store_sdf.count(),\"\\n\")\n",
    "\n",
    "# Filter out NA\n",
    "features_store_sdf = features_store_sdf.drop(\"avg_rating\",\"snapshot_date\",\"concentration\",\"avg_delay_rate\",\"act_days_to_deliver\",\"total_freight_value\",\"avg_processing_time\",\"same_state\",\"total_volume_cm3\",\"seller_city\",\"seller_state\")\n",
    "#rows_with_nulls = features_store_sdf.filter(\n",
    "    #reduce(lambda a, b: a | b, (col(c).isNull() for c in features_store_sdf.columns)))\n",
    "\n",
    "\n",
    "#order_ids_to_drop = [row[\"order_id\"] for row in rows_with_nulls.select(\"order_id\").distinct().collect()]\n",
    "#features_store_sdf = features_store_sdf.filter(~col(\"order_id\").isin(order_ids_to_drop))\n",
    "\n",
    "#Extract relevant features\n",
    "#features_store_sdf = features_store_sdf.filter(col(\"order_status\") == \"delivered\")\n",
    "features_sdf = features_store_sdf.toPandas()\n",
    "features_sdf = features_sdf.dropna(how='any')\n",
    "features_store_sdf = features_store_sdf[features_store_sdf[\"order_status\"] == \"delivered\"]\n",
    "print(\"row_count for features:\",features_store_sdf.count(),\"\\n\")\n",
    "\n",
    "features_store_sdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "11609efb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[order_id: string, order_status: string, total_qty: bigint, total_price: double, total_weight_g: double, total_density: double, delivery_distance: double, same_city: int, is_weekend: int, avg_rating: double, day_of_week: int, season: string]"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = features_store_sdf.dropna()\n",
    "test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cabff32",
   "metadata": {},
   "source": [
    "Processing for modelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "88c13a49",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>order_id</th>\n",
       "      <th>order_status</th>\n",
       "      <th>total_qty</th>\n",
       "      <th>total_price</th>\n",
       "      <th>total_weight_g</th>\n",
       "      <th>total_density</th>\n",
       "      <th>delivery_distance</th>\n",
       "      <th>same_city</th>\n",
       "      <th>is_weekend</th>\n",
       "      <th>avg_rating</th>\n",
       "      <th>avg_delay_rate</th>\n",
       "      <th>day_of_week</th>\n",
       "      <th>season_Summer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>09f58c00f941827ab206de7796785e44</td>\n",
       "      <td>delivered</td>\n",
       "      <td>1</td>\n",
       "      <td>8.90</td>\n",
       "      <td>200.0</td>\n",
       "      <td>0.568182</td>\n",
       "      <td>12.302606</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0bda8164c1a12b6a388ebec8559ee287</td>\n",
       "      <td>delivered</td>\n",
       "      <td>1</td>\n",
       "      <td>6.90</td>\n",
       "      <td>200.0</td>\n",
       "      <td>0.568182</td>\n",
       "      <td>10.536861</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>17fed53ba6dfef9b594ee2268642e2aa</td>\n",
       "      <td>delivered</td>\n",
       "      <td>1</td>\n",
       "      <td>9.90</td>\n",
       "      <td>200.0</td>\n",
       "      <td>0.568182</td>\n",
       "      <td>12.528518</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1b694ef5b28d3e949a4f0ffeb2c9fcd6</td>\n",
       "      <td>delivered</td>\n",
       "      <td>1</td>\n",
       "      <td>9.90</td>\n",
       "      <td>200.0</td>\n",
       "      <td>0.568182</td>\n",
       "      <td>10.536861</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>205d7052a6505124d200f6fea6b423bc</td>\n",
       "      <td>delivered</td>\n",
       "      <td>1</td>\n",
       "      <td>9.90</td>\n",
       "      <td>200.0</td>\n",
       "      <td>0.568182</td>\n",
       "      <td>10.536861</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2f9d791088532b218b41f892cc16073b</td>\n",
       "      <td>delivered</td>\n",
       "      <td>1</td>\n",
       "      <td>9.90</td>\n",
       "      <td>200.0</td>\n",
       "      <td>0.568182</td>\n",
       "      <td>15.043834</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>34bf4feda1e203af64692d97c6950c39</td>\n",
       "      <td>delivered</td>\n",
       "      <td>1</td>\n",
       "      <td>10.90</td>\n",
       "      <td>200.0</td>\n",
       "      <td>0.568182</td>\n",
       "      <td>6.443899</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>38bcb524e1c38c2c1b60600a80fc8999</td>\n",
       "      <td>delivered</td>\n",
       "      <td>1</td>\n",
       "      <td>2.90</td>\n",
       "      <td>200.0</td>\n",
       "      <td>0.568182</td>\n",
       "      <td>11.661939</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>3ce4038922670fead496aeae61a8a393</td>\n",
       "      <td>delivered</td>\n",
       "      <td>1</td>\n",
       "      <td>10.90</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.284091</td>\n",
       "      <td>10.536861</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>40599d3d28b75746952ded75566637b9</td>\n",
       "      <td>delivered</td>\n",
       "      <td>1</td>\n",
       "      <td>11.90</td>\n",
       "      <td>200.0</td>\n",
       "      <td>0.568182</td>\n",
       "      <td>10.536861</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>43d29c6fc78c31c80080d85e5260a9fb</td>\n",
       "      <td>delivered</td>\n",
       "      <td>1</td>\n",
       "      <td>10.90</td>\n",
       "      <td>200.0</td>\n",
       "      <td>0.568182</td>\n",
       "      <td>7.705215</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>464de32dc84484c1d26df3e8e38e708b</td>\n",
       "      <td>delivered</td>\n",
       "      <td>1</td>\n",
       "      <td>6.90</td>\n",
       "      <td>200.0</td>\n",
       "      <td>0.568182</td>\n",
       "      <td>12.528518</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>5965b589a33443dd1f820eb7df39762a</td>\n",
       "      <td>delivered</td>\n",
       "      <td>1</td>\n",
       "      <td>10.90</td>\n",
       "      <td>200.0</td>\n",
       "      <td>0.568182</td>\n",
       "      <td>10.536861</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>6acecf438369055d9243e121045cca74</td>\n",
       "      <td>delivered</td>\n",
       "      <td>1</td>\n",
       "      <td>9.90</td>\n",
       "      <td>200.0</td>\n",
       "      <td>0.568182</td>\n",
       "      <td>11.661939</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>7004296aa0256632eaddc171edaf727f</td>\n",
       "      <td>delivered</td>\n",
       "      <td>1</td>\n",
       "      <td>10.90</td>\n",
       "      <td>200.0</td>\n",
       "      <td>0.568182</td>\n",
       "      <td>10.536861</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>747996a66f5aa711deb8ae58f5ae46a0</td>\n",
       "      <td>delivered</td>\n",
       "      <td>1</td>\n",
       "      <td>9.90</td>\n",
       "      <td>200.0</td>\n",
       "      <td>0.568182</td>\n",
       "      <td>12.528518</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>7a18a504c1a4b32d883e68de2e1a7db0</td>\n",
       "      <td>delivered</td>\n",
       "      <td>1</td>\n",
       "      <td>7.90</td>\n",
       "      <td>200.0</td>\n",
       "      <td>0.568182</td>\n",
       "      <td>11.661939</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>8a784d47854e4cbc5562362393d504db</td>\n",
       "      <td>delivered</td>\n",
       "      <td>1</td>\n",
       "      <td>9.90</td>\n",
       "      <td>200.0</td>\n",
       "      <td>0.568182</td>\n",
       "      <td>12.528518</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>9b91ddcbd6cbceb83d4fd2462ca1f95e</td>\n",
       "      <td>delivered</td>\n",
       "      <td>1</td>\n",
       "      <td>10.90</td>\n",
       "      <td>200.0</td>\n",
       "      <td>0.568182</td>\n",
       "      <td>12.528518</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>b95a0a8bd30aece4e94e81f0591249d8</td>\n",
       "      <td>delivered</td>\n",
       "      <td>1</td>\n",
       "      <td>10.90</td>\n",
       "      <td>200.0</td>\n",
       "      <td>0.568182</td>\n",
       "      <td>10.536861</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>c96209cd1d43d071d3bdf48d299b7aa5</td>\n",
       "      <td>delivered</td>\n",
       "      <td>1</td>\n",
       "      <td>11.90</td>\n",
       "      <td>200.0</td>\n",
       "      <td>0.568182</td>\n",
       "      <td>10.536861</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>ca5a215980675471f0cf8199c041909a</td>\n",
       "      <td>delivered</td>\n",
       "      <td>1</td>\n",
       "      <td>10.90</td>\n",
       "      <td>200.0</td>\n",
       "      <td>0.568182</td>\n",
       "      <td>12.528518</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>cce1b8a1c5f8b1d224e19628299c8f54</td>\n",
       "      <td>delivered</td>\n",
       "      <td>1</td>\n",
       "      <td>10.90</td>\n",
       "      <td>200.0</td>\n",
       "      <td>0.568182</td>\n",
       "      <td>15.043834</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>ce86fa5a5108884726a2244bcae51ae6</td>\n",
       "      <td>delivered</td>\n",
       "      <td>1</td>\n",
       "      <td>10.90</td>\n",
       "      <td>200.0</td>\n",
       "      <td>0.568182</td>\n",
       "      <td>10.536861</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>d82cef48824870df9946d57e827ed727</td>\n",
       "      <td>delivered</td>\n",
       "      <td>1</td>\n",
       "      <td>10.90</td>\n",
       "      <td>200.0</td>\n",
       "      <td>0.568182</td>\n",
       "      <td>10.536861</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>db7576b1fe440f4c0a808855aacf0948</td>\n",
       "      <td>delivered</td>\n",
       "      <td>1</td>\n",
       "      <td>9.90</td>\n",
       "      <td>200.0</td>\n",
       "      <td>0.568182</td>\n",
       "      <td>15.043834</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>e1fe072ef14b519af1f0a8ed997c1301</td>\n",
       "      <td>delivered</td>\n",
       "      <td>1</td>\n",
       "      <td>9.90</td>\n",
       "      <td>200.0</td>\n",
       "      <td>0.568182</td>\n",
       "      <td>502.769958</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>ec7a019261fce44180373d45b442d78f</td>\n",
       "      <td>delivered</td>\n",
       "      <td>1</td>\n",
       "      <td>10.90</td>\n",
       "      <td>200.0</td>\n",
       "      <td>0.568182</td>\n",
       "      <td>10.536861</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>f175d67589e059cbbda956f10f0702e6</td>\n",
       "      <td>delivered</td>\n",
       "      <td>1</td>\n",
       "      <td>9.90</td>\n",
       "      <td>200.0</td>\n",
       "      <td>0.568182</td>\n",
       "      <td>10.536861</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>f2dd5f15184c73c0d45c02941c7c23d1</td>\n",
       "      <td>delivered</td>\n",
       "      <td>1</td>\n",
       "      <td>65.00</td>\n",
       "      <td>4200.0</td>\n",
       "      <td>0.107143</td>\n",
       "      <td>1484.304495</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>5</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>f92641ff0446a0e1c57195ebfe76e16a</td>\n",
       "      <td>delivered</td>\n",
       "      <td>1</td>\n",
       "      <td>9.90</td>\n",
       "      <td>200.0</td>\n",
       "      <td>0.568182</td>\n",
       "      <td>10.536861</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>157ec3dc3f38cdbd2706bd216edfe8fb</td>\n",
       "      <td>delivered</td>\n",
       "      <td>1</td>\n",
       "      <td>159.99</td>\n",
       "      <td>700.0</td>\n",
       "      <td>0.074405</td>\n",
       "      <td>357.099635</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3.111111</td>\n",
       "      <td>0.545455</td>\n",
       "      <td>6</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>1b3d11cf9f92c0f7baf627ab059621f8</td>\n",
       "      <td>delivered</td>\n",
       "      <td>1</td>\n",
       "      <td>636.00</td>\n",
       "      <td>638.0</td>\n",
       "      <td>0.085799</td>\n",
       "      <td>2263.747129</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>6</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>e6db6e9529fecbe14cd05dd349816656</td>\n",
       "      <td>delivered</td>\n",
       "      <td>1</td>\n",
       "      <td>109.90</td>\n",
       "      <td>467.0</td>\n",
       "      <td>0.102547</td>\n",
       "      <td>514.480452</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>6</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            order_id order_status  total_qty  total_price  \\\n",
       "0   09f58c00f941827ab206de7796785e44    delivered          1         8.90   \n",
       "1   0bda8164c1a12b6a388ebec8559ee287    delivered          1         6.90   \n",
       "2   17fed53ba6dfef9b594ee2268642e2aa    delivered          1         9.90   \n",
       "3   1b694ef5b28d3e949a4f0ffeb2c9fcd6    delivered          1         9.90   \n",
       "4   205d7052a6505124d200f6fea6b423bc    delivered          1         9.90   \n",
       "5   2f9d791088532b218b41f892cc16073b    delivered          1         9.90   \n",
       "6   34bf4feda1e203af64692d97c6950c39    delivered          1        10.90   \n",
       "7   38bcb524e1c38c2c1b60600a80fc8999    delivered          1         2.90   \n",
       "8   3ce4038922670fead496aeae61a8a393    delivered          1        10.90   \n",
       "9   40599d3d28b75746952ded75566637b9    delivered          1        11.90   \n",
       "10  43d29c6fc78c31c80080d85e5260a9fb    delivered          1        10.90   \n",
       "11  464de32dc84484c1d26df3e8e38e708b    delivered          1         6.90   \n",
       "12  5965b589a33443dd1f820eb7df39762a    delivered          1        10.90   \n",
       "13  6acecf438369055d9243e121045cca74    delivered          1         9.90   \n",
       "14  7004296aa0256632eaddc171edaf727f    delivered          1        10.90   \n",
       "15  747996a66f5aa711deb8ae58f5ae46a0    delivered          1         9.90   \n",
       "16  7a18a504c1a4b32d883e68de2e1a7db0    delivered          1         7.90   \n",
       "17  8a784d47854e4cbc5562362393d504db    delivered          1         9.90   \n",
       "18  9b91ddcbd6cbceb83d4fd2462ca1f95e    delivered          1        10.90   \n",
       "19  b95a0a8bd30aece4e94e81f0591249d8    delivered          1        10.90   \n",
       "20  c96209cd1d43d071d3bdf48d299b7aa5    delivered          1        11.90   \n",
       "21  ca5a215980675471f0cf8199c041909a    delivered          1        10.90   \n",
       "22  cce1b8a1c5f8b1d224e19628299c8f54    delivered          1        10.90   \n",
       "23  ce86fa5a5108884726a2244bcae51ae6    delivered          1        10.90   \n",
       "24  d82cef48824870df9946d57e827ed727    delivered          1        10.90   \n",
       "25  db7576b1fe440f4c0a808855aacf0948    delivered          1         9.90   \n",
       "26  e1fe072ef14b519af1f0a8ed997c1301    delivered          1         9.90   \n",
       "27  ec7a019261fce44180373d45b442d78f    delivered          1        10.90   \n",
       "28  f175d67589e059cbbda956f10f0702e6    delivered          1         9.90   \n",
       "29  f2dd5f15184c73c0d45c02941c7c23d1    delivered          1        65.00   \n",
       "30  f92641ff0446a0e1c57195ebfe76e16a    delivered          1         9.90   \n",
       "31  157ec3dc3f38cdbd2706bd216edfe8fb    delivered          1       159.99   \n",
       "32  1b3d11cf9f92c0f7baf627ab059621f8    delivered          1       636.00   \n",
       "33  e6db6e9529fecbe14cd05dd349816656    delivered          1       109.90   \n",
       "\n",
       "    total_weight_g  total_density  delivery_distance  same_city  is_weekend  \\\n",
       "0            200.0       0.568182          12.302606          1           0   \n",
       "1            200.0       0.568182          10.536861          1           0   \n",
       "2            200.0       0.568182          12.528518          1           0   \n",
       "3            200.0       0.568182          10.536861          1           0   \n",
       "4            200.0       0.568182          10.536861          1           0   \n",
       "5            200.0       0.568182          15.043834          1           0   \n",
       "6            200.0       0.568182           6.443899          1           0   \n",
       "7            200.0       0.568182          11.661939          1           0   \n",
       "8            100.0       0.284091          10.536861          1           0   \n",
       "9            200.0       0.568182          10.536861          1           0   \n",
       "10           200.0       0.568182           7.705215          1           0   \n",
       "11           200.0       0.568182          12.528518          1           0   \n",
       "12           200.0       0.568182          10.536861          1           0   \n",
       "13           200.0       0.568182          11.661939          1           0   \n",
       "14           200.0       0.568182          10.536861          1           0   \n",
       "15           200.0       0.568182          12.528518          1           0   \n",
       "16           200.0       0.568182          11.661939          1           0   \n",
       "17           200.0       0.568182          12.528518          1           0   \n",
       "18           200.0       0.568182          12.528518          1           0   \n",
       "19           200.0       0.568182          10.536861          1           0   \n",
       "20           200.0       0.568182          10.536861          1           0   \n",
       "21           200.0       0.568182          12.528518          1           0   \n",
       "22           200.0       0.568182          15.043834          1           0   \n",
       "23           200.0       0.568182          10.536861          1           0   \n",
       "24           200.0       0.568182          10.536861          1           0   \n",
       "25           200.0       0.568182          15.043834          1           0   \n",
       "26           200.0       0.568182         502.769958          0           0   \n",
       "27           200.0       0.568182          10.536861          1           0   \n",
       "28           200.0       0.568182          10.536861          1           0   \n",
       "29          4200.0       0.107143        1484.304495          0           0   \n",
       "30           200.0       0.568182          10.536861          1           0   \n",
       "31           700.0       0.074405         357.099635          0           0   \n",
       "32           638.0       0.085799        2263.747129          0           0   \n",
       "33           467.0       0.102547         514.480452          0           0   \n",
       "\n",
       "    avg_rating  avg_delay_rate  day_of_week  season_Summer  \n",
       "0     5.000000        0.000000            5            1.0  \n",
       "1     5.000000        0.000000            5            1.0  \n",
       "2     5.000000        0.000000            5            1.0  \n",
       "3     5.000000        0.000000            5            1.0  \n",
       "4     5.000000        0.000000            5            1.0  \n",
       "5     5.000000        0.000000            5            1.0  \n",
       "6     5.000000        0.000000            5            1.0  \n",
       "7     5.000000        0.000000            5            1.0  \n",
       "8     5.000000        0.000000            5            1.0  \n",
       "9     5.000000        0.000000            5            1.0  \n",
       "10    5.000000        0.000000            5            1.0  \n",
       "11    5.000000        0.000000            5            1.0  \n",
       "12    5.000000        0.000000            5            1.0  \n",
       "13    5.000000        0.000000            5            1.0  \n",
       "14    5.000000        0.000000            5            1.0  \n",
       "15    5.000000        0.000000            5            1.0  \n",
       "16    5.000000        0.000000            5            1.0  \n",
       "17    5.000000        0.000000            5            1.0  \n",
       "18    5.000000        0.000000            5            1.0  \n",
       "19    5.000000        0.000000            5            1.0  \n",
       "20    5.000000        0.000000            5            1.0  \n",
       "21    5.000000        0.000000            5            1.0  \n",
       "22    5.000000        0.000000            5            1.0  \n",
       "23    5.000000        0.000000            5            1.0  \n",
       "24    5.000000        0.000000            5            1.0  \n",
       "25    5.000000        0.000000            5            1.0  \n",
       "26    5.000000        0.000000            5            1.0  \n",
       "27    5.000000        0.000000            5            1.0  \n",
       "28    5.000000        0.000000            5            1.0  \n",
       "29    2.000000        0.250000            5            1.0  \n",
       "30    5.000000        0.000000            5            1.0  \n",
       "31    3.111111        0.545455            6            1.0  \n",
       "32    4.000000        1.000000            6            1.0  \n",
       "33    1.000000        1.000000            6            1.0  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "import pandas as pd\n",
    "\n",
    "encoder = OneHotEncoder(sparse_output=False, handle_unknown='ignore')\n",
    "encoder.fit(features_sdf[['season']])  # Only fit on training data\n",
    "encoded_feature = encoder.transform(features_sdf[['season']])\n",
    "encoded_f = pd.DataFrame(encoded_feature, columns=encoder.get_feature_names_out(['season']), index=features_sdf.index)\n",
    "features_sdf = pd.concat([features_sdf.drop(columns=['season']), encoded_f], axis=1)\n",
    "\n",
    "features_sdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "b8be2284",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_inference 37\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/mle_env/lib/python3.10/site-packages/sklearn/utils/validation.py:2732: UserWarning: X has feature names, but StandardScaler was fitted without feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.types import NumericType\n",
    "if features_sdf.empty == True:\n",
    "    y_inference_pdf = features_sdf[['order_id','order_status']]\n",
    "    y_inference_pdf['model_name'] = ''\n",
    "    y_inference_pdf['model_predictions'] = ''\n",
    "    print('y_inference', y_inference_pdf.shape[0])\n",
    "else: \n",
    "    # prepare X_inference\n",
    "    encoder = OneHotEncoder(sparse_output=False, handle_unknown='ignore')\n",
    "    encoder.fit(features_sdf[['season']])  # Only fit on training data\n",
    "    encoded_feature = encoder.transform(features_sdf[['season']])\n",
    "    encoded_f = pd.DataFrame(encoded_feature, columns=encoder.get_feature_names_out(['season']), index=features_sdf.index)\n",
    "    features_sdf = pd.concat([features_sdf.drop(columns=['season']), encoded_f], axis=1)\n",
    "    expected_columns = ['season_Spring', 'season_Summer', 'season_Winter']\n",
    "    for col in expected_columns:\n",
    "        if col not in features_sdf.columns:\n",
    "            features_sdf[col] = 0\n",
    "    features_pdf = features_sdf.select_dtypes(include='number')\n",
    "    transformer_stdscaler = model_artefact[\"preprocessing_transformers\"][\"stdscaler\"]\n",
    "    X_inference = transformer_stdscaler.transform(features_pdf)\n",
    "    print('X_inference', X_inference.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1a4362f-9dee-4838-a030-a74b88884b4f",
   "metadata": {},
   "source": [
    "## model prediction inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "973c76b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.24"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "threshold = model_artefact['threshold']\n",
    "threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "a5e85498-68bb-4083-8035-3247d7e296d4",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Input X contains NaN.\nLogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[80], line 6\u001b[0m\n\u001b[1;32m      3\u001b[0m threshold \u001b[38;5;241m=\u001b[39m model_artefact[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mthreshold\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m      5\u001b[0m \u001b[38;5;66;03m# predict model\u001b[39;00m\n\u001b[0;32m----> 6\u001b[0m y_inference \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict_proba\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_inference\u001b[49m\u001b[43m)\u001b[49m[:, \u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m      8\u001b[0m \u001b[38;5;66;03m# prepare output\u001b[39;00m\n\u001b[1;32m      9\u001b[0m y_inference_pdf \u001b[38;5;241m=\u001b[39m features_sdf[[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124morder_id\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124morder_status\u001b[39m\u001b[38;5;124m\"\u001b[39m]]\u001b[38;5;241m.\u001b[39mcopy()\n",
      "File \u001b[0;32m/opt/anaconda3/envs/mle_env/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1428\u001b[0m, in \u001b[0;36mLogisticRegression.predict_proba\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m   1423\u001b[0m ovr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmulti_class \u001b[38;5;129;01min\u001b[39;00m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124movr\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwarn\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[1;32m   1424\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmulti_class \u001b[38;5;129;01min\u001b[39;00m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mauto\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdeprecated\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m   1425\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclasses_\u001b[38;5;241m.\u001b[39msize \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m2\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msolver \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mliblinear\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   1426\u001b[0m )\n\u001b[1;32m   1427\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ovr:\n\u001b[0;32m-> 1428\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_predict_proba_lr\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1429\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1430\u001b[0m     decision \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdecision_function(X)\n",
      "File \u001b[0;32m/opt/anaconda3/envs/mle_env/lib/python3.10/site-packages/sklearn/linear_model/_base.py:389\u001b[0m, in \u001b[0;36mLinearClassifierMixin._predict_proba_lr\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    382\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_predict_proba_lr\u001b[39m(\u001b[38;5;28mself\u001b[39m, X):\n\u001b[1;32m    383\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Probability estimation for OvR logistic regression.\u001b[39;00m\n\u001b[1;32m    384\u001b[0m \n\u001b[1;32m    385\u001b[0m \u001b[38;5;124;03m    Positive class probabilities are computed as\u001b[39;00m\n\u001b[1;32m    386\u001b[0m \u001b[38;5;124;03m    1. / (1. + np.exp(-self.decision_function(X)));\u001b[39;00m\n\u001b[1;32m    387\u001b[0m \u001b[38;5;124;03m    multiclass is handled by normalizing that over all classes.\u001b[39;00m\n\u001b[1;32m    388\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 389\u001b[0m     prob \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecision_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    390\u001b[0m     expit(prob, out\u001b[38;5;241m=\u001b[39mprob)\n\u001b[1;32m    391\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m prob\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n",
      "File \u001b[0;32m/opt/anaconda3/envs/mle_env/lib/python3.10/site-packages/sklearn/linear_model/_base.py:351\u001b[0m, in \u001b[0;36mLinearClassifierMixin.decision_function\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    348\u001b[0m check_is_fitted(\u001b[38;5;28mself\u001b[39m)\n\u001b[1;32m    349\u001b[0m xp, _ \u001b[38;5;241m=\u001b[39m get_namespace(X)\n\u001b[0;32m--> 351\u001b[0m X \u001b[38;5;241m=\u001b[39m \u001b[43mvalidate_data\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maccept_sparse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcsr\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m    352\u001b[0m scores \u001b[38;5;241m=\u001b[39m safe_sparse_dot(X, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcoef_\u001b[38;5;241m.\u001b[39mT, dense_output\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m) \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mintercept_\n\u001b[1;32m    353\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m (\n\u001b[1;32m    354\u001b[0m     xp\u001b[38;5;241m.\u001b[39mreshape(scores, (\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m,))\n\u001b[1;32m    355\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m (scores\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m scores\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m    356\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m scores\n\u001b[1;32m    357\u001b[0m )\n",
      "File \u001b[0;32m/opt/anaconda3/envs/mle_env/lib/python3.10/site-packages/sklearn/utils/validation.py:2944\u001b[0m, in \u001b[0;36mvalidate_data\u001b[0;34m(_estimator, X, y, reset, validate_separately, skip_check_array, **check_params)\u001b[0m\n\u001b[1;32m   2942\u001b[0m         out \u001b[38;5;241m=\u001b[39m X, y\n\u001b[1;32m   2943\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m no_val_X \u001b[38;5;129;01mand\u001b[39;00m no_val_y:\n\u001b[0;32m-> 2944\u001b[0m     out \u001b[38;5;241m=\u001b[39m \u001b[43mcheck_array\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minput_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mX\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mcheck_params\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2945\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m no_val_X \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m no_val_y:\n\u001b[1;32m   2946\u001b[0m     out \u001b[38;5;241m=\u001b[39m _check_y(y, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcheck_params)\n",
      "File \u001b[0;32m/opt/anaconda3/envs/mle_env/lib/python3.10/site-packages/sklearn/utils/validation.py:1107\u001b[0m, in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_writeable, force_all_finite, ensure_all_finite, ensure_non_negative, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[0m\n\u001b[1;32m   1101\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   1102\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFound array with dim \u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m. \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m expected <= 2.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1103\u001b[0m         \u001b[38;5;241m%\u001b[39m (array\u001b[38;5;241m.\u001b[39mndim, estimator_name)\n\u001b[1;32m   1104\u001b[0m     )\n\u001b[1;32m   1106\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ensure_all_finite:\n\u001b[0;32m-> 1107\u001b[0m     \u001b[43m_assert_all_finite\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1108\u001b[0m \u001b[43m        \u001b[49m\u001b[43marray\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1109\u001b[0m \u001b[43m        \u001b[49m\u001b[43minput_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1110\u001b[0m \u001b[43m        \u001b[49m\u001b[43mestimator_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mestimator_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1111\u001b[0m \u001b[43m        \u001b[49m\u001b[43mallow_nan\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mensure_all_finite\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mallow-nan\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1112\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1114\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m copy:\n\u001b[1;32m   1115\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m _is_numpy_namespace(xp):\n\u001b[1;32m   1116\u001b[0m         \u001b[38;5;66;03m# only make a copy if `array` and `array_orig` may share memory`\u001b[39;00m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/mle_env/lib/python3.10/site-packages/sklearn/utils/validation.py:120\u001b[0m, in \u001b[0;36m_assert_all_finite\u001b[0;34m(X, allow_nan, msg_dtype, estimator_name, input_name)\u001b[0m\n\u001b[1;32m    117\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m first_pass_isfinite:\n\u001b[1;32m    118\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[0;32m--> 120\u001b[0m \u001b[43m_assert_all_finite_element_wise\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    121\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    122\u001b[0m \u001b[43m    \u001b[49m\u001b[43mxp\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mxp\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    123\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_nan\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mallow_nan\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    124\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmsg_dtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmsg_dtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    125\u001b[0m \u001b[43m    \u001b[49m\u001b[43mestimator_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mestimator_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    126\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    127\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/mle_env/lib/python3.10/site-packages/sklearn/utils/validation.py:169\u001b[0m, in \u001b[0;36m_assert_all_finite_element_wise\u001b[0;34m(X, xp, allow_nan, msg_dtype, estimator_name, input_name)\u001b[0m\n\u001b[1;32m    152\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m estimator_name \u001b[38;5;129;01mand\u001b[39;00m input_name \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mX\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m has_nan_error:\n\u001b[1;32m    153\u001b[0m     \u001b[38;5;66;03m# Improve the error message on how to handle missing values in\u001b[39;00m\n\u001b[1;32m    154\u001b[0m     \u001b[38;5;66;03m# scikit-learn.\u001b[39;00m\n\u001b[1;32m    155\u001b[0m     msg_err \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    156\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mestimator_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m does not accept missing values\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    157\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m encoded as NaN natively. For supervised learning, you might want\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    167\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m#estimators-that-handle-nan-values\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    168\u001b[0m     )\n\u001b[0;32m--> 169\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(msg_err)\n",
      "\u001b[0;31mValueError\u001b[0m: Input X contains NaN.\nLogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values"
     ]
    }
   ],
   "source": [
    "# load model\n",
    "model = model_artefact[\"model\"]\n",
    "threshold = model_artefact['threshold']\n",
    "\n",
    "# predict model\n",
    "y_inference = model.predict_proba(X_inference)[:, 1]\n",
    "\n",
    "# prepare output\n",
    "y_inference_pdf = features_sdf[[\"order_id\", \"order_status\"]].copy()\n",
    "y_inference_pdf[\"model_name\"] = config[\"model_name\"]\n",
    "y_inference_pdf[\"model_predictions\"] = y_inference.round(4)\n",
    "y_inference_pdf[\"model_predictions\"] = (y_inference_pdf[\"model_predictions\"] > threshold).astype(int)\n",
    "\n",
    "y_inference_pdf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf3fe2b8-4642-486d-aa3b-2d7703ad3d15",
   "metadata": {},
   "source": [
    "## save model inference to datamart gold table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3c28e3e5-81ca-4685-a1f1-f1df12908a72",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "datamart/gold/model_predictions/reg_2017_12_04/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 12:>                                                         (0 + 8) / 8]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved to: datamart/gold/model_predictions/reg_2017_12_04/reg_2017_12_04_predictions_2016_10_10.parquet\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# create bronze datalake\n",
    "gold_directory = f\"datamart/gold/model_predictions/{config['model_name'][:-4]}/\"\n",
    "print(gold_directory)\n",
    "\n",
    "if not os.path.exists(gold_directory):\n",
    "    os.makedirs(gold_directory)\n",
    "\n",
    "# save gold table - IRL connect to database to write\n",
    "partition_name = config[\"model_name\"][:-4] + \"_predictions_\" + snapshot_date_str.replace('-','_') + '.parquet'\n",
    "filepath = gold_directory + partition_name\n",
    "spark.createDataFrame(y_inference_pdf).write.mode(\"overwrite\").parquet(filepath)\n",
    "# df.toPandas().to_parquet(filepath,\n",
    "#           compression='gzip')\n",
    "print('saved to:', filepath)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77a0dfb6-dc32-4a70-9118-9d924213fb2c",
   "metadata": {},
   "source": [
    "## backfill"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cc06866",
   "metadata": {},
   "source": [
    "## Run predictions for XGB and REG "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5867fe20",
   "metadata": {},
   "source": [
    "#### Model Monitoring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9b02e05",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving labels: 100%|██████████| 1/1 [00:00<00:00, 1149.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No data to write. Skipping write step.\n",
      "saved to: datamart/gold/model_monitoring/reg/2017_01_01.parquet\n",
      "rows added: 0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "from sklearn.metrics import fbeta_score\n",
    "\n",
    "def monitoring(snapshotdate, model):\n",
    "    snapshotdate_str = snapshotdate.replace('-', '_')\n",
    "    if model == 'reg':\n",
    "        model_pred_loc = \"datamart/gold/model_predictions/reg_2018_04_01/\" #update\n",
    "        file_name = 'reg_2018_04_01_predictions_' + snapshotdate_str + '.parquet' #update\n",
    "    else:\n",
    "        model_pred_loc = \"datamart/gold/model_predictions/xgb_2018_04_01/\" #update\n",
    "        file_name = 'xgb_2018_04_01_predictions_' + snapshotdate_str + '.parquet' #update\n",
    "    \n",
    "    date_lst = [snapshotdate]\n",
    "    for date_str in tqdm(date_lst, total=len(date_lst), desc=\"Saving labels\"):\n",
    "        files_list = os.path.join(model_pred_loc, file_name)\n",
    "        if os.path.exists(files_list):\n",
    "            model_pred_list = spark.read.parquet(files_list)\n",
    "            print(\"row_count for predictions:\",model_pred_list.count(),\"\\n\")\n",
    "            #Import the ground truths\n",
    "            ground_truth_loc =  \"datamart/gold/label_store\"\n",
    "            files_list = glob.glob(os.path.join(ground_truth_loc, snapshotdate_str+'*.parquet'))\n",
    "            ground_truth_list = spark.read.option(\"header\", \"true\").parquet(*files_list)\n",
    "            print(\"row_count for ground Truths:\",ground_truth_list.count(),\"\\n\")\n",
    "\n",
    "            ground_truth = ground_truth_list.toPandas()\n",
    "            model_pred = model_pred_list.toPandas()\n",
    "            f1_5_score = 0\n",
    "            if ground_truth_list.count() == 0:\n",
    "                df_results = pd.DataFrame([[snapshotdate, f1_5_score]], columns=['snapshot_date', 'f1_5_score'])\n",
    "            else:\n",
    "                final_df = (\n",
    "                    ground_truth.merge(model_pred, how='left', on='order_id')\n",
    "                    [['order_id','model_predictions','miss_delivery_sla','model_name','snapshot_date_y']]  # select columns\n",
    "                    .rename(columns={'miss_delivery_sla': 'ground_truth'})  # rename\n",
    "                )\n",
    "                # Drop NaNs and ensure integer types\n",
    "                filtered_eval = final_df.dropna(subset=[\"ground_truth\", \"model_predictions\"])\n",
    "                y_true = filtered_eval[\"ground_truth\"].astype(int)\n",
    "                y_pred = filtered_eval[\"model_predictions\"].astype(int)\n",
    "\n",
    "                # Compute F1.5 score\n",
    "                f1_5_score = fbeta_score(y_true, y_pred, beta=1.5)\n",
    "                print(f\"F1.5-score: {f1_5_score:.4f}\")\n",
    "                df_results = pd.DataFrame([[snapshotdate, f1_5_score]], columns=['snapshot_date', 'f1_5_score'])\n",
    "\n",
    "        else:\n",
    "            df_results = pd.DataFrame(columns=['snapshot_date', 'f1_5_score'])\n",
    "\n",
    "    # --- save model inference to datamart gold table ---\n",
    "    if model == 'reg':\n",
    "        gold_directory = f\"datamart/gold/model_monitoring/reg/\"\n",
    "    else:\n",
    "        gold_directory = f\"datamart/gold/model_monitoring/xgb/\"\n",
    "    \n",
    "    if not os.path.exists(gold_directory):\n",
    "        os.makedirs(gold_directory)\n",
    "\n",
    "    # save gold table\n",
    "    partition_name = snapshotdate_str+'.parquet'\n",
    "    filepath = gold_directory + partition_name\n",
    "    if df_results.empty:\n",
    "        print(\"No monitoring data to write. Skipping write step.\")\n",
    "        spark.stop()\n",
    "    else: \n",
    "        spark_df = spark.createDataFrame(df_results)\n",
    "        spark_df = spark_df.withColumn(\"f1_5_score\", col(\"f1_5_score\").cast(\"double\"))\n",
    "        spark_df.write.mode(\"overwrite\").parquet(filepath)\n",
    "    rows = df_results.shape[0]\n",
    "    print('saved to:', filepath)\n",
    "    print(f'rows added: {df_results.shape[0]}')\n",
    "    return rows\n",
    "\n",
    "snapshotdate = '2017-01-01'\n",
    "test = monitoring(snapshotdate, 'reg')\n",
    "test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "640b19f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "row_count for Predictions: 32 \n",
      "\n",
      "row_count for ground Truths: 32 \n",
      "\n",
      "F1.5-score: 0.0000\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>order_id</th>\n",
       "      <th>model_predictions</th>\n",
       "      <th>ground_truth</th>\n",
       "      <th>model_name</th>\n",
       "      <th>snapshot_date_y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>b95a0a8bd30aece4e94e81f0591249d8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>reg_2018_04_01.pkl</td>\n",
       "      <td>2017-01-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ca5a215980675471f0cf8199c041909a</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>reg_2018_04_01.pkl</td>\n",
       "      <td>2017-01-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7a18a504c1a4b32d883e68de2e1a7db0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>reg_2018_04_01.pkl</td>\n",
       "      <td>2017-01-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>464de32dc84484c1d26df3e8e38e708b</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>reg_2018_04_01.pkl</td>\n",
       "      <td>2017-01-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>34bf4feda1e203af64692d97c6950c39</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>reg_2018_04_01.pkl</td>\n",
       "      <td>2017-01-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2f9d791088532b218b41f892cc16073b</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>reg_2018_04_01.pkl</td>\n",
       "      <td>2017-01-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>3ce4038922670fead496aeae61a8a393</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>reg_2018_04_01.pkl</td>\n",
       "      <td>2017-01-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>d82cef48824870df9946d57e827ed727</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>reg_2018_04_01.pkl</td>\n",
       "      <td>2017-01-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>e1fe072ef14b519af1f0a8ed997c1301</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>reg_2018_04_01.pkl</td>\n",
       "      <td>2017-01-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>f2dd5f15184c73c0d45c02941c7c23d1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>reg_2018_04_01.pkl</td>\n",
       "      <td>2017-01-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>8a784d47854e4cbc5562362393d504db</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>reg_2018_04_01.pkl</td>\n",
       "      <td>2017-01-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>747996a66f5aa711deb8ae58f5ae46a0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>reg_2018_04_01.pkl</td>\n",
       "      <td>2017-01-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>1b694ef5b28d3e949a4f0ffeb2c9fcd6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>reg_2018_04_01.pkl</td>\n",
       "      <td>2017-01-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>40599d3d28b75746952ded75566637b9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>reg_2018_04_01.pkl</td>\n",
       "      <td>2017-01-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>43d29c6fc78c31c80080d85e5260a9fb</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>reg_2018_04_01.pkl</td>\n",
       "      <td>2017-01-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>205d7052a6505124d200f6fea6b423bc</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>reg_2018_04_01.pkl</td>\n",
       "      <td>2017-01-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>17fed53ba6dfef9b594ee2268642e2aa</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>reg_2018_04_01.pkl</td>\n",
       "      <td>2017-01-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>db7576b1fe440f4c0a808855aacf0948</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>reg_2018_04_01.pkl</td>\n",
       "      <td>2017-01-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>9021fdebb45ac827a6033d6969d5c2e3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>reg_2018_04_01.pkl</td>\n",
       "      <td>2017-01-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>cce1b8a1c5f8b1d224e19628299c8f54</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>reg_2018_04_01.pkl</td>\n",
       "      <td>2017-01-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>ce86fa5a5108884726a2244bcae51ae6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>reg_2018_04_01.pkl</td>\n",
       "      <td>2017-01-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>9b91ddcbd6cbceb83d4fd2462ca1f95e</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>reg_2018_04_01.pkl</td>\n",
       "      <td>2017-01-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>c96209cd1d43d071d3bdf48d299b7aa5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>reg_2018_04_01.pkl</td>\n",
       "      <td>2017-01-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>5965b589a33443dd1f820eb7df39762a</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>reg_2018_04_01.pkl</td>\n",
       "      <td>2017-01-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>7004296aa0256632eaddc171edaf727f</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>reg_2018_04_01.pkl</td>\n",
       "      <td>2017-01-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>6acecf438369055d9243e121045cca74</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>reg_2018_04_01.pkl</td>\n",
       "      <td>2017-01-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>38bcb524e1c38c2c1b60600a80fc8999</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>reg_2018_04_01.pkl</td>\n",
       "      <td>2017-01-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0bda8164c1a12b6a388ebec8559ee287</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>reg_2018_04_01.pkl</td>\n",
       "      <td>2017-01-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>09f58c00f941827ab206de7796785e44</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>reg_2018_04_01.pkl</td>\n",
       "      <td>2017-01-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>f175d67589e059cbbda956f10f0702e6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>reg_2018_04_01.pkl</td>\n",
       "      <td>2017-01-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>f92641ff0446a0e1c57195ebfe76e16a</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>reg_2018_04_01.pkl</td>\n",
       "      <td>2017-01-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>ec7a019261fce44180373d45b442d78f</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>reg_2018_04_01.pkl</td>\n",
       "      <td>2017-01-05</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            order_id  model_predictions  ground_truth  \\\n",
       "0   b95a0a8bd30aece4e94e81f0591249d8                  0             0   \n",
       "1   ca5a215980675471f0cf8199c041909a                  0             0   \n",
       "2   7a18a504c1a4b32d883e68de2e1a7db0                  0             0   \n",
       "3   464de32dc84484c1d26df3e8e38e708b                  0             0   \n",
       "4   34bf4feda1e203af64692d97c6950c39                  0             0   \n",
       "5   2f9d791088532b218b41f892cc16073b                  0             0   \n",
       "6   3ce4038922670fead496aeae61a8a393                  0             0   \n",
       "7   d82cef48824870df9946d57e827ed727                  0             0   \n",
       "8   e1fe072ef14b519af1f0a8ed997c1301                  1             0   \n",
       "9   f2dd5f15184c73c0d45c02941c7c23d1                  1             0   \n",
       "10  8a784d47854e4cbc5562362393d504db                  0             0   \n",
       "11  747996a66f5aa711deb8ae58f5ae46a0                  0             0   \n",
       "12  1b694ef5b28d3e949a4f0ffeb2c9fcd6                  0             0   \n",
       "13  40599d3d28b75746952ded75566637b9                  0             0   \n",
       "14  43d29c6fc78c31c80080d85e5260a9fb                  0             0   \n",
       "15  205d7052a6505124d200f6fea6b423bc                  0             0   \n",
       "16  17fed53ba6dfef9b594ee2268642e2aa                  0             0   \n",
       "17  db7576b1fe440f4c0a808855aacf0948                  0             0   \n",
       "18  9021fdebb45ac827a6033d6969d5c2e3                  1             0   \n",
       "19  cce1b8a1c5f8b1d224e19628299c8f54                  0             0   \n",
       "20  ce86fa5a5108884726a2244bcae51ae6                  0             0   \n",
       "21  9b91ddcbd6cbceb83d4fd2462ca1f95e                  0             0   \n",
       "22  c96209cd1d43d071d3bdf48d299b7aa5                  0             0   \n",
       "23  5965b589a33443dd1f820eb7df39762a                  0             0   \n",
       "24  7004296aa0256632eaddc171edaf727f                  0             0   \n",
       "25  6acecf438369055d9243e121045cca74                  0             0   \n",
       "26  38bcb524e1c38c2c1b60600a80fc8999                  0             0   \n",
       "27  0bda8164c1a12b6a388ebec8559ee287                  0             0   \n",
       "28  09f58c00f941827ab206de7796785e44                  0             0   \n",
       "29  f175d67589e059cbbda956f10f0702e6                  0             0   \n",
       "30  f92641ff0446a0e1c57195ebfe76e16a                  0             0   \n",
       "31  ec7a019261fce44180373d45b442d78f                  0             0   \n",
       "\n",
       "            model_name snapshot_date_y  \n",
       "0   reg_2018_04_01.pkl      2017-01-05  \n",
       "1   reg_2018_04_01.pkl      2017-01-05  \n",
       "2   reg_2018_04_01.pkl      2017-01-05  \n",
       "3   reg_2018_04_01.pkl      2017-01-05  \n",
       "4   reg_2018_04_01.pkl      2017-01-05  \n",
       "5   reg_2018_04_01.pkl      2017-01-05  \n",
       "6   reg_2018_04_01.pkl      2017-01-05  \n",
       "7   reg_2018_04_01.pkl      2017-01-05  \n",
       "8   reg_2018_04_01.pkl      2017-01-05  \n",
       "9   reg_2018_04_01.pkl      2017-01-05  \n",
       "10  reg_2018_04_01.pkl      2017-01-05  \n",
       "11  reg_2018_04_01.pkl      2017-01-05  \n",
       "12  reg_2018_04_01.pkl      2017-01-05  \n",
       "13  reg_2018_04_01.pkl      2017-01-05  \n",
       "14  reg_2018_04_01.pkl      2017-01-05  \n",
       "15  reg_2018_04_01.pkl      2017-01-05  \n",
       "16  reg_2018_04_01.pkl      2017-01-05  \n",
       "17  reg_2018_04_01.pkl      2017-01-05  \n",
       "18  reg_2018_04_01.pkl      2017-01-05  \n",
       "19  reg_2018_04_01.pkl      2017-01-05  \n",
       "20  reg_2018_04_01.pkl      2017-01-05  \n",
       "21  reg_2018_04_01.pkl      2017-01-05  \n",
       "22  reg_2018_04_01.pkl      2017-01-05  \n",
       "23  reg_2018_04_01.pkl      2017-01-05  \n",
       "24  reg_2018_04_01.pkl      2017-01-05  \n",
       "25  reg_2018_04_01.pkl      2017-01-05  \n",
       "26  reg_2018_04_01.pkl      2017-01-05  \n",
       "27  reg_2018_04_01.pkl      2017-01-05  \n",
       "28  reg_2018_04_01.pkl      2017-01-05  \n",
       "29  reg_2018_04_01.pkl      2017-01-05  \n",
       "30  reg_2018_04_01.pkl      2017-01-05  \n",
       "31  reg_2018_04_01.pkl      2017-01-05  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import fbeta_score\n",
    "model = 'reg'\n",
    "snapshotdate = '2017-01-05'\n",
    "snapshotdate_str = snapshotdate.replace('-', '_')\n",
    "if model == 'reg':\n",
    "    model_pred_loc = \"datamart/gold/model_predictions/reg_2018_04_01/\" #update\n",
    "    file_name = 'reg_2018_04_01_predictions_' + snapshotdate_str + '.parquet' #update\n",
    "else:\n",
    "    model_pred_loc = \"datamart/gold/model_predictions/xgb_2018_04_01/\" #update\n",
    "    file_name = 'xgb_2018_04_01_predictions_' + snapshotdate_str + '.parquet' #update\n",
    "\n",
    "files_list = os.path.join(model_pred_loc, file_name)\n",
    "if os.path.exists(files_list):\n",
    "    model_pred_list = spark.read.parquet(files_list)\n",
    "    print(\"row_count for Predictions:\",model_pred_list.count(),\"\\n\")\n",
    "    #Import the ground truths\n",
    "    ground_truth_loc =  \"datamart/gold/label_store\"\n",
    "    files_list = glob.glob(os.path.join(ground_truth_loc, snapshotdate_str+'*.parquet'))\n",
    "    ground_truth_list = spark.read.option(\"header\", \"true\").parquet(*files_list)\n",
    "    print(\"row_count for ground Truths:\",ground_truth_list.count(),\"\\n\")\n",
    "\n",
    "rows = model_pred_list.count()\n",
    "ground_truth = ground_truth_list.toPandas()\n",
    "model_pred = model_pred_list.toPandas()\n",
    "\n",
    "final_df = (\n",
    "    ground_truth.merge(model_pred, how='left', on='order_id')\n",
    "    [['order_id','model_predictions','miss_delivery_sla','model_name','snapshot_date_y']]  # select columns\n",
    "    .rename(columns={'miss_delivery_sla': 'ground_truth'})  # rename\n",
    ")\n",
    "\n",
    "\n",
    "# Drop NaNs and ensure integer types\n",
    "filtered_eval = final_df.dropna(subset=[\"ground_truth\", \"model_predictions\"])\n",
    "y_true = filtered_eval[\"ground_truth\"].astype(int)\n",
    "y_pred = filtered_eval[\"model_predictions\"].astype(int)\n",
    "\n",
    "# Compute F1.5 score\n",
    "f1_5_score = fbeta_score(y_true, y_pred, beta=1.5)\n",
    "print(f\"F1.5-score: {f1_5_score:.4f}\")\n",
    "df_results = pd.DataFrame([[snapshotdate, model,rows, f1_5_score]], columns=['snapshot_date', 'model', 'num_of_orders', 'f1_5_score'])\n",
    "    \n",
    "filtered_eval"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c339e3cb-1826-49a0-ac73-cb381f85b033",
   "metadata": {},
   "source": [
    "## Check datamart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "418abe90-da75-4c5e-a588-60e00ab3c947",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>snapshot_date</th>\n",
       "      <th>model</th>\n",
       "      <th>num_of_orders</th>\n",
       "      <th>f1_5_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>393</th>\n",
       "      <td>2017-06-01</td>\n",
       "      <td>reg</td>\n",
       "      <td>123</td>\n",
       "      <td>0.502146</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159</th>\n",
       "      <td>2017-06-02</td>\n",
       "      <td>reg</td>\n",
       "      <td>123</td>\n",
       "      <td>0.642504</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>126</th>\n",
       "      <td>2017-06-03</td>\n",
       "      <td>reg</td>\n",
       "      <td>88</td>\n",
       "      <td>0.640845</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>453</th>\n",
       "      <td>2017-06-04</td>\n",
       "      <td>reg</td>\n",
       "      <td>98</td>\n",
       "      <td>0.432373</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>450</th>\n",
       "      <td>2017-06-05</td>\n",
       "      <td>reg</td>\n",
       "      <td>142</td>\n",
       "      <td>0.571631</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>391</th>\n",
       "      <td>2018-08-13</td>\n",
       "      <td>reg</td>\n",
       "      <td>284</td>\n",
       "      <td>0.403509</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>254</th>\n",
       "      <td>2018-08-14</td>\n",
       "      <td>reg</td>\n",
       "      <td>311</td>\n",
       "      <td>0.439189</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>237</th>\n",
       "      <td>2018-08-15</td>\n",
       "      <td>reg</td>\n",
       "      <td>282</td>\n",
       "      <td>0.184922</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>434</th>\n",
       "      <td>2018-08-16</td>\n",
       "      <td>reg</td>\n",
       "      <td>316</td>\n",
       "      <td>0.194611</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>373</th>\n",
       "      <td>2018-08-17</td>\n",
       "      <td>reg</td>\n",
       "      <td>249</td>\n",
       "      <td>0.052632</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>443 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    snapshot_date model  num_of_orders  f1_5_score\n",
       "393    2017-06-01   reg            123    0.502146\n",
       "159    2017-06-02   reg            123    0.642504\n",
       "126    2017-06-03   reg             88    0.640845\n",
       "453    2017-06-04   reg             98    0.432373\n",
       "450    2017-06-05   reg            142    0.571631\n",
       "..            ...   ...            ...         ...\n",
       "391    2018-08-13   reg            284    0.403509\n",
       "254    2018-08-14   reg            311    0.439189\n",
       "237    2018-08-15   reg            282    0.184922\n",
       "434    2018-08-16   reg            316    0.194611\n",
       "373    2018-08-17   reg            249    0.052632\n",
       "\n",
       "[443 rows x 4 columns]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = 'datamart/gold/model_monitoring/reg'\n",
    "filepath = glob.glob(os.path.join(path, '*.parquet'))\n",
    "\n",
    "# Unpack the list of files\n",
    "model_monitoring=spark.read.option(\"header\", \"true\").parquet(*filepath)\n",
    "# Convert to Pandas for inspection\n",
    "model_monitoring_test = model_monitoring.toPandas()\n",
    "model_monitoring_test = model_monitoring_test[model_monitoring_test['f1_5_score'] != 0.0]\n",
    "model_monitoring_test.sort_values('snapshot_date')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "55728897-0715-43a0-904f-5aba101b03aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert snapshot_date to datetime if not already\n",
    "model_monitoring_test['snapshot_date'] = pd.to_datetime(model_monitoring_test['snapshot_date'])\n",
    "\n",
    "# Group by year and month, then calculate average f1_5_score\n",
    "monthly_avg = model_monitoring_test.groupby(model_monitoring_test['snapshot_date'].dt.to_period('M'))['f1_5_score'].mean().reset_index()\n",
    "\n",
    "# Optional: convert 'snapshot_date' back to string or datetime\n",
    "monthly_avg['snapshot_date'] = monthly_avg['snapshot_date'].dt.to_timestamp()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "36d64e8e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>snapshot_date</th>\n",
       "      <th>f1_5_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2017-06-01</td>\n",
       "      <td>0.594991</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2017-07-01</td>\n",
       "      <td>0.651238</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2017-08-01</td>\n",
       "      <td>0.655408</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2017-09-01</td>\n",
       "      <td>0.641031</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2017-10-01</td>\n",
       "      <td>0.638244</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2017-11-01</td>\n",
       "      <td>0.647729</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2017-12-01</td>\n",
       "      <td>0.642155</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2018-01-01</td>\n",
       "      <td>0.643985</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2018-02-01</td>\n",
       "      <td>0.675554</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2018-03-01</td>\n",
       "      <td>0.651711</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2018-04-01</td>\n",
       "      <td>0.654248</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>2018-05-01</td>\n",
       "      <td>0.582770</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>2018-06-01</td>\n",
       "      <td>0.511716</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>2018-07-01</td>\n",
       "      <td>0.477204</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>2018-08-01</td>\n",
       "      <td>0.377932</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   snapshot_date  f1_5_score\n",
       "0     2017-06-01    0.594991\n",
       "1     2017-07-01    0.651238\n",
       "2     2017-08-01    0.655408\n",
       "3     2017-09-01    0.641031\n",
       "4     2017-10-01    0.638244\n",
       "5     2017-11-01    0.647729\n",
       "6     2017-12-01    0.642155\n",
       "7     2018-01-01    0.643985\n",
       "8     2018-02-01    0.675554\n",
       "9     2018-03-01    0.651711\n",
       "10    2018-04-01    0.654248\n",
       "11    2018-05-01    0.582770\n",
       "12    2018-06-01    0.511716\n",
       "13    2018-07-01    0.477204\n",
       "14    2018-08-01    0.377932"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "monthly_avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "d29fda2c-e869-4ee6-9e98-fc85e69eb136",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "monthly_avg['snapshot_date'] = pd.to_datetime(monthly_avg['snapshot_date'])\n",
    "\n",
    "# Calculate mean and std dev\n",
    "mean_score = monthly_avg['f1_5_score'].mean()\n",
    "std_score = monthly_avg['f1_5_score'].std()\n",
    "\n",
    "# Plot\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(monthly_avg['snapshot_date'], monthly_avg['f1_5_score'], marker='o', label='Avg F1.5 Score')\n",
    "plt.axhline(mean_score, color='gray', linestyle='-.', label='Mean')\n",
    "plt.axhline(mean_score + std_score, color='green', linestyle='--', label='+1 Std Dev')\n",
    "plt.axhline(mean_score - std_score, color='red', linestyle='--', label='-1 Std Dev')\n",
    "\n",
    "plt.title('Monthly Average F1.5 Score with ±1 Std Dev')\n",
    "plt.xlabel('Month')\n",
    "plt.ylabel('Average F1.5 Score')\n",
    "#plt.grid(True)\n",
    "plt.xticks(rotation=45)\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aff19c58-94ad-4abb-984f-b082326c2871",
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "import os\n",
    "\n",
    "start_date = datetime.date(2017, 1, 1)\n",
    "end_date = datetime.date(2018, 10, 1)\n",
    "\n",
    "model = 'reg'\n",
    "\n",
    "for i in range((end_date - start_date).days + 1):\n",
    "    day = start_date + datetime.timedelta(days=i)\n",
    "    day_str = day.strftime(\"%Y-%m-%d\")\n",
    "    cmd = f'python model_monitoring.py --snapshotdate \"{day_str}\" --model \"{model}\"'\n",
    "    print(f'execute command: {cmd}')\n",
    "    os.system(cmd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6589bea",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (mle_env)",
   "language": "python",
   "name": "mle_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
